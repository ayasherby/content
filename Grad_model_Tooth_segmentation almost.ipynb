{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayasherby/content/blob/main/Grad_model_Tooth_segmentation%20almost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKGe9_ecqvux",
        "outputId": "d6b52b94-afc9-4e2b-d24d-2ec212a4169d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TEETH-RECOGNITION-WITH-MACHINE-LEARNING'...\n",
            "remote: Enumerating objects: 32505, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 32505 (delta 19), reused 17 (delta 9), pack-reused 32477\u001b[K\n",
            "Receiving objects: 100% (32505/32505), 6.29 GiB | 27.65 MiB/s, done.\n",
            "Resolving deltas: 100% (5099/5099), done.\n",
            "Updating files: 100% (14166/14166), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Arnold0210/TEETH-RECOGNITION-WITH-MACHINE-LEARNING\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb5T0pqI8NK8",
        "outputId": "0b092772-71a7-40e5-a6fe-c56ddfd81544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEmJCgbc1cz0",
        "outputId": "e8908e49-f281-46b2-e6e1-64f601f9ac7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuJaF0MOIcNf",
        "outputId": "e618ddf3-9b6b-4f99-fc29-7cddf22b0d9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory:  /content/TEETH-RECOGNITION-WITH-MACHINE-LEARNING/Experiment/Source\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Change the working directory to your project root\n",
        "project_root = '/content/TEETH-RECOGNITION-WITH-MACHINE-LEARNING/Experiment/Source'\n",
        "os.chdir(project_root)\n",
        "\n",
        "# Verify the change\n",
        "print(\"Current Working Directory: \", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3kp0HWZdRhN",
        "outputId": "0647c7f7-5cf2-4418-9b9c-ee52711a3b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PreProcessing Directory Already Exists.\n",
            "FeatureExtraction Directory Already Exists.\n",
            "Sampling Directory Already Exists.\n",
            "Classification Directory Already Exists.\n",
            "Segmentation Directory Already Exists.\n",
            "BarPlot Directory Already Exists.\n",
            "BarPlotCh1 Directory Already Exists.\n",
            "BarPlotCh2 Directory Already Exists.\n",
            "BarPlotCh3 Directory Already Exists.\n",
            "Mask Directory Already Exists.\n",
            "MaskOverlay Directory Already Exists.\n",
            "Inverse Directory Already Exists.\n",
            "ResizeImages Directory Already Exists.\n",
            "RGB2YCbCr Directory Already Exists.\n",
            "HSV Directory Already Exists.\n",
            "LAB Directory Already Exists.\n",
            "Lab_ Directory Already Exists.\n",
            "ResizeImages Directory Already Exists.\n",
            "Segmentation Directory Already Exists.\n",
            "BarPlot Directory Already Exists.\n",
            "BarPlotCh1 Directory Already Exists.\n",
            "BarPlotCh2 Directory Already Exists.\n",
            "BarPlotCh3 Directory Already Exists.\n",
            "Mask Directory Already Exists.\n",
            "MaskOverlay Directory Already Exists.\n",
            "Inverse Directory Already Exists.\n",
            "ResizeImages Directory Already Exists.\n",
            "RGB2YCbCr Directory Already Exists.\n",
            "HSV Directory Already Exists.\n",
            "LAB Directory Already Exists.\n",
            "Lab_ Directory Already Exists.\n",
            "SVM Directory Already Exists.\n",
            "\n",
            "Indicate the number of iterations: 5\n",
            "\n",
            "Number of folds to split the dataset: 5\n",
            "\n",
            "Percentage of test dataset (e.g., 20 for 20%): 20\n",
            "\n",
            "Training indices: [264, 10, 710, 52, 672, 294, 479, 25, 667, 118, 235, 125, 513, 353, 328, 650, 60, 74, 143, 309, 678, 178, 307, 557, 392, 522, 9, 681, 604, 190, 272, 567, 705, 630, 18, 640, 675, 326, 496, 180, 132, 527, 526, 31, 531, 223, 298, 6, 416, 482, 153, 713, 21, 758, 743, 251, 211, 34, 26, 770, 701, 192, 636, 610, 139, 210, 155, 684, 135, 159, 418, 239, 397, 67, 171, 546, 595, 660, 480, 452, 361, 391, 766, 13, 177, 487, 127, 101, 467, 711, 602, 214, 248, 520, 263, 233, 68, 545, 381, 508, 649, 243, 438, 616, 638, 150, 123, 581, 129, 688, 613, 385, 405, 654, 220, 172, 536, 237, 402, 104, 449, 712, 623, 539, 674, 734, 433, 645, 478, 692, 658, 76, 446, 22, 468, 205, 768, 735, 303, 586, 64, 63, 296, 731, 333, 554, 421, 569, 499, 403, 492, 631, 268, 266, 182, 100, 583, 162, 367, 308, 555, 49, 519, 73, 689, 72, 702, 117, 409, 106, 217, 370, 90, 751, 412, 532, 314, 742, 204, 137, 374, 590, 195, 305, 488, 471, 19, 726, 228, 321, 359, 275, 437, 473, 415, 605, 168, 17, 285, 699, 286, 194, 128, 196, 244, 656, 538, 1, 80, 279, 670, 419, 291, 585, 653, 71, 358, 229, 432, 594, 592, 565, 666, 378, 313, 732, 108, 116, 687, 661, 634, 144, 407, 98, 725, 36, 280, 120, 15, 152, 601, 763, 379, 639, 464, 401, 611, 737, 230, 20, 436, 757, 252, 208, 404, 627, 558, 619, 676, 600, 202, 191, 422, 497, 439, 662, 665, 312, 607, 566, 58, 170, 693, 476, 213, 40, 767, 400, 715, 579, 318, 270, 124, 56, 57, 183, 506, 448, 624, 29, 398, 533, 769, 288, 721, 2, 434, 425, 140, 399, 92, 517, 593, 203, 423, 754, 35, 32, 236, 81, 612, 323, 258, 11, 255, 232, 345, 384, 372, 723, 114, 500, 5, 625, 771, 96, 491, 507, 284, 659, 485, 85, 408, 187, 509, 722, 481, 652, 686, 514, 475, 461, 549, 261, 146, 360, 440, 269, 574, 548, 730, 7, 428, 161, 188, 716, 762, 530, 351, 733, 207, 589, 632, 348, 304, 706, 714, 552, 166, 597, 424, 134, 777, 39, 719, 121, 145, 694, 736, 411, 61, 644, 599, 620, 708, 637, 651, 521, 246, 642, 668, 224, 430, 93, 609, 363, 156, 283, 253, 451, 495, 690, 622, 242, 320, 319, 69, 429, 541, 456, 614, 748, 633, 147, 48, 394, 362, 4, 396, 41, 157, 91, 257, 346, 23, 553, 445, 267, 310, 193, 138, 512, 331, 535, 112, 455, 679, 591, 550, 606, 563, 46, 431, 290, 245, 227, 278, 761, 44, 357, 28, 355, 339, 691, 753, 325, 577, 240, 598, 406, 364, 55, 523, 354, 225, 141, 498, 663, 250, 720, 311, 386, 349, 84, 582, 542, 746, 635, 664, 745, 493, 685, 472, 200, 503, 578, 414, 698, 556, 59, 697, 575, 341, 113, 238, 646, 3, 460, 366, 158, 324, 655, 643, 759, 300, 626, 427, 673, 111, 281, 301, 677, 77, 368, 201, 83, 259, 344, 727, 50, 334, 648, 775, 241, 576, 470, 163, 463, 53, 47, 265, 441, 338, 562, 524, 371, 198, 89, 375, 573, 277, 131, 435, 511, 537, 154, 299, 78, 173, 747, 525, 490, 340, 133, 729, 380, 484, 695, 462, 560, 518, 772, 728, 534, 683, 617, 271, 377, 149, 119, 103, 185, 0, 764, 369, 444, 704, 33, 587, 282, 457, 342, 176, 218, 417, 564, 289, 608, 641, 295, 276, 516, 24, 209, 315, 773, 189, 247, 316, 502, 37, 603, 54, 14, 350, 221, 740, 703, 30, 256, 395, 390, 570, 426, 628, 317, 186, 596, 356, 547, 262, 717]\n",
            "Testing indices: [197, 474, 755, 302, 376, 175, 365, 388, 167, 179, 393, 126, 420, 477, 226, 680, 510, 51, 254, 724, 774, 629, 102, 551, 571, 336, 765, 16, 671, 383, 752, 142, 212, 184, 373, 776, 568, 136, 347, 115, 544, 231, 66, 329, 718, 443, 483, 387, 335, 750, 528, 739, 87, 62, 505, 332, 709, 559, 465, 65, 94, 273, 38, 97, 164, 389, 327, 615, 352, 657, 707, 109, 700, 696, 450, 647, 322, 274, 160, 572, 70, 454, 222, 174, 82, 486, 466, 489, 760, 181, 165, 234, 540, 330, 95, 459, 206, 75, 515, 151, 110, 618, 99, 8, 337, 216, 122, 529, 741, 169, 343, 621, 45, 442, 215, 543, 469, 504, 756, 501, 88, 86, 738, 682, 453, 588, 105, 447, 148, 260, 287, 584, 749, 458, 306, 744, 79, 199, 413, 382, 130, 43, 293, 27, 561, 12, 219, 669, 292, 107, 297, 494, 42, 580, 410, 249]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [197, 474, 755, 302, 376, 175, 365, 388, 167, 179, 393, 126, 420, 477, 226, 680, 510, 51, 254, 724, 774, 629, 102, 551, 571, 336, 765, 16, 671, 383, 752, 142, 212, 184, 373, 776, 568, 136, 347, 115, 544, 231, 66, 329, 718, 443, 483, 387, 335, 750, 528, 739, 87, 62, 505, 332, 709, 559, 465, 65, 94, 273, 38, 97, 164, 389, 327, 615, 352, 657, 707, 109, 700, 696, 450, 647, 322, 274, 160, 572, 70, 454, 222, 174, 82, 486, 466, 489, 760, 181, 165, 234, 540, 330, 95, 459, 206, 75, 515, 151, 110, 618, 99, 8, 337, 216, 122, 529, 741, 169, 343, 621, 45, 442, 215, 543, 469, 504, 756, 501, 88, 86, 738, 682, 453, 588, 105, 447, 148, 260, 287, 584, 749, 458, 306, 744, 79, 199, 413, 382, 130, 43, 293, 27, 561, 12, 219, 669, 292, 107, 297, 494, 42, 580, 410, 249, 583, 162, 367, 308, 555, 49, 519, 73, 689, 72, 702, 117, 409, 106, 217, 370, 90, 751, 412, 532, 314, 742, 204, 137, 374, 590, 195, 305, 488, 471, 19, 726, 228, 321, 359, 275, 437, 473, 415, 605, 168, 17, 285, 699, 286, 194, 128, 196, 244, 656, 538, 1, 80, 279, 670, 419, 291, 585, 653, 71, 358, 229, 432, 594, 592, 565, 666, 378, 313, 732, 108, 116, 687, 661, 634, 144, 407, 98, 725, 36, 280, 120, 15, 152, 601, 763, 379, 639, 464, 401, 611, 737, 230, 20, 436, 757, 252, 208, 404, 627, 558, 619, 676, 600, 202, 191, 422, 497, 439, 662, 665, 312, 607, 566, 58, 170, 693, 476, 213, 40, 767, 400, 715, 579, 318, 270, 124, 56, 57, 183, 506, 448, 624, 29, 398, 533, 769, 288, 721, 2, 434, 425, 140, 399, 92, 517, 593, 203, 423, 754, 35, 32, 236, 81, 612, 323, 258, 11, 255, 232, 345, 384, 372, 723, 114, 500, 5, 625, 771, 96, 491, 507, 284, 659, 485, 85, 408, 187, 509, 722, 481, 652, 686, 514, 475, 461, 549, 261, 146, 360, 440, 269, 574, 548, 730, 7, 428, 161, 188, 716, 762, 530, 351, 733, 207, 589, 632, 348, 304, 706, 714, 552, 166, 597, 424, 134, 777, 39, 719, 121, 145, 694, 736, 411, 61, 644, 599, 620, 708, 637, 651, 521, 246, 642, 668, 224, 430, 93, 609, 363, 156, 283, 253, 451, 495, 690, 622, 242, 320, 319, 69, 429, 541, 456, 614, 748, 633, 147, 48, 394, 362, 4, 396, 41, 157, 91, 257, 346, 23, 553, 445, 267, 310, 193, 138, 512, 331, 535, 112, 455, 679, 591, 550, 606, 563, 46, 431, 290, 245, 227, 278, 761, 44, 357, 28, 355, 339, 691, 753, 325, 577, 240, 598, 406, 364, 55, 523, 354, 225, 141, 498, 663, 250, 720, 311, 386, 349, 84, 582, 542, 746, 635, 664, 745, 493, 685, 472, 200, 503, 578, 414, 698, 556, 59, 697, 575, 341, 113, 238, 646, 3, 460, 366, 158, 324, 655, 643, 759, 300, 626, 427, 673, 111, 281, 301, 677, 77, 368, 201, 83, 259, 344, 727, 50, 334, 648, 775, 241, 576, 470, 163, 463, 53, 47, 265, 441, 338, 562, 524, 371, 198, 89, 375, 573, 277, 131, 435, 511, 537, 154, 299, 78, 173, 747, 525, 490, 340, 133, 729, 380, 484, 695, 462, 560, 518, 772, 728, 534, 683, 617, 271, 377, 149, 119, 103, 185, 0, 764, 369, 444, 704, 33, 587, 282, 457, 342, 176, 218, 417, 564, 289, 608, 641, 295, 276, 516, 24, 209, 315, 773, 189, 247, 316, 502, 37, 603, 54, 14, 350, 221, 740, 703, 30, 256, 395, 390, 570, 426, 628, 317, 186, 596, 356, 547, 262, 717]\n",
            "Testing indices: [264, 10, 710, 52, 672, 294, 479, 25, 667, 118, 235, 125, 513, 353, 328, 650, 60, 74, 143, 309, 678, 178, 307, 557, 392, 522, 9, 681, 604, 190, 272, 567, 705, 630, 18, 640, 675, 326, 496, 180, 132, 527, 526, 31, 531, 223, 298, 6, 416, 482, 153, 713, 21, 758, 743, 251, 211, 34, 26, 770, 701, 192, 636, 610, 139, 210, 155, 684, 135, 159, 418, 239, 397, 67, 171, 546, 595, 660, 480, 452, 361, 391, 766, 13, 177, 487, 127, 101, 467, 711, 602, 214, 248, 520, 263, 233, 68, 545, 381, 508, 649, 243, 438, 616, 638, 150, 123, 581, 129, 688, 613, 385, 405, 654, 220, 172, 536, 237, 402, 104, 449, 712, 623, 539, 674, 734, 433, 645, 478, 692, 658, 76, 446, 22, 468, 205, 768, 735, 303, 586, 64, 63, 296, 731, 333, 554, 421, 569, 499, 403, 492, 631, 268, 266, 182, 100]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [197, 474, 755, 302, 376, 175, 365, 388, 167, 179, 393, 126, 420, 477, 226, 680, 510, 51, 254, 724, 774, 629, 102, 551, 571, 336, 765, 16, 671, 383, 752, 142, 212, 184, 373, 776, 568, 136, 347, 115, 544, 231, 66, 329, 718, 443, 483, 387, 335, 750, 528, 739, 87, 62, 505, 332, 709, 559, 465, 65, 94, 273, 38, 97, 164, 389, 327, 615, 352, 657, 707, 109, 700, 696, 450, 647, 322, 274, 160, 572, 70, 454, 222, 174, 82, 486, 466, 489, 760, 181, 165, 234, 540, 330, 95, 459, 206, 75, 515, 151, 110, 618, 99, 8, 337, 216, 122, 529, 741, 169, 343, 621, 45, 442, 215, 543, 469, 504, 756, 501, 88, 86, 738, 682, 453, 588, 105, 447, 148, 260, 287, 584, 749, 458, 306, 744, 79, 199, 413, 382, 130, 43, 293, 27, 561, 12, 219, 669, 292, 107, 297, 494, 42, 580, 410, 249, 264, 10, 710, 52, 672, 294, 479, 25, 667, 118, 235, 125, 513, 353, 328, 650, 60, 74, 143, 309, 678, 178, 307, 557, 392, 522, 9, 681, 604, 190, 272, 567, 705, 630, 18, 640, 675, 326, 496, 180, 132, 527, 526, 31, 531, 223, 298, 6, 416, 482, 153, 713, 21, 758, 743, 251, 211, 34, 26, 770, 701, 192, 636, 610, 139, 210, 155, 684, 135, 159, 418, 239, 397, 67, 171, 546, 595, 660, 480, 452, 361, 391, 766, 13, 177, 487, 127, 101, 467, 711, 602, 214, 248, 520, 263, 233, 68, 545, 381, 508, 649, 243, 438, 616, 638, 150, 123, 581, 129, 688, 613, 385, 405, 654, 220, 172, 536, 237, 402, 104, 449, 712, 623, 539, 674, 734, 433, 645, 478, 692, 658, 76, 446, 22, 468, 205, 768, 735, 303, 586, 64, 63, 296, 731, 333, 554, 421, 569, 499, 403, 492, 631, 268, 266, 182, 100, 258, 11, 255, 232, 345, 384, 372, 723, 114, 500, 5, 625, 771, 96, 491, 507, 284, 659, 485, 85, 408, 187, 509, 722, 481, 652, 686, 514, 475, 461, 549, 261, 146, 360, 440, 269, 574, 548, 730, 7, 428, 161, 188, 716, 762, 530, 351, 733, 207, 589, 632, 348, 304, 706, 714, 552, 166, 597, 424, 134, 777, 39, 719, 121, 145, 694, 736, 411, 61, 644, 599, 620, 708, 637, 651, 521, 246, 642, 668, 224, 430, 93, 609, 363, 156, 283, 253, 451, 495, 690, 622, 242, 320, 319, 69, 429, 541, 456, 614, 748, 633, 147, 48, 394, 362, 4, 396, 41, 157, 91, 257, 346, 23, 553, 445, 267, 310, 193, 138, 512, 331, 535, 112, 455, 679, 591, 550, 606, 563, 46, 431, 290, 245, 227, 278, 761, 44, 357, 28, 355, 339, 691, 753, 325, 577, 240, 598, 406, 364, 55, 523, 354, 225, 141, 498, 663, 250, 720, 311, 386, 349, 84, 582, 542, 746, 635, 664, 745, 493, 685, 472, 200, 503, 578, 414, 698, 556, 59, 697, 575, 341, 113, 238, 646, 3, 460, 366, 158, 324, 655, 643, 759, 300, 626, 427, 673, 111, 281, 301, 677, 77, 368, 201, 83, 259, 344, 727, 50, 334, 648, 775, 241, 576, 470, 163, 463, 53, 47, 265, 441, 338, 562, 524, 371, 198, 89, 375, 573, 277, 131, 435, 511, 537, 154, 299, 78, 173, 747, 525, 490, 340, 133, 729, 380, 484, 695, 462, 560, 518, 772, 728, 534, 683, 617, 271, 377, 149, 119, 103, 185, 0, 764, 369, 444, 704, 33, 587, 282, 457, 342, 176, 218, 417, 564, 289, 608, 641, 295, 276, 516, 24, 209, 315, 773, 189, 247, 316, 502, 37, 603, 54, 14, 350, 221, 740, 703, 30, 256, 395, 390, 570, 426, 628, 317, 186, 596, 356, 547, 262, 717]\n",
            "Testing indices: [583, 162, 367, 308, 555, 49, 519, 73, 689, 72, 702, 117, 409, 106, 217, 370, 90, 751, 412, 532, 314, 742, 204, 137, 374, 590, 195, 305, 488, 471, 19, 726, 228, 321, 359, 275, 437, 473, 415, 605, 168, 17, 285, 699, 286, 194, 128, 196, 244, 656, 538, 1, 80, 279, 670, 419, 291, 585, 653, 71, 358, 229, 432, 594, 592, 565, 666, 378, 313, 732, 108, 116, 687, 661, 634, 144, 407, 98, 725, 36, 280, 120, 15, 152, 601, 763, 379, 639, 464, 401, 611, 737, 230, 20, 436, 757, 252, 208, 404, 627, 558, 619, 676, 600, 202, 191, 422, 497, 439, 662, 665, 312, 607, 566, 58, 170, 693, 476, 213, 40, 767, 400, 715, 579, 318, 270, 124, 56, 57, 183, 506, 448, 624, 29, 398, 533, 769, 288, 721, 2, 434, 425, 140, 399, 92, 517, 593, 203, 423, 754, 35, 32, 236, 81, 612, 323]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [197, 474, 755, 302, 376, 175, 365, 388, 167, 179, 393, 126, 420, 477, 226, 680, 510, 51, 254, 724, 774, 629, 102, 551, 571, 336, 765, 16, 671, 383, 752, 142, 212, 184, 373, 776, 568, 136, 347, 115, 544, 231, 66, 329, 718, 443, 483, 387, 335, 750, 528, 739, 87, 62, 505, 332, 709, 559, 465, 65, 94, 273, 38, 97, 164, 389, 327, 615, 352, 657, 707, 109, 700, 696, 450, 647, 322, 274, 160, 572, 70, 454, 222, 174, 82, 486, 466, 489, 760, 181, 165, 234, 540, 330, 95, 459, 206, 75, 515, 151, 110, 618, 99, 8, 337, 216, 122, 529, 741, 169, 343, 621, 45, 442, 215, 543, 469, 504, 756, 501, 88, 86, 738, 682, 453, 588, 105, 447, 148, 260, 287, 584, 749, 458, 306, 744, 79, 199, 413, 382, 130, 43, 293, 27, 561, 12, 219, 669, 292, 107, 297, 494, 42, 580, 410, 249, 264, 10, 710, 52, 672, 294, 479, 25, 667, 118, 235, 125, 513, 353, 328, 650, 60, 74, 143, 309, 678, 178, 307, 557, 392, 522, 9, 681, 604, 190, 272, 567, 705, 630, 18, 640, 675, 326, 496, 180, 132, 527, 526, 31, 531, 223, 298, 6, 416, 482, 153, 713, 21, 758, 743, 251, 211, 34, 26, 770, 701, 192, 636, 610, 139, 210, 155, 684, 135, 159, 418, 239, 397, 67, 171, 546, 595, 660, 480, 452, 361, 391, 766, 13, 177, 487, 127, 101, 467, 711, 602, 214, 248, 520, 263, 233, 68, 545, 381, 508, 649, 243, 438, 616, 638, 150, 123, 581, 129, 688, 613, 385, 405, 654, 220, 172, 536, 237, 402, 104, 449, 712, 623, 539, 674, 734, 433, 645, 478, 692, 658, 76, 446, 22, 468, 205, 768, 735, 303, 586, 64, 63, 296, 731, 333, 554, 421, 569, 499, 403, 492, 631, 268, 266, 182, 100, 583, 162, 367, 308, 555, 49, 519, 73, 689, 72, 702, 117, 409, 106, 217, 370, 90, 751, 412, 532, 314, 742, 204, 137, 374, 590, 195, 305, 488, 471, 19, 726, 228, 321, 359, 275, 437, 473, 415, 605, 168, 17, 285, 699, 286, 194, 128, 196, 244, 656, 538, 1, 80, 279, 670, 419, 291, 585, 653, 71, 358, 229, 432, 594, 592, 565, 666, 378, 313, 732, 108, 116, 687, 661, 634, 144, 407, 98, 725, 36, 280, 120, 15, 152, 601, 763, 379, 639, 464, 401, 611, 737, 230, 20, 436, 757, 252, 208, 404, 627, 558, 619, 676, 600, 202, 191, 422, 497, 439, 662, 665, 312, 607, 566, 58, 170, 693, 476, 213, 40, 767, 400, 715, 579, 318, 270, 124, 56, 57, 183, 506, 448, 624, 29, 398, 533, 769, 288, 721, 2, 434, 425, 140, 399, 92, 517, 593, 203, 423, 754, 35, 32, 236, 81, 612, 323, 663, 250, 720, 311, 386, 349, 84, 582, 542, 746, 635, 664, 745, 493, 685, 472, 200, 503, 578, 414, 698, 556, 59, 697, 575, 341, 113, 238, 646, 3, 460, 366, 158, 324, 655, 643, 759, 300, 626, 427, 673, 111, 281, 301, 677, 77, 368, 201, 83, 259, 344, 727, 50, 334, 648, 775, 241, 576, 470, 163, 463, 53, 47, 265, 441, 338, 562, 524, 371, 198, 89, 375, 573, 277, 131, 435, 511, 537, 154, 299, 78, 173, 747, 525, 490, 340, 133, 729, 380, 484, 695, 462, 560, 518, 772, 728, 534, 683, 617, 271, 377, 149, 119, 103, 185, 0, 764, 369, 444, 704, 33, 587, 282, 457, 342, 176, 218, 417, 564, 289, 608, 641, 295, 276, 516, 24, 209, 315, 773, 189, 247, 316, 502, 37, 603, 54, 14, 350, 221, 740, 703, 30, 256, 395, 390, 570, 426, 628, 317, 186, 596, 356, 547, 262, 717]\n",
            "Testing indices: [258, 11, 255, 232, 345, 384, 372, 723, 114, 500, 5, 625, 771, 96, 491, 507, 284, 659, 485, 85, 408, 187, 509, 722, 481, 652, 686, 514, 475, 461, 549, 261, 146, 360, 440, 269, 574, 548, 730, 7, 428, 161, 188, 716, 762, 530, 351, 733, 207, 589, 632, 348, 304, 706, 714, 552, 166, 597, 424, 134, 777, 39, 719, 121, 145, 694, 736, 411, 61, 644, 599, 620, 708, 637, 651, 521, 246, 642, 668, 224, 430, 93, 609, 363, 156, 283, 253, 451, 495, 690, 622, 242, 320, 319, 69, 429, 541, 456, 614, 748, 633, 147, 48, 394, 362, 4, 396, 41, 157, 91, 257, 346, 23, 553, 445, 267, 310, 193, 138, 512, 331, 535, 112, 455, 679, 591, 550, 606, 563, 46, 431, 290, 245, 227, 278, 761, 44, 357, 28, 355, 339, 691, 753, 325, 577, 240, 598, 406, 364, 55, 523, 354, 225, 141, 498]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [197, 474, 755, 302, 376, 175, 365, 388, 167, 179, 393, 126, 420, 477, 226, 680, 510, 51, 254, 724, 774, 629, 102, 551, 571, 336, 765, 16, 671, 383, 752, 142, 212, 184, 373, 776, 568, 136, 347, 115, 544, 231, 66, 329, 718, 443, 483, 387, 335, 750, 528, 739, 87, 62, 505, 332, 709, 559, 465, 65, 94, 273, 38, 97, 164, 389, 327, 615, 352, 657, 707, 109, 700, 696, 450, 647, 322, 274, 160, 572, 70, 454, 222, 174, 82, 486, 466, 489, 760, 181, 165, 234, 540, 330, 95, 459, 206, 75, 515, 151, 110, 618, 99, 8, 337, 216, 122, 529, 741, 169, 343, 621, 45, 442, 215, 543, 469, 504, 756, 501, 88, 86, 738, 682, 453, 588, 105, 447, 148, 260, 287, 584, 749, 458, 306, 744, 79, 199, 413, 382, 130, 43, 293, 27, 561, 12, 219, 669, 292, 107, 297, 494, 42, 580, 410, 249, 264, 10, 710, 52, 672, 294, 479, 25, 667, 118, 235, 125, 513, 353, 328, 650, 60, 74, 143, 309, 678, 178, 307, 557, 392, 522, 9, 681, 604, 190, 272, 567, 705, 630, 18, 640, 675, 326, 496, 180, 132, 527, 526, 31, 531, 223, 298, 6, 416, 482, 153, 713, 21, 758, 743, 251, 211, 34, 26, 770, 701, 192, 636, 610, 139, 210, 155, 684, 135, 159, 418, 239, 397, 67, 171, 546, 595, 660, 480, 452, 361, 391, 766, 13, 177, 487, 127, 101, 467, 711, 602, 214, 248, 520, 263, 233, 68, 545, 381, 508, 649, 243, 438, 616, 638, 150, 123, 581, 129, 688, 613, 385, 405, 654, 220, 172, 536, 237, 402, 104, 449, 712, 623, 539, 674, 734, 433, 645, 478, 692, 658, 76, 446, 22, 468, 205, 768, 735, 303, 586, 64, 63, 296, 731, 333, 554, 421, 569, 499, 403, 492, 631, 268, 266, 182, 100, 583, 162, 367, 308, 555, 49, 519, 73, 689, 72, 702, 117, 409, 106, 217, 370, 90, 751, 412, 532, 314, 742, 204, 137, 374, 590, 195, 305, 488, 471, 19, 726, 228, 321, 359, 275, 437, 473, 415, 605, 168, 17, 285, 699, 286, 194, 128, 196, 244, 656, 538, 1, 80, 279, 670, 419, 291, 585, 653, 71, 358, 229, 432, 594, 592, 565, 666, 378, 313, 732, 108, 116, 687, 661, 634, 144, 407, 98, 725, 36, 280, 120, 15, 152, 601, 763, 379, 639, 464, 401, 611, 737, 230, 20, 436, 757, 252, 208, 404, 627, 558, 619, 676, 600, 202, 191, 422, 497, 439, 662, 665, 312, 607, 566, 58, 170, 693, 476, 213, 40, 767, 400, 715, 579, 318, 270, 124, 56, 57, 183, 506, 448, 624, 29, 398, 533, 769, 288, 721, 2, 434, 425, 140, 399, 92, 517, 593, 203, 423, 754, 35, 32, 236, 81, 612, 323, 258, 11, 255, 232, 345, 384, 372, 723, 114, 500, 5, 625, 771, 96, 491, 507, 284, 659, 485, 85, 408, 187, 509, 722, 481, 652, 686, 514, 475, 461, 549, 261, 146, 360, 440, 269, 574, 548, 730, 7, 428, 161, 188, 716, 762, 530, 351, 733, 207, 589, 632, 348, 304, 706, 714, 552, 166, 597, 424, 134, 777, 39, 719, 121, 145, 694, 736, 411, 61, 644, 599, 620, 708, 637, 651, 521, 246, 642, 668, 224, 430, 93, 609, 363, 156, 283, 253, 451, 495, 690, 622, 242, 320, 319, 69, 429, 541, 456, 614, 748, 633, 147, 48, 394, 362, 4, 396, 41, 157, 91, 257, 346, 23, 553, 445, 267, 310, 193, 138, 512, 331, 535, 112, 455, 679, 591, 550, 606, 563, 46, 431, 290, 245, 227, 278, 761, 44, 357, 28, 355, 339, 691, 753, 325, 577, 240, 598, 406, 364, 55, 523, 354, 225, 141, 498]\n",
            "Testing indices: [663, 250, 720, 311, 386, 349, 84, 582, 542, 746, 635, 664, 745, 493, 685, 472, 200, 503, 578, 414, 698, 556, 59, 697, 575, 341, 113, 238, 646, 3, 460, 366, 158, 324, 655, 643, 759, 300, 626, 427, 673, 111, 281, 301, 677, 77, 368, 201, 83, 259, 344, 727, 50, 334, 648, 775, 241, 576, 470, 163, 463, 53, 47, 265, 441, 338, 562, 524, 371, 198, 89, 375, 573, 277, 131, 435, 511, 537, 154, 299, 78, 173, 747, 525, 490, 340, 133, 729, 380, 484, 695, 462, 560, 518, 772, 728, 534, 683, 617, 271, 377, 149, 119, 103, 185, 0, 764, 369, 444, 704, 33, 587, 282, 457, 342, 176, 218, 417, 564, 289, 608, 641, 295, 276, 516, 24, 209, 315, 773, 189, 247, 316, 502, 37, 603, 54, 14, 350, 221, 740, 703, 30, 256, 395, 390, 570, 426, 628, 317, 186, 596, 356, 547, 262, 717]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [31, 160, 194, 11, 112, 188, 110, 2, 128, 119, 38, 8, 124, 57, 101, 66, 46, 109, 134, 68, 44, 139, 175, 92, 121, 153, 60, 4, 85, 151, 30, 169, 74, 94, 138, 177, 64, 117, 41, 61, 154, 150, 136, 193, 17, 26, 7, 76, 39, 180, 108, 178, 93, 1, 33, 120, 82, 90, 102, 48, 116, 52, 84, 72, 9, 172, 130, 149, 181, 122, 75, 185, 43, 159, 0, 87, 16, 51, 189, 168, 192, 111, 54, 133, 106, 147, 77, 100, 63, 56, 53, 99, 86, 183, 158, 114, 123, 23, 27, 97, 103, 165, 49, 5, 167, 131, 171, 88, 105, 157, 182, 24, 65, 148, 107, 28, 115, 164, 95, 98, 91, 144, 127, 129, 166, 142, 6, 143, 79, 59, 22, 25, 176, 40, 18, 12, 155, 163, 174, 145, 21, 78, 173, 32, 10, 156, 34, 161, 170, 186, 187, 3, 35, 37, 184, 13]\n",
            "Testing indices: [55, 83, 190, 50, 42, 69, 179, 104, 80, 113, 29, 73, 47, 118, 19, 58, 36, 152, 96, 132, 81, 141, 137, 191, 135, 146, 14, 71, 20, 70, 125, 45, 62, 15, 126, 89, 140, 162, 67]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [55, 83, 190, 50, 42, 69, 179, 104, 80, 113, 29, 73, 47, 118, 19, 58, 36, 152, 96, 132, 81, 141, 137, 191, 135, 146, 14, 71, 20, 70, 125, 45, 62, 15, 126, 89, 140, 162, 67, 61, 154, 150, 136, 193, 17, 26, 7, 76, 39, 180, 108, 178, 93, 1, 33, 120, 82, 90, 102, 48, 116, 52, 84, 72, 9, 172, 130, 149, 181, 122, 75, 185, 43, 159, 0, 87, 16, 51, 189, 168, 192, 111, 54, 133, 106, 147, 77, 100, 63, 56, 53, 99, 86, 183, 158, 114, 123, 23, 27, 97, 103, 165, 49, 5, 167, 131, 171, 88, 105, 157, 182, 24, 65, 148, 107, 28, 115, 164, 95, 98, 91, 144, 127, 129, 166, 142, 6, 143, 79, 59, 22, 25, 176, 40, 18, 12, 155, 163, 174, 145, 21, 78, 173, 32, 10, 156, 34, 161, 170, 186, 187, 3, 35, 37, 184, 13]\n",
            "Testing indices: [31, 160, 194, 11, 112, 188, 110, 2, 128, 119, 38, 8, 124, 57, 101, 66, 46, 109, 134, 68, 44, 139, 175, 92, 121, 153, 60, 4, 85, 151, 30, 169, 74, 94, 138, 177, 64, 117, 41]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [55, 83, 190, 50, 42, 69, 179, 104, 80, 113, 29, 73, 47, 118, 19, 58, 36, 152, 96, 132, 81, 141, 137, 191, 135, 146, 14, 71, 20, 70, 125, 45, 62, 15, 126, 89, 140, 162, 67, 31, 160, 194, 11, 112, 188, 110, 2, 128, 119, 38, 8, 124, 57, 101, 66, 46, 109, 134, 68, 44, 139, 175, 92, 121, 153, 60, 4, 85, 151, 30, 169, 74, 94, 138, 177, 64, 117, 41, 189, 168, 192, 111, 54, 133, 106, 147, 77, 100, 63, 56, 53, 99, 86, 183, 158, 114, 123, 23, 27, 97, 103, 165, 49, 5, 167, 131, 171, 88, 105, 157, 182, 24, 65, 148, 107, 28, 115, 164, 95, 98, 91, 144, 127, 129, 166, 142, 6, 143, 79, 59, 22, 25, 176, 40, 18, 12, 155, 163, 174, 145, 21, 78, 173, 32, 10, 156, 34, 161, 170, 186, 187, 3, 35, 37, 184, 13]\n",
            "Testing indices: [61, 154, 150, 136, 193, 17, 26, 7, 76, 39, 180, 108, 178, 93, 1, 33, 120, 82, 90, 102, 48, 116, 52, 84, 72, 9, 172, 130, 149, 181, 122, 75, 185, 43, 159, 0, 87, 16, 51]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [55, 83, 190, 50, 42, 69, 179, 104, 80, 113, 29, 73, 47, 118, 19, 58, 36, 152, 96, 132, 81, 141, 137, 191, 135, 146, 14, 71, 20, 70, 125, 45, 62, 15, 126, 89, 140, 162, 67, 31, 160, 194, 11, 112, 188, 110, 2, 128, 119, 38, 8, 124, 57, 101, 66, 46, 109, 134, 68, 44, 139, 175, 92, 121, 153, 60, 4, 85, 151, 30, 169, 74, 94, 138, 177, 64, 117, 41, 61, 154, 150, 136, 193, 17, 26, 7, 76, 39, 180, 108, 178, 93, 1, 33, 120, 82, 90, 102, 48, 116, 52, 84, 72, 9, 172, 130, 149, 181, 122, 75, 185, 43, 159, 0, 87, 16, 51, 164, 95, 98, 91, 144, 127, 129, 166, 142, 6, 143, 79, 59, 22, 25, 176, 40, 18, 12, 155, 163, 174, 145, 21, 78, 173, 32, 10, 156, 34, 161, 170, 186, 187, 3, 35, 37, 184, 13]\n",
            "Testing indices: [189, 168, 192, 111, 54, 133, 106, 147, 77, 100, 63, 56, 53, 99, 86, 183, 158, 114, 123, 23, 27, 97, 103, 165, 49, 5, 167, 131, 171, 88, 105, 157, 182, 24, 65, 148, 107, 28, 115]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [55, 83, 190, 50, 42, 69, 179, 104, 80, 113, 29, 73, 47, 118, 19, 58, 36, 152, 96, 132, 81, 141, 137, 191, 135, 146, 14, 71, 20, 70, 125, 45, 62, 15, 126, 89, 140, 162, 67, 31, 160, 194, 11, 112, 188, 110, 2, 128, 119, 38, 8, 124, 57, 101, 66, 46, 109, 134, 68, 44, 139, 175, 92, 121, 153, 60, 4, 85, 151, 30, 169, 74, 94, 138, 177, 64, 117, 41, 61, 154, 150, 136, 193, 17, 26, 7, 76, 39, 180, 108, 178, 93, 1, 33, 120, 82, 90, 102, 48, 116, 52, 84, 72, 9, 172, 130, 149, 181, 122, 75, 185, 43, 159, 0, 87, 16, 51, 189, 168, 192, 111, 54, 133, 106, 147, 77, 100, 63, 56, 53, 99, 86, 183, 158, 114, 123, 23, 27, 97, 103, 165, 49, 5, 167, 131, 171, 88, 105, 157, 182, 24, 65, 148, 107, 28, 115]\n",
            "Testing indices: [164, 95, 98, 91, 144, 127, 129, 166, 142, 6, 143, 79, 59, 22, 25, 176, 40, 18, 12, 155, 163, 174, 145, 21, 78, 173, 32, 10, 156, 34, 161, 170, 186, 187, 3, 35, 37, 184, 13]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "--------- Iteration 1 ---------\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 28,  0,  0],\n",
            "       [ 0, 69,  0,  0],\n",
            "       [ 0, 50,  0,  0],\n",
            "       [ 0,  9,  0,  0]]), array([[ 0, 32,  0,  0],\n",
            "       [ 0, 75,  0,  0],\n",
            "       [ 0, 38,  0,  0],\n",
            "       [ 0, 11,  0,  0]]), array([[ 0, 34,  0,  0],\n",
            "       [ 0, 72,  0,  0],\n",
            "       [ 0, 38,  0,  0],\n",
            "       [ 0, 12,  0,  0]]), array([[ 0, 39,  0,  0],\n",
            "       [ 0, 71,  0,  0],\n",
            "       [ 0, 35,  0,  0],\n",
            "       [ 0, 10,  0,  0]]), array([[ 0, 46,  0,  0],\n",
            "       [ 0, 55,  0,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0,  9,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        28\\n          a2    0.44231   1.00000   0.61333        69\\n          a3    0.00000   0.00000   0.00000        50\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.44231       156\\n   macro avg    0.11058   0.25000   0.15333       156\\nweighted avg    0.19564   0.44231   0.27128       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        32\\n          a2    0.48077   1.00000   0.64935        75\\n          a3    0.00000   0.00000   0.00000        38\\n         a35    0.00000   0.00000   0.00000        11\\n\\n    accuracy                        0.48077       156\\n   macro avg    0.12019   0.25000   0.16234       156\\nweighted avg    0.23114   0.48077   0.31219       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        34\\n          a2    0.46154   1.00000   0.63158        72\\n          a3    0.00000   0.00000   0.00000        38\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.46154       156\\n   macro avg    0.11538   0.25000   0.15789       156\\nweighted avg    0.21302   0.46154   0.29150       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        39\\n          a2    0.45806   1.00000   0.62832        71\\n          a3    0.00000   0.00000   0.00000        35\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.45806       155\\n   macro avg    0.11452   0.25000   0.15708       155\\nweighted avg    0.20982   0.45806   0.28781       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        46\\n          a2    0.35484   1.00000   0.52381        55\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.35484       155\\n   macro avg    0.08871   0.25000   0.13095       155\\nweighted avg    0.12591   0.35484   0.18587       155\\n']\n",
            "Mean Accuracy: 0.4395037220843673\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 28,  0,  0],\n",
            "       [ 0, 67,  2,  0],\n",
            "       [ 0, 50,  0,  0],\n",
            "       [ 0,  6,  3,  0]]), array([[ 1, 30,  1,  0],\n",
            "       [ 4, 70,  1,  0],\n",
            "       [ 0, 36,  2,  0],\n",
            "       [ 0, 11,  0,  0]]), array([[ 1, 33,  0,  0],\n",
            "       [ 1, 70,  1,  0],\n",
            "       [ 1, 34,  3,  0],\n",
            "       [ 1, 11,  0,  0]]), array([[ 2, 35,  2,  0],\n",
            "       [ 5, 65,  1,  0],\n",
            "       [ 2, 31,  2,  0],\n",
            "       [ 0,  9,  1,  0]]), array([[ 0, 45,  1,  0],\n",
            "       [ 0, 55,  0,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0,  9,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        28\\n          a2    0.44371   0.97101   0.60909        69\\n          a3    0.00000   0.00000   0.00000        50\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.42949       156\\n   macro avg    0.11093   0.24275   0.15227       156\\nweighted avg    0.19626   0.42949   0.26941       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.20000   0.03125   0.05405        32\\n          a2    0.47619   0.93333   0.63063        75\\n          a3    0.50000   0.05263   0.09524        38\\n         a35    0.00000   0.00000   0.00000        11\\n\\n    accuracy                        0.46795       156\\n   macro avg    0.29405   0.25430   0.19498       156\\nweighted avg    0.39176   0.46795   0.33747       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.25000   0.02941   0.05263        34\\n          a2    0.47297   0.97222   0.63636        72\\n          a3    0.75000   0.07895   0.14286        38\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.47436       156\\n   macro avg    0.36824   0.27015   0.20796       156\\nweighted avg    0.45547   0.47436   0.33998       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.22222   0.05128   0.08333        39\\n          a2    0.46429   0.91549   0.61611        71\\n          a3    0.33333   0.05714   0.09756        35\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.44516       155\\n   macro avg    0.25496   0.25598   0.19925       155\\nweighted avg    0.34386   0.44516   0.32522       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        46\\n          a2    0.35714   1.00000   0.52632        55\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.35484       155\\n   macro avg    0.08929   0.25000   0.13158       155\\nweighted avg    0.12673   0.35484   0.18676       155\\n']\n",
            "Mean Accuracy: 0.4343589743589744\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[10, 13,  5,  0],\n",
            "       [14, 29, 21,  5],\n",
            "       [ 9, 17, 19,  5],\n",
            "       [ 0,  5,  3,  1]]), array([[11, 12,  8,  1],\n",
            "       [22, 27, 23,  3],\n",
            "       [ 4, 21, 11,  2],\n",
            "       [ 5,  1,  3,  2]]), array([[ 7, 20,  5,  2],\n",
            "       [17, 25, 26,  4],\n",
            "       [ 7, 19, 10,  2],\n",
            "       [ 3,  6,  3,  0]]), array([[15, 15,  8,  1],\n",
            "       [21, 29, 16,  5],\n",
            "       [ 7, 17, 10,  1],\n",
            "       [ 2,  4,  1,  3]]), array([[13, 23,  8,  2],\n",
            "       [13, 25, 10,  7],\n",
            "       [ 8, 22, 12,  3],\n",
            "       [ 0,  6,  2,  1]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.30303   0.35714   0.32787        28\\n          a2    0.45312   0.42029   0.43609        69\\n          a3    0.39583   0.38000   0.38776        50\\n         a35    0.09091   0.11111   0.10000         9\\n\\n    accuracy                        0.37821       156\\n   macro avg    0.31072   0.31714   0.31293       156\\nweighted avg    0.38693   0.37821   0.38178       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.26190   0.34375   0.29730        32\\n          a2    0.44262   0.36000   0.39706        75\\n          a3    0.24444   0.28947   0.26506        38\\n         a35    0.25000   0.18182   0.21053        11\\n\\n    accuracy                        0.32692       156\\n   macro avg    0.29974   0.29376   0.29249       156\\nweighted avg    0.34370   0.32692   0.33129       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.20588   0.20588   0.20588        34\\n          a2    0.35714   0.34722   0.35211        72\\n          a3    0.22727   0.26316   0.24390        38\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.26923       156\\n   macro avg    0.19757   0.20407   0.20047       156\\nweighted avg    0.26507   0.26923   0.26680       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.33333   0.38462   0.35714        39\\n          a2    0.44615   0.40845   0.42647        71\\n          a3    0.28571   0.28571   0.28571        35\\n         a35    0.30000   0.30000   0.30000        10\\n\\n    accuracy                        0.36774       155\\n   macro avg    0.34130   0.34470   0.34233       155\\nweighted avg    0.37211   0.36774   0.36908       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.38235   0.28261   0.32500        46\\n          a2    0.32895   0.45455   0.38168        55\\n          a3    0.37500   0.26667   0.31169        45\\n         a35    0.07692   0.11111   0.09091         9\\n\\n    accuracy                        0.32903       155\\n   macro avg    0.29081   0.27873   0.27732       155\\nweighted avg    0.34353   0.32903   0.32765       155\\n']\n",
            "Mean Accuracy: 0.33422663358147225\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 11,  0,  0],\n",
            "       [ 0, 21,  0,  0],\n",
            "       [ 0,  6,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0,  9,  0,  0],\n",
            "       [ 0, 17,  0,  0],\n",
            "       [ 0, 11,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0,  8,  0,  0],\n",
            "       [ 0, 18,  0,  0],\n",
            "       [ 0, 10,  0,  0],\n",
            "       [ 0,  3,  0,  0]]), array([[ 0, 10,  0],\n",
            "       [ 0, 21,  0],\n",
            "       [ 0,  8,  0]]), array([[ 0,  7,  0,  0],\n",
            "       [ 0, 20,  0,  0],\n",
            "       [ 0,  8,  0,  0],\n",
            "       [ 0,  4,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        11\\n          a2    0.53846   1.00000   0.70000        21\\n          a3    0.00000   0.00000   0.00000         6\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.53846        39\\n   macro avg    0.13462   0.25000   0.17500        39\\nweighted avg    0.28994   0.53846   0.37692        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         9\\n          a2    0.43590   1.00000   0.60714        17\\n          a3    0.00000   0.00000   0.00000        11\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.43590        39\\n   macro avg    0.10897   0.25000   0.15179        39\\nweighted avg    0.19001   0.43590   0.26465        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         8\\n          a2    0.46154   1.00000   0.63158        18\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11538   0.25000   0.15789        39\\nweighted avg    0.21302   0.46154   0.29150        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        10\\n          a2    0.53846   1.00000   0.70000        21\\n          a3    0.00000   0.00000   0.00000         8\\n         a35    0.00000   0.00000   0.00000         0\\n\\n   micro avg    0.53846   0.53846   0.53846        39\\n   macro avg    0.13462   0.25000   0.17500        39\\nweighted avg    0.28994   0.53846   0.37692        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         7\\n          a2    0.51282   1.00000   0.67797        20\\n          a3    0.00000   0.00000   0.00000         8\\n         a35    0.00000   0.00000   0.00000         4\\n\\n    accuracy                        0.51282        39\\n   macro avg    0.12821   0.25000   0.16949        39\\nweighted avg    0.26298   0.51282   0.34767        39\\n']\n",
            "Mean Accuracy: 0.49743589743589745\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 11,  0,  0],\n",
            "       [ 0, 21,  0,  0],\n",
            "       [ 0,  6,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0,  9,  0,  0],\n",
            "       [ 0, 17,  0,  0],\n",
            "       [ 0, 11,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0,  8,  0,  0],\n",
            "       [ 0, 18,  0,  0],\n",
            "       [ 0, 10,  0,  0],\n",
            "       [ 0,  3,  0,  0]]), array([[ 0, 10,  0],\n",
            "       [ 0, 21,  0],\n",
            "       [ 0,  8,  0]]), array([[ 0,  7,  0,  0],\n",
            "       [ 0, 20,  0,  0],\n",
            "       [ 0,  8,  0,  0],\n",
            "       [ 0,  4,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        11\\n          a2    0.53846   1.00000   0.70000        21\\n          a3    0.00000   0.00000   0.00000         6\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.53846        39\\n   macro avg    0.13462   0.25000   0.17500        39\\nweighted avg    0.28994   0.53846   0.37692        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         9\\n          a2    0.43590   1.00000   0.60714        17\\n          a3    0.00000   0.00000   0.00000        11\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.43590        39\\n   macro avg    0.10897   0.25000   0.15179        39\\nweighted avg    0.19001   0.43590   0.26465        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         8\\n          a2    0.46154   1.00000   0.63158        18\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11538   0.25000   0.15789        39\\nweighted avg    0.21302   0.46154   0.29150        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        10\\n          a2    0.53846   1.00000   0.70000        21\\n          a3    0.00000   0.00000   0.00000         8\\n         a35    0.00000   0.00000   0.00000         0\\n\\n   micro avg    0.53846   0.53846   0.53846        39\\n   macro avg    0.13462   0.25000   0.17500        39\\nweighted avg    0.28994   0.53846   0.37692        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         7\\n          a2    0.51282   1.00000   0.67797        20\\n          a3    0.00000   0.00000   0.00000         8\\n         a35    0.00000   0.00000   0.00000         4\\n\\n    accuracy                        0.51282        39\\n   macro avg    0.12821   0.25000   0.16949        39\\nweighted avg    0.26298   0.51282   0.34767        39\\n']\n",
            "Mean Accuracy: 0.49743589743589745\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[2, 6, 3, 0],\n",
            "       [4, 9, 6, 2],\n",
            "       [2, 2, 2, 0],\n",
            "       [0, 1, 0, 0]]), array([[2, 5, 2, 0],\n",
            "       [3, 9, 4, 1],\n",
            "       [2, 7, 1, 1],\n",
            "       [0, 0, 2, 0]]), array([[1, 7, 0, 0],\n",
            "       [6, 6, 2, 4],\n",
            "       [2, 7, 1, 0],\n",
            "       [0, 1, 2, 0]]), array([[ 3,  4,  3,  0],\n",
            "       [ 2, 14,  4,  1],\n",
            "       [ 2,  3,  3,  0],\n",
            "       [ 0,  0,  0,  0]]), array([[ 2,  1,  4,  0],\n",
            "       [ 3, 10,  5,  2],\n",
            "       [ 1,  4,  1,  2],\n",
            "       [ 0,  3,  1,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.25000   0.18182   0.21053        11\\n          a2    0.50000   0.42857   0.46154        21\\n          a3    0.18182   0.33333   0.23529         6\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.33333        39\\n   macro avg    0.23295   0.23593   0.22684        39\\nweighted avg    0.36772   0.33333   0.34410        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.28571   0.22222   0.25000         9\\n          a2    0.42857   0.52941   0.47368        17\\n          a3    0.11111   0.09091   0.10000        11\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.30769        39\\n   macro avg    0.20635   0.21064   0.20592        39\\nweighted avg    0.28409   0.30769   0.29238        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.11111   0.12500   0.11765         8\\n          a2    0.28571   0.33333   0.30769        18\\n          a3    0.20000   0.10000   0.13333        10\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.20513        39\\n   macro avg    0.14921   0.13958   0.13967        39\\nweighted avg    0.20594   0.20513   0.20033        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.42857   0.30000   0.35294        10\\n          a2    0.66667   0.66667   0.66667        21\\n          a3    0.30000   0.37500   0.33333         8\\n         a35    0.00000   0.00000   0.00000         0\\n\\n    accuracy                        0.51282        39\\n   macro avg    0.34881   0.33542   0.33824        39\\nweighted avg    0.53040   0.51282   0.51785        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.33333   0.28571   0.30769         7\\n          a2    0.55556   0.50000   0.52632        20\\n          a3    0.09091   0.12500   0.10526         8\\n         a35    0.00000   0.00000   0.00000         4\\n\\n    accuracy                        0.33333        39\\n   macro avg    0.24495   0.22768   0.23482        39\\nweighted avg    0.36338   0.33333   0.34672        39\\n']\n",
            "Mean Accuracy: 0.3384615384615384\n",
            "--------- End of Iteration ---------\n",
            "\n",
            "Training indices: [626, 402, 733, 228, 599, 253, 484, 645, 91, 382, 70, 633, 126, 8, 663, 494, 666, 739, 546, 138, 441, 684, 335, 29, 590, 447, 231, 707, 539, 425, 731, 536, 612, 195, 280, 771, 698, 15, 108, 719, 742, 535, 437, 718, 727, 652, 137, 220, 525, 193, 159, 0, 325, 52, 367, 589, 513, 614, 315, 729, 655, 657, 649, 123, 398, 90, 371, 573, 394, 346, 246, 189, 229, 465, 528, 342, 321, 133, 104, 715, 71, 188, 74, 407, 524, 503, 395, 302, 347, 26, 638, 624, 202, 512, 617, 116, 487, 518, 365, 713, 519, 53, 375, 386, 482, 497, 543, 54, 178, 417, 591, 583, 777, 218, 477, 344, 463, 272, 362, 355, 256, 470, 314, 33, 744, 696, 379, 277, 6, 726, 168, 163, 569, 625, 306, 444, 164, 506, 568, 743, 533, 690, 65, 219, 610, 704, 269, 267, 670, 77, 661, 192, 295, 94, 32, 592, 120, 516, 756, 476, 570, 57, 88, 555, 130, 39, 131, 96, 150, 445, 155, 372, 318, 558, 390, 750, 2, 594, 105, 762, 728, 412, 140, 338, 471, 640, 611, 42, 276, 748, 461, 636, 233, 737, 239, 139, 86, 370, 549, 283, 488, 25, 768, 103, 317, 345, 205, 587, 688, 440, 683, 262, 263, 738, 735, 616, 479, 281, 76, 305, 66, 211, 359, 327, 24, 151, 296, 464, 393, 9, 165, 759, 493, 654, 629, 456, 409, 450, 326, 521, 288, 763, 210, 222, 723, 404, 217, 250, 117, 451, 540, 242, 265, 227, 241, 106, 561, 391, 773, 428, 357, 740, 135, 430, 725, 693, 469, 551, 554, 563, 747, 537, 579, 419, 251, 7, 259, 361, 182, 557, 113, 49, 622, 1, 647, 605, 118, 225, 597, 145, 261, 699, 360, 651, 635, 712, 517, 459, 439, 258, 134, 132, 19, 144, 653, 720, 167, 366, 667, 254, 174, 299, 529, 764, 183, 67, 341, 432, 571, 285, 266, 486, 527, 442, 467, 406, 364, 603, 523, 300, 596, 35, 101, 545, 385, 397, 112, 284, 716, 681, 734, 4, 38, 170, 634, 562, 73, 237, 198, 547, 187, 593, 363, 548, 330, 343, 141, 232, 109, 45, 578, 659, 502, 61, 566, 775, 730, 498, 662, 185, 776, 403, 505, 373, 337, 177, 384, 312, 410, 413, 618, 602, 722, 64, 358, 286, 708, 352, 339, 411, 392, 316, 68, 650, 598, 190, 559, 507, 774, 264, 601, 351, 758, 607, 207, 606, 702, 107, 499, 531, 23, 538, 585, 436, 426, 710, 95, 154, 196, 197, 184, 478, 452, 176, 694, 575, 100, 12, 17, 460, 334, 160, 158, 216, 706, 414, 746, 619, 541, 82, 692, 462, 323, 282, 146, 405, 5, 340, 489, 152, 658, 309, 627, 466, 353, 677, 129, 481, 396, 757, 128, 89, 480, 553, 574, 754, 675, 255, 201, 676, 181, 97, 69, 311, 34, 13, 223, 125, 43, 350, 400, 21, 291, 665, 208, 532, 63, 142, 60, 492, 55, 565, 240, 695, 235, 224, 297, 560, 59, 149, 273, 454, 31, 268, 556, 582, 244, 22, 383, 686, 62, 79, 279, 613, 586, 564, 249, 83, 115, 119, 41, 27, 333, 307, 127, 669, 495, 186, 438, 772, 767, 252, 98, 749, 760, 765, 584, 204, 600, 329, 11, 745, 515, 3, 46, 212, 292, 44, 153, 147, 577, 294, 173, 448, 20, 514, 226, 639, 247, 608, 320, 483, 648, 700, 293, 420, 509, 37, 431, 213, 377, 166, 36, 93, 84, 604, 156, 446, 674, 47, 679, 336, 501, 157, 588, 369, 172, 243, 423, 18, 376, 632, 271, 206, 458, 289, 544, 191, 741, 80, 399, 48, 303, 78, 162, 110, 522, 349, 421, 641, 753, 72, 703, 136, 542, 572, 16, 630, 717, 511, 102, 301]\n",
            "Testing indices: [680, 646, 534, 194, 304, 290, 81, 526, 485, 736, 678, 354, 609, 429, 628, 770, 378, 111, 550, 701, 490, 169, 274, 180, 714, 30, 389, 671, 724, 387, 161, 721, 709, 755, 368, 689, 457, 238, 766, 260, 308, 711, 298, 58, 179, 50, 99, 552, 581, 278, 148, 322, 324, 697, 380, 530, 576, 500, 356, 416, 623, 473, 769, 472, 331, 673, 348, 418, 453, 637, 449, 491, 313, 319, 381, 236, 751, 287, 435, 230, 732, 203, 672, 40, 631, 415, 87, 248, 752, 567, 685, 443, 580, 408, 257, 28, 388, 761, 615, 656, 475, 270, 468, 221, 595, 520, 705, 122, 504, 434, 643, 214, 620, 199, 508, 644, 621, 510, 687, 75, 56, 455, 401, 143, 275, 332, 234, 433, 474, 496, 14, 374, 200, 124, 121, 660, 175, 215, 245, 664, 209, 51, 171, 668, 114, 691, 424, 10, 642, 328, 427, 310, 422, 92, 85, 682]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [680, 646, 534, 194, 304, 290, 81, 526, 485, 736, 678, 354, 609, 429, 628, 770, 378, 111, 550, 701, 490, 169, 274, 180, 714, 30, 389, 671, 724, 387, 161, 721, 709, 755, 368, 689, 457, 238, 766, 260, 308, 711, 298, 58, 179, 50, 99, 552, 581, 278, 148, 322, 324, 697, 380, 530, 576, 500, 356, 416, 623, 473, 769, 472, 331, 673, 348, 418, 453, 637, 449, 491, 313, 319, 381, 236, 751, 287, 435, 230, 732, 203, 672, 40, 631, 415, 87, 248, 752, 567, 685, 443, 580, 408, 257, 28, 388, 761, 615, 656, 475, 270, 468, 221, 595, 520, 705, 122, 504, 434, 643, 214, 620, 199, 508, 644, 621, 510, 687, 75, 56, 455, 401, 143, 275, 332, 234, 433, 474, 496, 14, 374, 200, 124, 121, 660, 175, 215, 245, 664, 209, 51, 171, 668, 114, 691, 424, 10, 642, 328, 427, 310, 422, 92, 85, 682, 120, 516, 756, 476, 570, 57, 88, 555, 130, 39, 131, 96, 150, 445, 155, 372, 318, 558, 390, 750, 2, 594, 105, 762, 728, 412, 140, 338, 471, 640, 611, 42, 276, 748, 461, 636, 233, 737, 239, 139, 86, 370, 549, 283, 488, 25, 768, 103, 317, 345, 205, 587, 688, 440, 683, 262, 263, 738, 735, 616, 479, 281, 76, 305, 66, 211, 359, 327, 24, 151, 296, 464, 393, 9, 165, 759, 493, 654, 629, 456, 409, 450, 326, 521, 288, 763, 210, 222, 723, 404, 217, 250, 117, 451, 540, 242, 265, 227, 241, 106, 561, 391, 773, 428, 357, 740, 135, 430, 725, 693, 469, 551, 554, 563, 747, 537, 579, 419, 251, 7, 259, 361, 182, 557, 113, 49, 622, 1, 647, 605, 118, 225, 597, 145, 261, 699, 360, 651, 635, 712, 517, 459, 439, 258, 134, 132, 19, 144, 653, 720, 167, 366, 667, 254, 174, 299, 529, 764, 183, 67, 341, 432, 571, 285, 266, 486, 527, 442, 467, 406, 364, 603, 523, 300, 596, 35, 101, 545, 385, 397, 112, 284, 716, 681, 734, 4, 38, 170, 634, 562, 73, 237, 198, 547, 187, 593, 363, 548, 330, 343, 141, 232, 109, 45, 578, 659, 502, 61, 566, 775, 730, 498, 662, 185, 776, 403, 505, 373, 337, 177, 384, 312, 410, 413, 618, 602, 722, 64, 358, 286, 708, 352, 339, 411, 392, 316, 68, 650, 598, 190, 559, 507, 774, 264, 601, 351, 758, 607, 207, 606, 702, 107, 499, 531, 23, 538, 585, 436, 426, 710, 95, 154, 196, 197, 184, 478, 452, 176, 694, 575, 100, 12, 17, 460, 334, 160, 158, 216, 706, 414, 746, 619, 541, 82, 692, 462, 323, 282, 146, 405, 5, 340, 489, 152, 658, 309, 627, 466, 353, 677, 129, 481, 396, 757, 128, 89, 480, 553, 574, 754, 675, 255, 201, 676, 181, 97, 69, 311, 34, 13, 223, 125, 43, 350, 400, 21, 291, 665, 208, 532, 63, 142, 60, 492, 55, 565, 240, 695, 235, 224, 297, 560, 59, 149, 273, 454, 31, 268, 556, 582, 244, 22, 383, 686, 62, 79, 279, 613, 586, 564, 249, 83, 115, 119, 41, 27, 333, 307, 127, 669, 495, 186, 438, 772, 767, 252, 98, 749, 760, 765, 584, 204, 600, 329, 11, 745, 515, 3, 46, 212, 292, 44, 153, 147, 577, 294, 173, 448, 20, 514, 226, 639, 247, 608, 320, 483, 648, 700, 293, 420, 509, 37, 431, 213, 377, 166, 36, 93, 84, 604, 156, 446, 674, 47, 679, 336, 501, 157, 588, 369, 172, 243, 423, 18, 376, 632, 271, 206, 458, 289, 544, 191, 741, 80, 399, 48, 303, 78, 162, 110, 522, 349, 421, 641, 753, 72, 703, 136, 542, 572, 16, 630, 717, 511, 102, 301]\n",
            "Testing indices: [626, 402, 733, 228, 599, 253, 484, 645, 91, 382, 70, 633, 126, 8, 663, 494, 666, 739, 546, 138, 441, 684, 335, 29, 590, 447, 231, 707, 539, 425, 731, 536, 612, 195, 280, 771, 698, 15, 108, 719, 742, 535, 437, 718, 727, 652, 137, 220, 525, 193, 159, 0, 325, 52, 367, 589, 513, 614, 315, 729, 655, 657, 649, 123, 398, 90, 371, 573, 394, 346, 246, 189, 229, 465, 528, 342, 321, 133, 104, 715, 71, 188, 74, 407, 524, 503, 395, 302, 347, 26, 638, 624, 202, 512, 617, 116, 487, 518, 365, 713, 519, 53, 375, 386, 482, 497, 543, 54, 178, 417, 591, 583, 777, 218, 477, 344, 463, 272, 362, 355, 256, 470, 314, 33, 744, 696, 379, 277, 6, 726, 168, 163, 569, 625, 306, 444, 164, 506, 568, 743, 533, 690, 65, 219, 610, 704, 269, 267, 670, 77, 661, 192, 295, 94, 32, 592]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [680, 646, 534, 194, 304, 290, 81, 526, 485, 736, 678, 354, 609, 429, 628, 770, 378, 111, 550, 701, 490, 169, 274, 180, 714, 30, 389, 671, 724, 387, 161, 721, 709, 755, 368, 689, 457, 238, 766, 260, 308, 711, 298, 58, 179, 50, 99, 552, 581, 278, 148, 322, 324, 697, 380, 530, 576, 500, 356, 416, 623, 473, 769, 472, 331, 673, 348, 418, 453, 637, 449, 491, 313, 319, 381, 236, 751, 287, 435, 230, 732, 203, 672, 40, 631, 415, 87, 248, 752, 567, 685, 443, 580, 408, 257, 28, 388, 761, 615, 656, 475, 270, 468, 221, 595, 520, 705, 122, 504, 434, 643, 214, 620, 199, 508, 644, 621, 510, 687, 75, 56, 455, 401, 143, 275, 332, 234, 433, 474, 496, 14, 374, 200, 124, 121, 660, 175, 215, 245, 664, 209, 51, 171, 668, 114, 691, 424, 10, 642, 328, 427, 310, 422, 92, 85, 682, 626, 402, 733, 228, 599, 253, 484, 645, 91, 382, 70, 633, 126, 8, 663, 494, 666, 739, 546, 138, 441, 684, 335, 29, 590, 447, 231, 707, 539, 425, 731, 536, 612, 195, 280, 771, 698, 15, 108, 719, 742, 535, 437, 718, 727, 652, 137, 220, 525, 193, 159, 0, 325, 52, 367, 589, 513, 614, 315, 729, 655, 657, 649, 123, 398, 90, 371, 573, 394, 346, 246, 189, 229, 465, 528, 342, 321, 133, 104, 715, 71, 188, 74, 407, 524, 503, 395, 302, 347, 26, 638, 624, 202, 512, 617, 116, 487, 518, 365, 713, 519, 53, 375, 386, 482, 497, 543, 54, 178, 417, 591, 583, 777, 218, 477, 344, 463, 272, 362, 355, 256, 470, 314, 33, 744, 696, 379, 277, 6, 726, 168, 163, 569, 625, 306, 444, 164, 506, 568, 743, 533, 690, 65, 219, 610, 704, 269, 267, 670, 77, 661, 192, 295, 94, 32, 592, 529, 764, 183, 67, 341, 432, 571, 285, 266, 486, 527, 442, 467, 406, 364, 603, 523, 300, 596, 35, 101, 545, 385, 397, 112, 284, 716, 681, 734, 4, 38, 170, 634, 562, 73, 237, 198, 547, 187, 593, 363, 548, 330, 343, 141, 232, 109, 45, 578, 659, 502, 61, 566, 775, 730, 498, 662, 185, 776, 403, 505, 373, 337, 177, 384, 312, 410, 413, 618, 602, 722, 64, 358, 286, 708, 352, 339, 411, 392, 316, 68, 650, 598, 190, 559, 507, 774, 264, 601, 351, 758, 607, 207, 606, 702, 107, 499, 531, 23, 538, 585, 436, 426, 710, 95, 154, 196, 197, 184, 478, 452, 176, 694, 575, 100, 12, 17, 460, 334, 160, 158, 216, 706, 414, 746, 619, 541, 82, 692, 462, 323, 282, 146, 405, 5, 340, 489, 152, 658, 309, 627, 466, 353, 677, 129, 481, 396, 757, 128, 89, 480, 553, 574, 754, 675, 255, 201, 676, 181, 97, 69, 311, 34, 13, 223, 125, 43, 350, 400, 21, 291, 665, 208, 532, 63, 142, 60, 492, 55, 565, 240, 695, 235, 224, 297, 560, 59, 149, 273, 454, 31, 268, 556, 582, 244, 22, 383, 686, 62, 79, 279, 613, 586, 564, 249, 83, 115, 119, 41, 27, 333, 307, 127, 669, 495, 186, 438, 772, 767, 252, 98, 749, 760, 765, 584, 204, 600, 329, 11, 745, 515, 3, 46, 212, 292, 44, 153, 147, 577, 294, 173, 448, 20, 514, 226, 639, 247, 608, 320, 483, 648, 700, 293, 420, 509, 37, 431, 213, 377, 166, 36, 93, 84, 604, 156, 446, 674, 47, 679, 336, 501, 157, 588, 369, 172, 243, 423, 18, 376, 632, 271, 206, 458, 289, 544, 191, 741, 80, 399, 48, 303, 78, 162, 110, 522, 349, 421, 641, 753, 72, 703, 136, 542, 572, 16, 630, 717, 511, 102, 301]\n",
            "Testing indices: [120, 516, 756, 476, 570, 57, 88, 555, 130, 39, 131, 96, 150, 445, 155, 372, 318, 558, 390, 750, 2, 594, 105, 762, 728, 412, 140, 338, 471, 640, 611, 42, 276, 748, 461, 636, 233, 737, 239, 139, 86, 370, 549, 283, 488, 25, 768, 103, 317, 345, 205, 587, 688, 440, 683, 262, 263, 738, 735, 616, 479, 281, 76, 305, 66, 211, 359, 327, 24, 151, 296, 464, 393, 9, 165, 759, 493, 654, 629, 456, 409, 450, 326, 521, 288, 763, 210, 222, 723, 404, 217, 250, 117, 451, 540, 242, 265, 227, 241, 106, 561, 391, 773, 428, 357, 740, 135, 430, 725, 693, 469, 551, 554, 563, 747, 537, 579, 419, 251, 7, 259, 361, 182, 557, 113, 49, 622, 1, 647, 605, 118, 225, 597, 145, 261, 699, 360, 651, 635, 712, 517, 459, 439, 258, 134, 132, 19, 144, 653, 720, 167, 366, 667, 254, 174, 299]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [680, 646, 534, 194, 304, 290, 81, 526, 485, 736, 678, 354, 609, 429, 628, 770, 378, 111, 550, 701, 490, 169, 274, 180, 714, 30, 389, 671, 724, 387, 161, 721, 709, 755, 368, 689, 457, 238, 766, 260, 308, 711, 298, 58, 179, 50, 99, 552, 581, 278, 148, 322, 324, 697, 380, 530, 576, 500, 356, 416, 623, 473, 769, 472, 331, 673, 348, 418, 453, 637, 449, 491, 313, 319, 381, 236, 751, 287, 435, 230, 732, 203, 672, 40, 631, 415, 87, 248, 752, 567, 685, 443, 580, 408, 257, 28, 388, 761, 615, 656, 475, 270, 468, 221, 595, 520, 705, 122, 504, 434, 643, 214, 620, 199, 508, 644, 621, 510, 687, 75, 56, 455, 401, 143, 275, 332, 234, 433, 474, 496, 14, 374, 200, 124, 121, 660, 175, 215, 245, 664, 209, 51, 171, 668, 114, 691, 424, 10, 642, 328, 427, 310, 422, 92, 85, 682, 626, 402, 733, 228, 599, 253, 484, 645, 91, 382, 70, 633, 126, 8, 663, 494, 666, 739, 546, 138, 441, 684, 335, 29, 590, 447, 231, 707, 539, 425, 731, 536, 612, 195, 280, 771, 698, 15, 108, 719, 742, 535, 437, 718, 727, 652, 137, 220, 525, 193, 159, 0, 325, 52, 367, 589, 513, 614, 315, 729, 655, 657, 649, 123, 398, 90, 371, 573, 394, 346, 246, 189, 229, 465, 528, 342, 321, 133, 104, 715, 71, 188, 74, 407, 524, 503, 395, 302, 347, 26, 638, 624, 202, 512, 617, 116, 487, 518, 365, 713, 519, 53, 375, 386, 482, 497, 543, 54, 178, 417, 591, 583, 777, 218, 477, 344, 463, 272, 362, 355, 256, 470, 314, 33, 744, 696, 379, 277, 6, 726, 168, 163, 569, 625, 306, 444, 164, 506, 568, 743, 533, 690, 65, 219, 610, 704, 269, 267, 670, 77, 661, 192, 295, 94, 32, 592, 120, 516, 756, 476, 570, 57, 88, 555, 130, 39, 131, 96, 150, 445, 155, 372, 318, 558, 390, 750, 2, 594, 105, 762, 728, 412, 140, 338, 471, 640, 611, 42, 276, 748, 461, 636, 233, 737, 239, 139, 86, 370, 549, 283, 488, 25, 768, 103, 317, 345, 205, 587, 688, 440, 683, 262, 263, 738, 735, 616, 479, 281, 76, 305, 66, 211, 359, 327, 24, 151, 296, 464, 393, 9, 165, 759, 493, 654, 629, 456, 409, 450, 326, 521, 288, 763, 210, 222, 723, 404, 217, 250, 117, 451, 540, 242, 265, 227, 241, 106, 561, 391, 773, 428, 357, 740, 135, 430, 725, 693, 469, 551, 554, 563, 747, 537, 579, 419, 251, 7, 259, 361, 182, 557, 113, 49, 622, 1, 647, 605, 118, 225, 597, 145, 261, 699, 360, 651, 635, 712, 517, 459, 439, 258, 134, 132, 19, 144, 653, 720, 167, 366, 667, 254, 174, 299, 255, 201, 676, 181, 97, 69, 311, 34, 13, 223, 125, 43, 350, 400, 21, 291, 665, 208, 532, 63, 142, 60, 492, 55, 565, 240, 695, 235, 224, 297, 560, 59, 149, 273, 454, 31, 268, 556, 582, 244, 22, 383, 686, 62, 79, 279, 613, 586, 564, 249, 83, 115, 119, 41, 27, 333, 307, 127, 669, 495, 186, 438, 772, 767, 252, 98, 749, 760, 765, 584, 204, 600, 329, 11, 745, 515, 3, 46, 212, 292, 44, 153, 147, 577, 294, 173, 448, 20, 514, 226, 639, 247, 608, 320, 483, 648, 700, 293, 420, 509, 37, 431, 213, 377, 166, 36, 93, 84, 604, 156, 446, 674, 47, 679, 336, 501, 157, 588, 369, 172, 243, 423, 18, 376, 632, 271, 206, 458, 289, 544, 191, 741, 80, 399, 48, 303, 78, 162, 110, 522, 349, 421, 641, 753, 72, 703, 136, 542, 572, 16, 630, 717, 511, 102, 301]\n",
            "Testing indices: [529, 764, 183, 67, 341, 432, 571, 285, 266, 486, 527, 442, 467, 406, 364, 603, 523, 300, 596, 35, 101, 545, 385, 397, 112, 284, 716, 681, 734, 4, 38, 170, 634, 562, 73, 237, 198, 547, 187, 593, 363, 548, 330, 343, 141, 232, 109, 45, 578, 659, 502, 61, 566, 775, 730, 498, 662, 185, 776, 403, 505, 373, 337, 177, 384, 312, 410, 413, 618, 602, 722, 64, 358, 286, 708, 352, 339, 411, 392, 316, 68, 650, 598, 190, 559, 507, 774, 264, 601, 351, 758, 607, 207, 606, 702, 107, 499, 531, 23, 538, 585, 436, 426, 710, 95, 154, 196, 197, 184, 478, 452, 176, 694, 575, 100, 12, 17, 460, 334, 160, 158, 216, 706, 414, 746, 619, 541, 82, 692, 462, 323, 282, 146, 405, 5, 340, 489, 152, 658, 309, 627, 466, 353, 677, 129, 481, 396, 757, 128, 89, 480, 553, 574, 754, 675]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [680, 646, 534, 194, 304, 290, 81, 526, 485, 736, 678, 354, 609, 429, 628, 770, 378, 111, 550, 701, 490, 169, 274, 180, 714, 30, 389, 671, 724, 387, 161, 721, 709, 755, 368, 689, 457, 238, 766, 260, 308, 711, 298, 58, 179, 50, 99, 552, 581, 278, 148, 322, 324, 697, 380, 530, 576, 500, 356, 416, 623, 473, 769, 472, 331, 673, 348, 418, 453, 637, 449, 491, 313, 319, 381, 236, 751, 287, 435, 230, 732, 203, 672, 40, 631, 415, 87, 248, 752, 567, 685, 443, 580, 408, 257, 28, 388, 761, 615, 656, 475, 270, 468, 221, 595, 520, 705, 122, 504, 434, 643, 214, 620, 199, 508, 644, 621, 510, 687, 75, 56, 455, 401, 143, 275, 332, 234, 433, 474, 496, 14, 374, 200, 124, 121, 660, 175, 215, 245, 664, 209, 51, 171, 668, 114, 691, 424, 10, 642, 328, 427, 310, 422, 92, 85, 682, 626, 402, 733, 228, 599, 253, 484, 645, 91, 382, 70, 633, 126, 8, 663, 494, 666, 739, 546, 138, 441, 684, 335, 29, 590, 447, 231, 707, 539, 425, 731, 536, 612, 195, 280, 771, 698, 15, 108, 719, 742, 535, 437, 718, 727, 652, 137, 220, 525, 193, 159, 0, 325, 52, 367, 589, 513, 614, 315, 729, 655, 657, 649, 123, 398, 90, 371, 573, 394, 346, 246, 189, 229, 465, 528, 342, 321, 133, 104, 715, 71, 188, 74, 407, 524, 503, 395, 302, 347, 26, 638, 624, 202, 512, 617, 116, 487, 518, 365, 713, 519, 53, 375, 386, 482, 497, 543, 54, 178, 417, 591, 583, 777, 218, 477, 344, 463, 272, 362, 355, 256, 470, 314, 33, 744, 696, 379, 277, 6, 726, 168, 163, 569, 625, 306, 444, 164, 506, 568, 743, 533, 690, 65, 219, 610, 704, 269, 267, 670, 77, 661, 192, 295, 94, 32, 592, 120, 516, 756, 476, 570, 57, 88, 555, 130, 39, 131, 96, 150, 445, 155, 372, 318, 558, 390, 750, 2, 594, 105, 762, 728, 412, 140, 338, 471, 640, 611, 42, 276, 748, 461, 636, 233, 737, 239, 139, 86, 370, 549, 283, 488, 25, 768, 103, 317, 345, 205, 587, 688, 440, 683, 262, 263, 738, 735, 616, 479, 281, 76, 305, 66, 211, 359, 327, 24, 151, 296, 464, 393, 9, 165, 759, 493, 654, 629, 456, 409, 450, 326, 521, 288, 763, 210, 222, 723, 404, 217, 250, 117, 451, 540, 242, 265, 227, 241, 106, 561, 391, 773, 428, 357, 740, 135, 430, 725, 693, 469, 551, 554, 563, 747, 537, 579, 419, 251, 7, 259, 361, 182, 557, 113, 49, 622, 1, 647, 605, 118, 225, 597, 145, 261, 699, 360, 651, 635, 712, 517, 459, 439, 258, 134, 132, 19, 144, 653, 720, 167, 366, 667, 254, 174, 299, 529, 764, 183, 67, 341, 432, 571, 285, 266, 486, 527, 442, 467, 406, 364, 603, 523, 300, 596, 35, 101, 545, 385, 397, 112, 284, 716, 681, 734, 4, 38, 170, 634, 562, 73, 237, 198, 547, 187, 593, 363, 548, 330, 343, 141, 232, 109, 45, 578, 659, 502, 61, 566, 775, 730, 498, 662, 185, 776, 403, 505, 373, 337, 177, 384, 312, 410, 413, 618, 602, 722, 64, 358, 286, 708, 352, 339, 411, 392, 316, 68, 650, 598, 190, 559, 507, 774, 264, 601, 351, 758, 607, 207, 606, 702, 107, 499, 531, 23, 538, 585, 436, 426, 710, 95, 154, 196, 197, 184, 478, 452, 176, 694, 575, 100, 12, 17, 460, 334, 160, 158, 216, 706, 414, 746, 619, 541, 82, 692, 462, 323, 282, 146, 405, 5, 340, 489, 152, 658, 309, 627, 466, 353, 677, 129, 481, 396, 757, 128, 89, 480, 553, 574, 754, 675]\n",
            "Testing indices: [255, 201, 676, 181, 97, 69, 311, 34, 13, 223, 125, 43, 350, 400, 21, 291, 665, 208, 532, 63, 142, 60, 492, 55, 565, 240, 695, 235, 224, 297, 560, 59, 149, 273, 454, 31, 268, 556, 582, 244, 22, 383, 686, 62, 79, 279, 613, 586, 564, 249, 83, 115, 119, 41, 27, 333, 307, 127, 669, 495, 186, 438, 772, 767, 252, 98, 749, 760, 765, 584, 204, 600, 329, 11, 745, 515, 3, 46, 212, 292, 44, 153, 147, 577, 294, 173, 448, 20, 514, 226, 639, 247, 608, 320, 483, 648, 700, 293, 420, 509, 37, 431, 213, 377, 166, 36, 93, 84, 604, 156, 446, 674, 47, 679, 336, 501, 157, 588, 369, 172, 243, 423, 18, 376, 632, 271, 206, 458, 289, 544, 191, 741, 80, 399, 48, 303, 78, 162, 110, 522, 349, 421, 641, 753, 72, 703, 136, 542, 572, 16, 630, 717, 511, 102, 301]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [165, 152, 109, 181, 133, 80, 9, 146, 35, 58, 116, 55, 19, 77, 47, 169, 56, 89, 147, 103, 10, 111, 60, 115, 123, 142, 153, 108, 21, 83, 18, 131, 117, 63, 130, 180, 0, 110, 49, 105, 26, 44, 170, 16, 2, 14, 137, 138, 119, 57, 126, 141, 175, 113, 173, 13, 107, 99, 160, 124, 71, 81, 88, 17, 127, 8, 38, 15, 7, 64, 189, 82, 156, 73, 36, 188, 41, 86, 12, 78, 96, 140, 163, 192, 28, 106, 101, 135, 159, 154, 61, 97, 74, 186, 70, 185, 132, 143, 144, 102, 161, 31, 87, 90, 23, 164, 174, 166, 50, 183, 59, 155, 193, 104, 29, 151, 118, 25, 85, 65, 134, 76, 30, 33, 157, 136, 54, 45, 34, 177, 178, 176, 148, 37, 122, 92, 114, 95, 167, 75, 79, 46, 40, 43, 11, 149, 5, 98, 128, 150, 171, 20, 22, 158, 93, 112]\n",
            "Testing indices: [62, 42, 100, 129, 27, 139, 191, 194, 168, 67, 182, 84, 179, 1, 3, 91, 184, 4, 24, 187, 51, 69, 94, 190, 172, 53, 52, 66, 162, 68, 125, 120, 6, 32, 145, 48, 72, 121, 39]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [62, 42, 100, 129, 27, 139, 191, 194, 168, 67, 182, 84, 179, 1, 3, 91, 184, 4, 24, 187, 51, 69, 94, 190, 172, 53, 52, 66, 162, 68, 125, 120, 6, 32, 145, 48, 72, 121, 39, 105, 26, 44, 170, 16, 2, 14, 137, 138, 119, 57, 126, 141, 175, 113, 173, 13, 107, 99, 160, 124, 71, 81, 88, 17, 127, 8, 38, 15, 7, 64, 189, 82, 156, 73, 36, 188, 41, 86, 12, 78, 96, 140, 163, 192, 28, 106, 101, 135, 159, 154, 61, 97, 74, 186, 70, 185, 132, 143, 144, 102, 161, 31, 87, 90, 23, 164, 174, 166, 50, 183, 59, 155, 193, 104, 29, 151, 118, 25, 85, 65, 134, 76, 30, 33, 157, 136, 54, 45, 34, 177, 178, 176, 148, 37, 122, 92, 114, 95, 167, 75, 79, 46, 40, 43, 11, 149, 5, 98, 128, 150, 171, 20, 22, 158, 93, 112]\n",
            "Testing indices: [165, 152, 109, 181, 133, 80, 9, 146, 35, 58, 116, 55, 19, 77, 47, 169, 56, 89, 147, 103, 10, 111, 60, 115, 123, 142, 153, 108, 21, 83, 18, 131, 117, 63, 130, 180, 0, 110, 49]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [62, 42, 100, 129, 27, 139, 191, 194, 168, 67, 182, 84, 179, 1, 3, 91, 184, 4, 24, 187, 51, 69, 94, 190, 172, 53, 52, 66, 162, 68, 125, 120, 6, 32, 145, 48, 72, 121, 39, 165, 152, 109, 181, 133, 80, 9, 146, 35, 58, 116, 55, 19, 77, 47, 169, 56, 89, 147, 103, 10, 111, 60, 115, 123, 142, 153, 108, 21, 83, 18, 131, 117, 63, 130, 180, 0, 110, 49, 12, 78, 96, 140, 163, 192, 28, 106, 101, 135, 159, 154, 61, 97, 74, 186, 70, 185, 132, 143, 144, 102, 161, 31, 87, 90, 23, 164, 174, 166, 50, 183, 59, 155, 193, 104, 29, 151, 118, 25, 85, 65, 134, 76, 30, 33, 157, 136, 54, 45, 34, 177, 178, 176, 148, 37, 122, 92, 114, 95, 167, 75, 79, 46, 40, 43, 11, 149, 5, 98, 128, 150, 171, 20, 22, 158, 93, 112]\n",
            "Testing indices: [105, 26, 44, 170, 16, 2, 14, 137, 138, 119, 57, 126, 141, 175, 113, 173, 13, 107, 99, 160, 124, 71, 81, 88, 17, 127, 8, 38, 15, 7, 64, 189, 82, 156, 73, 36, 188, 41, 86]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [62, 42, 100, 129, 27, 139, 191, 194, 168, 67, 182, 84, 179, 1, 3, 91, 184, 4, 24, 187, 51, 69, 94, 190, 172, 53, 52, 66, 162, 68, 125, 120, 6, 32, 145, 48, 72, 121, 39, 165, 152, 109, 181, 133, 80, 9, 146, 35, 58, 116, 55, 19, 77, 47, 169, 56, 89, 147, 103, 10, 111, 60, 115, 123, 142, 153, 108, 21, 83, 18, 131, 117, 63, 130, 180, 0, 110, 49, 105, 26, 44, 170, 16, 2, 14, 137, 138, 119, 57, 126, 141, 175, 113, 173, 13, 107, 99, 160, 124, 71, 81, 88, 17, 127, 8, 38, 15, 7, 64, 189, 82, 156, 73, 36, 188, 41, 86, 25, 85, 65, 134, 76, 30, 33, 157, 136, 54, 45, 34, 177, 178, 176, 148, 37, 122, 92, 114, 95, 167, 75, 79, 46, 40, 43, 11, 149, 5, 98, 128, 150, 171, 20, 22, 158, 93, 112]\n",
            "Testing indices: [12, 78, 96, 140, 163, 192, 28, 106, 101, 135, 159, 154, 61, 97, 74, 186, 70, 185, 132, 143, 144, 102, 161, 31, 87, 90, 23, 164, 174, 166, 50, 183, 59, 155, 193, 104, 29, 151, 118]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [62, 42, 100, 129, 27, 139, 191, 194, 168, 67, 182, 84, 179, 1, 3, 91, 184, 4, 24, 187, 51, 69, 94, 190, 172, 53, 52, 66, 162, 68, 125, 120, 6, 32, 145, 48, 72, 121, 39, 165, 152, 109, 181, 133, 80, 9, 146, 35, 58, 116, 55, 19, 77, 47, 169, 56, 89, 147, 103, 10, 111, 60, 115, 123, 142, 153, 108, 21, 83, 18, 131, 117, 63, 130, 180, 0, 110, 49, 105, 26, 44, 170, 16, 2, 14, 137, 138, 119, 57, 126, 141, 175, 113, 173, 13, 107, 99, 160, 124, 71, 81, 88, 17, 127, 8, 38, 15, 7, 64, 189, 82, 156, 73, 36, 188, 41, 86, 12, 78, 96, 140, 163, 192, 28, 106, 101, 135, 159, 154, 61, 97, 74, 186, 70, 185, 132, 143, 144, 102, 161, 31, 87, 90, 23, 164, 174, 166, 50, 183, 59, 155, 193, 104, 29, 151, 118]\n",
            "Testing indices: [25, 85, 65, 134, 76, 30, 33, 157, 136, 54, 45, 34, 177, 178, 176, 148, 37, 122, 92, 114, 95, 167, 75, 79, 46, 40, 43, 11, 149, 5, 98, 128, 150, 171, 20, 22, 158, 93, 112]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "--------- Iteration 2 ---------\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 32,  0,  0],\n",
            "       [ 0, 77,  0,  0],\n",
            "       [ 0, 37,  0,  0],\n",
            "       [ 0, 10,  0,  0]]), array([[ 0, 32,  0,  0],\n",
            "       [ 0, 71,  0,  0],\n",
            "       [ 0, 44,  0,  0],\n",
            "       [ 0,  9,  0,  0]]), array([[ 0, 32,  0,  0],\n",
            "       [ 0, 78,  0,  0],\n",
            "       [ 0, 35,  0,  0],\n",
            "       [ 0, 11,  0,  0]]), array([[ 0, 42,  0,  0],\n",
            "       [ 0, 72,  0,  0],\n",
            "       [ 0, 33,  0,  0],\n",
            "       [ 0,  8,  0,  0]]), array([[ 0, 39,  0,  0],\n",
            "       [ 0, 60,  0,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0, 11,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        32\\n          a2    0.49359   1.00000   0.66094        77\\n          a3    0.00000   0.00000   0.00000        37\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.49359       156\\n   macro avg    0.12340   0.25000   0.16524       156\\nweighted avg    0.24363   0.49359   0.32624       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        32\\n          a2    0.45513   1.00000   0.62555        71\\n          a3    0.00000   0.00000   0.00000        44\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.45513       156\\n   macro avg    0.11378   0.25000   0.15639       156\\nweighted avg    0.20714   0.45513   0.28471       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        32\\n          a2    0.50000   1.00000   0.66667        78\\n          a3    0.00000   0.00000   0.00000        35\\n         a35    0.00000   0.00000   0.00000        11\\n\\n    accuracy                        0.50000       156\\n   macro avg    0.12500   0.25000   0.16667       156\\nweighted avg    0.25000   0.50000   0.33333       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        42\\n          a2    0.46452   1.00000   0.63436        72\\n          a3    0.00000   0.00000   0.00000        33\\n         a35    0.00000   0.00000   0.00000         8\\n\\n    accuracy                        0.46452       155\\n   macro avg    0.11613   0.25000   0.15859       155\\nweighted avg    0.21578   0.46452   0.29467       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        39\\n          a2    0.38710   1.00000   0.55814        60\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000        11\\n\\n    accuracy                        0.38710       155\\n   macro avg    0.09677   0.25000   0.13953       155\\nweighted avg    0.14984   0.38710   0.21605       155\\n']\n",
            "Mean Accuracy: 0.4600661703887511\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 32,  0,  0],\n",
            "       [ 0, 74,  3,  0],\n",
            "       [ 0, 37,  0,  0],\n",
            "       [ 0,  7,  3,  0]]), array([[ 0, 32,  0,  0],\n",
            "       [ 1, 70,  0,  0],\n",
            "       [ 0, 44,  0,  0],\n",
            "       [ 0,  9,  0,  0]]), array([[ 0, 32,  0,  0],\n",
            "       [ 1, 77,  0,  0],\n",
            "       [ 0, 34,  1,  0],\n",
            "       [ 0, 11,  0,  0]]), array([[ 0, 41,  1,  0],\n",
            "       [ 0, 71,  1,  0],\n",
            "       [ 1, 32,  0,  0],\n",
            "       [ 0,  6,  2,  0]]), array([[ 0, 39,  0,  0],\n",
            "       [ 0, 60,  0,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0, 11,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        32\\n          a2    0.49333   0.96104   0.65198        77\\n          a3    0.00000   0.00000   0.00000        37\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.47436       156\\n   macro avg    0.12333   0.24026   0.16300       156\\nweighted avg    0.24350   0.47436   0.32181       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        32\\n          a2    0.45161   0.98592   0.61947        71\\n          a3    0.00000   0.00000   0.00000        44\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.44872       156\\n   macro avg    0.11290   0.24648   0.15487       156\\nweighted avg    0.20554   0.44872   0.28194       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        32\\n          a2    0.50000   0.98718   0.66379        78\\n          a3    1.00000   0.02857   0.05556        35\\n         a35    0.00000   0.00000   0.00000        11\\n\\n    accuracy                        0.50000       156\\n   macro avg    0.37500   0.25394   0.17984       156\\nweighted avg    0.47436   0.50000   0.34436       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        42\\n          a2    0.47333   0.98611   0.63964        72\\n          a3    0.00000   0.00000   0.00000        33\\n         a35    0.00000   0.00000   0.00000         8\\n\\n    accuracy                        0.45806       155\\n   macro avg    0.11833   0.24653   0.15991       155\\nweighted avg    0.21987   0.45806   0.29712       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        39\\n          a2    0.38710   1.00000   0.55814        60\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000        11\\n\\n    accuracy                        0.38710       155\\n   macro avg    0.09677   0.25000   0.13953       155\\nweighted avg    0.14984   0.38710   0.21605       155\\n']\n",
            "Mean Accuracy: 0.4536476426799007\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[12, 13,  7,  0],\n",
            "       [16, 33, 24,  4],\n",
            "       [11, 11, 10,  5],\n",
            "       [ 2,  4,  2,  2]]), array([[ 7, 17,  6,  2],\n",
            "       [24, 26, 17,  4],\n",
            "       [11, 18, 11,  4],\n",
            "       [ 1,  2,  3,  3]]), array([[14, 12,  6,  0],\n",
            "       [15, 32, 23,  8],\n",
            "       [ 5, 15, 14,  1],\n",
            "       [ 2,  2,  5,  2]]), array([[15, 17,  5,  5],\n",
            "       [16, 33, 21,  2],\n",
            "       [12, 12,  8,  1],\n",
            "       [ 3,  2,  0,  3]]), array([[ 7, 24,  7,  1],\n",
            "       [ 6, 36, 15,  3],\n",
            "       [ 9, 21, 12,  3],\n",
            "       [ 1,  3,  4,  3]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.29268   0.37500   0.32877        32\\n          a2    0.54098   0.42857   0.47826        77\\n          a3    0.23256   0.27027   0.25000        37\\n         a35    0.18182   0.20000   0.19048        10\\n\\n    accuracy                        0.36538       156\\n   macro avg    0.31201   0.31846   0.31188       156\\nweighted avg    0.39387   0.36538   0.37501       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.16279   0.21875   0.18667        32\\n          a2    0.41270   0.36620   0.38806        71\\n          a3    0.29730   0.25000   0.27160        44\\n         a35    0.23077   0.33333   0.27273         9\\n\\n    accuracy                        0.30128       156\\n   macro avg    0.27589   0.29207   0.27976       156\\nweighted avg    0.31839   0.30128   0.30725       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.38889   0.43750   0.41176        32\\n          a2    0.52459   0.41026   0.46043        78\\n          a3    0.29167   0.40000   0.33735        35\\n         a35    0.18182   0.18182   0.18182        11\\n\\n    accuracy                        0.39744       156\\n   macro avg    0.34674   0.35739   0.34784       156\\nweighted avg    0.42033   0.39744   0.40319       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.32609   0.35714   0.34091        42\\n          a2    0.51562   0.45833   0.48529        72\\n          a3    0.23529   0.24242   0.23881        33\\n         a35    0.27273   0.37500   0.31579         8\\n\\n    accuracy                        0.38065       155\\n   macro avg    0.33743   0.35823   0.34520       155\\nweighted avg    0.39205   0.38065   0.38494       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.30435   0.17949   0.22581        39\\n          a2    0.42857   0.60000   0.50000        60\\n          a3    0.31579   0.26667   0.28916        45\\n         a35    0.30000   0.27273   0.28571        11\\n\\n    accuracy                        0.37419       155\\n   macro avg    0.33718   0.32972   0.32517       155\\nweighted avg    0.35545   0.37419   0.35459       155\\n']\n",
            "Mean Accuracy: 0.3637882547559967\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0,  8,  0,  0],\n",
            "       [ 0, 15,  0,  0],\n",
            "       [ 0, 15,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0,  8,  0,  0],\n",
            "       [ 0, 19,  0,  0],\n",
            "       [ 0, 10,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0,  9,  0,  0],\n",
            "       [ 0, 13,  0,  0],\n",
            "       [ 0, 12,  0,  0],\n",
            "       [ 0,  5,  0,  0]]), array([[ 0,  9,  0,  0],\n",
            "       [ 0, 19,  0,  0],\n",
            "       [ 0,  9,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0, 11,  2,  0],\n",
            "       [ 0, 10,  5,  0],\n",
            "       [ 0,  8,  1,  0],\n",
            "       [ 0,  1,  1,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         8\\n          a2    0.38462   1.00000   0.55556        15\\n          a3    0.00000   0.00000   0.00000        15\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.38462        39\\n   macro avg    0.09615   0.25000   0.13889        39\\nweighted avg    0.14793   0.38462   0.21368        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         8\\n          a2    0.48718   1.00000   0.65517        19\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.48718        39\\n   macro avg    0.12179   0.25000   0.16379        39\\nweighted avg    0.23734   0.48718   0.31919        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         9\\n          a2    0.33333   1.00000   0.50000        13\\n          a3    0.00000   0.00000   0.00000        12\\n         a35    0.00000   0.00000   0.00000         5\\n\\n    accuracy                        0.33333        39\\n   macro avg    0.08333   0.25000   0.12500        39\\nweighted avg    0.11111   0.33333   0.16667        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         9\\n          a2    0.48718   1.00000   0.65517        19\\n          a3    0.00000   0.00000   0.00000         9\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.48718        39\\n   macro avg    0.12179   0.25000   0.16379        39\\nweighted avg    0.23734   0.48718   0.31919        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        13\\n          a2    0.33333   0.66667   0.44444        15\\n          a3    0.11111   0.11111   0.11111         9\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.28205        39\\n   macro avg    0.11111   0.19444   0.13889        39\\nweighted avg    0.15385   0.28205   0.19658        39\\n']\n",
            "Mean Accuracy: 0.3948717948717949\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0,  8,  0,  0],\n",
            "       [ 0, 15,  0,  0],\n",
            "       [ 0, 15,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0,  7,  1,  0],\n",
            "       [ 1, 17,  1,  0],\n",
            "       [ 0, 10,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0,  9,  0,  0],\n",
            "       [ 0, 13,  0,  0],\n",
            "       [ 0, 12,  0,  0],\n",
            "       [ 0,  5,  0,  0]]), array([[ 0,  9,  0,  0],\n",
            "       [ 0, 18,  1,  0],\n",
            "       [ 0,  9,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0, 12,  1,  0],\n",
            "       [ 0, 14,  1,  0],\n",
            "       [ 0,  9,  0,  0],\n",
            "       [ 0,  2,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         8\\n          a2    0.38462   1.00000   0.55556        15\\n          a3    0.00000   0.00000   0.00000        15\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.38462        39\\n   macro avg    0.09615   0.25000   0.13889        39\\nweighted avg    0.14793   0.38462   0.21368        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         8\\n          a2    0.47222   0.89474   0.61818        19\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.43590        39\\n   macro avg    0.11806   0.22368   0.15455        39\\nweighted avg    0.23006   0.43590   0.30117        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         9\\n          a2    0.33333   1.00000   0.50000        13\\n          a3    0.00000   0.00000   0.00000        12\\n         a35    0.00000   0.00000   0.00000         5\\n\\n    accuracy                        0.33333        39\\n   macro avg    0.08333   0.25000   0.12500        39\\nweighted avg    0.11111   0.33333   0.16667        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         9\\n          a2    0.47368   0.94737   0.63158        19\\n          a3    0.00000   0.00000   0.00000         9\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11842   0.23684   0.15789        39\\nweighted avg    0.23077   0.46154   0.30769        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        13\\n          a2    0.37838   0.93333   0.53846        15\\n          a3    0.00000   0.00000   0.00000         9\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.35897        39\\n   macro avg    0.09459   0.23333   0.13462        39\\nweighted avg    0.14553   0.35897   0.20710        39\\n']\n",
            "Mean Accuracy: 0.3948717948717949\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[3, 3, 2, 0],\n",
            "       [2, 6, 5, 2],\n",
            "       [2, 4, 6, 3],\n",
            "       [0, 0, 0, 1]]), array([[ 3,  2,  2,  1],\n",
            "       [ 4, 11,  3,  1],\n",
            "       [ 3,  4,  2,  1],\n",
            "       [ 0,  1,  1,  0]]), array([[2, 4, 3, 0],\n",
            "       [4, 4, 5, 0],\n",
            "       [2, 5, 4, 1],\n",
            "       [0, 2, 2, 1]]), array([[ 3,  2,  4,  0],\n",
            "       [ 5,  4, 10,  0],\n",
            "       [ 3,  5,  1,  0],\n",
            "       [ 1,  0,  1,  0]]), array([[1, 2, 9, 1],\n",
            "       [5, 6, 4, 0],\n",
            "       [3, 1, 5, 0],\n",
            "       [0, 2, 0, 0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.42857   0.37500   0.40000         8\\n          a2    0.46154   0.40000   0.42857        15\\n          a3    0.46154   0.40000   0.42857        15\\n         a35    0.16667   1.00000   0.28571         1\\n\\n    accuracy                        0.41026        39\\n   macro avg    0.37958   0.54375   0.38571        39\\nweighted avg    0.44722   0.41026   0.41905        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.30000   0.37500   0.33333         8\\n          a2    0.61111   0.57895   0.59459        19\\n          a3    0.25000   0.20000   0.22222        10\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.41026        39\\n   macro avg    0.29028   0.28849   0.28754        39\\nweighted avg    0.42336   0.41026   0.41503        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.25000   0.22222   0.23529         9\\n          a2    0.26667   0.30769   0.28571        13\\n          a3    0.28571   0.33333   0.30769        12\\n         a35    0.50000   0.20000   0.28571         5\\n\\n    accuracy                        0.28205        39\\n   macro avg    0.32560   0.26581   0.27860        39\\nweighted avg    0.29860   0.28205   0.28084        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.25000   0.33333   0.28571         9\\n          a2    0.36364   0.21053   0.26667        19\\n          a3    0.06250   0.11111   0.08000         9\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.20513        39\\n   macro avg    0.16903   0.16374   0.15810        39\\nweighted avg    0.24927   0.20513   0.21431        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.11111   0.07692   0.09091        13\\n          a2    0.54545   0.40000   0.46154        15\\n          a3    0.27778   0.55556   0.37037         9\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.30769        39\\n   macro avg    0.23359   0.25812   0.23070        39\\nweighted avg    0.31093   0.30769   0.29329        39\\n']\n",
            "Mean Accuracy: 0.3230769230769231\n",
            "--------- End of Iteration ---------\n",
            "\n",
            "Training indices: [556, 203, 486, 758, 412, 771, 668, 111, 323, 473, 177, 202, 373, 99, 13, 483, 747, 378, 298, 361, 609, 720, 245, 411, 700, 588, 526, 43, 634, 661, 341, 402, 53, 278, 238, 651, 557, 525, 224, 733, 547, 670, 252, 133, 697, 56, 627, 152, 701, 665, 101, 374, 79, 487, 424, 295, 98, 144, 210, 641, 766, 117, 389, 636, 328, 172, 183, 672, 243, 645, 752, 368, 644, 61, 605, 562, 648, 81, 533, 35, 607, 757, 748, 768, 26, 530, 292, 396, 254, 494, 472, 561, 342, 116, 409, 214, 310, 694, 148, 313, 28, 102, 649, 118, 623, 274, 294, 55, 625, 726, 178, 569, 251, 369, 553, 41, 235, 42, 545, 692, 391, 736, 32, 598, 175, 264, 717, 772, 63, 495, 222, 333, 769, 388, 103, 221, 658, 753, 476, 586, 180, 516, 626, 220, 351, 656, 774, 92, 440, 746, 611, 289, 234, 635, 22, 646, 325, 261, 624, 115, 209, 591, 493, 225, 248, 158, 400, 352, 523, 149, 749, 534, 256, 629, 16, 165, 480, 335, 45, 497, 604, 765, 273, 73, 659, 285, 253, 573, 442, 565, 662, 484, 767, 40, 75, 517, 436, 64, 192, 182, 380, 346, 501, 464, 377, 496, 543, 94, 187, 606, 680, 36, 195, 432, 615, 171, 30, 290, 11, 348, 27, 277, 137, 398, 422, 552, 153, 318, 760, 266, 460, 269, 491, 756, 193, 515, 725, 754, 312, 3, 559, 113, 653, 242, 485, 293, 17, 66, 107, 108, 603, 37, 488, 4, 24, 286, 420, 12, 334, 93, 332, 709, 284, 140, 570, 419, 340, 750, 69, 630, 463, 320, 462, 5, 691, 299, 381, 142, 427, 89, 737, 708, 582, 226, 513, 126, 564, 466, 349, 10, 727, 589, 134, 319, 322, 535, 444, 329, 179, 121, 696, 597, 707, 551, 739, 578, 239, 492, 90, 14, 452, 263, 502, 48, 350, 445, 206, 617, 446, 503, 729, 345, 404, 712, 82, 667, 184, 259, 208, 583, 579, 434, 482, 614, 39, 343, 613, 141, 57, 358, 620, 305, 270, 454, 401, 602, 231, 447, 105, 660, 190, 406, 555, 344, 357, 481, 735, 572, 25, 677, 587, 167, 718, 685, 213, 80, 255, 330, 110, 62, 375, 337, 154, 71, 156, 324, 575, 129, 223, 566, 281, 174, 6, 438, 237, 489, 87, 684, 664, 185, 54, 51, 430, 669, 461, 151, 541, 596, 628, 550, 78, 431, 211, 676, 511, 704, 479, 719, 166, 150, 601, 143, 544, 475, 449, 271, 688, 671, 571, 387, 216, 504, 84, 367, 650, 106, 250, 9, 459, 450, 282, 275, 246, 415, 23, 205, 191, 370, 77, 734, 236, 201, 715, 413, 96, 147, 34, 307, 433, 742, 306, 595, 621, 240, 15, 68, 610, 751, 123, 429, 287, 189, 512, 135, 568, 437, 91, 686, 682, 759, 456, 47, 395, 652, 740, 616, 632, 689, 132, 619, 363, 364, 360, 83, 639, 188, 687, 314, 524, 618, 86, 567, 423, 490, 181, 711, 724, 499, 730, 44, 1, 315, 405, 468, 508, 161, 465, 283, 592, 710, 353, 58, 548, 723, 386, 164, 372, 109, 379, 169, 478, 763, 443, 85, 713, 743, 560, 540, 521, 354, 673, 467, 590, 745, 732, 38, 637, 76, 347, 428, 576, 457, 506, 52, 527, 170, 291, 339, 549, 666, 458, 119, 675, 303, 594, 681, 317, 122, 755, 383, 145, 654, 327, 643, 593, 18, 300, 59, 728, 599, 385, 227, 229, 136, 542, 336, 21, 20, 219, 173, 7, 695, 448, 417, 702, 407, 33, 706, 744, 204, 394, 509, 228, 418, 761, 392, 362, 207, 233, 399, 741, 455, 764, 217, 655, 558, 498, 640, 775, 382, 297, 8, 19, 376, 194, 88, 67, 0, 197, 714, 762, 453]\n",
            "Testing indices: [176, 331, 186, 678, 721, 528, 514, 679, 738, 159, 49, 249, 267, 722, 522, 260, 500, 359, 657, 470, 410, 46, 393, 198, 72, 776, 546, 130, 777, 584, 529, 690, 139, 265, 416, 663, 157, 426, 155, 316, 321, 100, 421, 532, 633, 538, 580, 127, 247, 215, 647, 355, 520, 563, 120, 311, 716, 554, 196, 631, 60, 302, 304, 451, 95, 770, 163, 31, 146, 474, 168, 124, 128, 674, 471, 435, 577, 698, 356, 414, 160, 74, 600, 539, 507, 505, 279, 288, 232, 244, 138, 384, 308, 309, 258, 162, 536, 131, 519, 510, 268, 683, 622, 276, 301, 50, 272, 112, 366, 65, 29, 773, 97, 114, 200, 574, 218, 212, 296, 408, 608, 612, 581, 537, 441, 703, 693, 585, 638, 365, 469, 70, 262, 439, 326, 397, 241, 104, 390, 518, 642, 230, 531, 257, 338, 731, 477, 705, 699, 280, 425, 125, 2, 403, 199, 371]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [176, 331, 186, 678, 721, 528, 514, 679, 738, 159, 49, 249, 267, 722, 522, 260, 500, 359, 657, 470, 410, 46, 393, 198, 72, 776, 546, 130, 777, 584, 529, 690, 139, 265, 416, 663, 157, 426, 155, 316, 321, 100, 421, 532, 633, 538, 580, 127, 247, 215, 647, 355, 520, 563, 120, 311, 716, 554, 196, 631, 60, 302, 304, 451, 95, 770, 163, 31, 146, 474, 168, 124, 128, 674, 471, 435, 577, 698, 356, 414, 160, 74, 600, 539, 507, 505, 279, 288, 232, 244, 138, 384, 308, 309, 258, 162, 536, 131, 519, 510, 268, 683, 622, 276, 301, 50, 272, 112, 366, 65, 29, 773, 97, 114, 200, 574, 218, 212, 296, 408, 608, 612, 581, 537, 441, 703, 693, 585, 638, 365, 469, 70, 262, 439, 326, 397, 241, 104, 390, 518, 642, 230, 531, 257, 338, 731, 477, 705, 699, 280, 425, 125, 2, 403, 199, 371, 325, 261, 624, 115, 209, 591, 493, 225, 248, 158, 400, 352, 523, 149, 749, 534, 256, 629, 16, 165, 480, 335, 45, 497, 604, 765, 273, 73, 659, 285, 253, 573, 442, 565, 662, 484, 767, 40, 75, 517, 436, 64, 192, 182, 380, 346, 501, 464, 377, 496, 543, 94, 187, 606, 680, 36, 195, 432, 615, 171, 30, 290, 11, 348, 27, 277, 137, 398, 422, 552, 153, 318, 760, 266, 460, 269, 491, 756, 193, 515, 725, 754, 312, 3, 559, 113, 653, 242, 485, 293, 17, 66, 107, 108, 603, 37, 488, 4, 24, 286, 420, 12, 334, 93, 332, 709, 284, 140, 570, 419, 340, 750, 69, 630, 463, 320, 462, 5, 691, 299, 381, 142, 427, 89, 737, 708, 582, 226, 513, 126, 564, 466, 349, 10, 727, 589, 134, 319, 322, 535, 444, 329, 179, 121, 696, 597, 707, 551, 739, 578, 239, 492, 90, 14, 452, 263, 502, 48, 350, 445, 206, 617, 446, 503, 729, 345, 404, 712, 82, 667, 184, 259, 208, 583, 579, 434, 482, 614, 39, 343, 613, 141, 57, 358, 620, 305, 270, 454, 401, 602, 231, 447, 105, 660, 190, 406, 555, 344, 357, 481, 735, 572, 25, 677, 587, 167, 718, 685, 213, 80, 255, 330, 110, 62, 375, 337, 154, 71, 156, 324, 575, 129, 223, 566, 281, 174, 6, 438, 237, 489, 87, 684, 664, 185, 54, 51, 430, 669, 461, 151, 541, 596, 628, 550, 78, 431, 211, 676, 511, 704, 479, 719, 166, 150, 601, 143, 544, 475, 449, 271, 688, 671, 571, 387, 216, 504, 84, 367, 650, 106, 250, 9, 459, 450, 282, 275, 246, 415, 23, 205, 191, 370, 77, 734, 236, 201, 715, 413, 96, 147, 34, 307, 433, 742, 306, 595, 621, 240, 15, 68, 610, 751, 123, 429, 287, 189, 512, 135, 568, 437, 91, 686, 682, 759, 456, 47, 395, 652, 740, 616, 632, 689, 132, 619, 363, 364, 360, 83, 639, 188, 687, 314, 524, 618, 86, 567, 423, 490, 181, 711, 724, 499, 730, 44, 1, 315, 405, 468, 508, 161, 465, 283, 592, 710, 353, 58, 548, 723, 386, 164, 372, 109, 379, 169, 478, 763, 443, 85, 713, 743, 560, 540, 521, 354, 673, 467, 590, 745, 732, 38, 637, 76, 347, 428, 576, 457, 506, 52, 527, 170, 291, 339, 549, 666, 458, 119, 675, 303, 594, 681, 317, 122, 755, 383, 145, 654, 327, 643, 593, 18, 300, 59, 728, 599, 385, 227, 229, 136, 542, 336, 21, 20, 219, 173, 7, 695, 448, 417, 702, 407, 33, 706, 744, 204, 394, 509, 228, 418, 761, 392, 362, 207, 233, 399, 741, 455, 764, 217, 655, 558, 498, 640, 775, 382, 297, 8, 19, 376, 194, 88, 67, 0, 197, 714, 762, 453]\n",
            "Testing indices: [556, 203, 486, 758, 412, 771, 668, 111, 323, 473, 177, 202, 373, 99, 13, 483, 747, 378, 298, 361, 609, 720, 245, 411, 700, 588, 526, 43, 634, 661, 341, 402, 53, 278, 238, 651, 557, 525, 224, 733, 547, 670, 252, 133, 697, 56, 627, 152, 701, 665, 101, 374, 79, 487, 424, 295, 98, 144, 210, 641, 766, 117, 389, 636, 328, 172, 183, 672, 243, 645, 752, 368, 644, 61, 605, 562, 648, 81, 533, 35, 607, 757, 748, 768, 26, 530, 292, 396, 254, 494, 472, 561, 342, 116, 409, 214, 310, 694, 148, 313, 28, 102, 649, 118, 623, 274, 294, 55, 625, 726, 178, 569, 251, 369, 553, 41, 235, 42, 545, 692, 391, 736, 32, 598, 175, 264, 717, 772, 63, 495, 222, 333, 769, 388, 103, 221, 658, 753, 476, 586, 180, 516, 626, 220, 351, 656, 774, 92, 440, 746, 611, 289, 234, 635, 22, 646]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [176, 331, 186, 678, 721, 528, 514, 679, 738, 159, 49, 249, 267, 722, 522, 260, 500, 359, 657, 470, 410, 46, 393, 198, 72, 776, 546, 130, 777, 584, 529, 690, 139, 265, 416, 663, 157, 426, 155, 316, 321, 100, 421, 532, 633, 538, 580, 127, 247, 215, 647, 355, 520, 563, 120, 311, 716, 554, 196, 631, 60, 302, 304, 451, 95, 770, 163, 31, 146, 474, 168, 124, 128, 674, 471, 435, 577, 698, 356, 414, 160, 74, 600, 539, 507, 505, 279, 288, 232, 244, 138, 384, 308, 309, 258, 162, 536, 131, 519, 510, 268, 683, 622, 276, 301, 50, 272, 112, 366, 65, 29, 773, 97, 114, 200, 574, 218, 212, 296, 408, 608, 612, 581, 537, 441, 703, 693, 585, 638, 365, 469, 70, 262, 439, 326, 397, 241, 104, 390, 518, 642, 230, 531, 257, 338, 731, 477, 705, 699, 280, 425, 125, 2, 403, 199, 371, 556, 203, 486, 758, 412, 771, 668, 111, 323, 473, 177, 202, 373, 99, 13, 483, 747, 378, 298, 361, 609, 720, 245, 411, 700, 588, 526, 43, 634, 661, 341, 402, 53, 278, 238, 651, 557, 525, 224, 733, 547, 670, 252, 133, 697, 56, 627, 152, 701, 665, 101, 374, 79, 487, 424, 295, 98, 144, 210, 641, 766, 117, 389, 636, 328, 172, 183, 672, 243, 645, 752, 368, 644, 61, 605, 562, 648, 81, 533, 35, 607, 757, 748, 768, 26, 530, 292, 396, 254, 494, 472, 561, 342, 116, 409, 214, 310, 694, 148, 313, 28, 102, 649, 118, 623, 274, 294, 55, 625, 726, 178, 569, 251, 369, 553, 41, 235, 42, 545, 692, 391, 736, 32, 598, 175, 264, 717, 772, 63, 495, 222, 333, 769, 388, 103, 221, 658, 753, 476, 586, 180, 516, 626, 220, 351, 656, 774, 92, 440, 746, 611, 289, 234, 635, 22, 646, 502, 48, 350, 445, 206, 617, 446, 503, 729, 345, 404, 712, 82, 667, 184, 259, 208, 583, 579, 434, 482, 614, 39, 343, 613, 141, 57, 358, 620, 305, 270, 454, 401, 602, 231, 447, 105, 660, 190, 406, 555, 344, 357, 481, 735, 572, 25, 677, 587, 167, 718, 685, 213, 80, 255, 330, 110, 62, 375, 337, 154, 71, 156, 324, 575, 129, 223, 566, 281, 174, 6, 438, 237, 489, 87, 684, 664, 185, 54, 51, 430, 669, 461, 151, 541, 596, 628, 550, 78, 431, 211, 676, 511, 704, 479, 719, 166, 150, 601, 143, 544, 475, 449, 271, 688, 671, 571, 387, 216, 504, 84, 367, 650, 106, 250, 9, 459, 450, 282, 275, 246, 415, 23, 205, 191, 370, 77, 734, 236, 201, 715, 413, 96, 147, 34, 307, 433, 742, 306, 595, 621, 240, 15, 68, 610, 751, 123, 429, 287, 189, 512, 135, 568, 437, 91, 686, 682, 759, 456, 47, 395, 652, 740, 616, 632, 689, 132, 619, 363, 364, 360, 83, 639, 188, 687, 314, 524, 618, 86, 567, 423, 490, 181, 711, 724, 499, 730, 44, 1, 315, 405, 468, 508, 161, 465, 283, 592, 710, 353, 58, 548, 723, 386, 164, 372, 109, 379, 169, 478, 763, 443, 85, 713, 743, 560, 540, 521, 354, 673, 467, 590, 745, 732, 38, 637, 76, 347, 428, 576, 457, 506, 52, 527, 170, 291, 339, 549, 666, 458, 119, 675, 303, 594, 681, 317, 122, 755, 383, 145, 654, 327, 643, 593, 18, 300, 59, 728, 599, 385, 227, 229, 136, 542, 336, 21, 20, 219, 173, 7, 695, 448, 417, 702, 407, 33, 706, 744, 204, 394, 509, 228, 418, 761, 392, 362, 207, 233, 399, 741, 455, 764, 217, 655, 558, 498, 640, 775, 382, 297, 8, 19, 376, 194, 88, 67, 0, 197, 714, 762, 453]\n",
            "Testing indices: [325, 261, 624, 115, 209, 591, 493, 225, 248, 158, 400, 352, 523, 149, 749, 534, 256, 629, 16, 165, 480, 335, 45, 497, 604, 765, 273, 73, 659, 285, 253, 573, 442, 565, 662, 484, 767, 40, 75, 517, 436, 64, 192, 182, 380, 346, 501, 464, 377, 496, 543, 94, 187, 606, 680, 36, 195, 432, 615, 171, 30, 290, 11, 348, 27, 277, 137, 398, 422, 552, 153, 318, 760, 266, 460, 269, 491, 756, 193, 515, 725, 754, 312, 3, 559, 113, 653, 242, 485, 293, 17, 66, 107, 108, 603, 37, 488, 4, 24, 286, 420, 12, 334, 93, 332, 709, 284, 140, 570, 419, 340, 750, 69, 630, 463, 320, 462, 5, 691, 299, 381, 142, 427, 89, 737, 708, 582, 226, 513, 126, 564, 466, 349, 10, 727, 589, 134, 319, 322, 535, 444, 329, 179, 121, 696, 597, 707, 551, 739, 578, 239, 492, 90, 14, 452, 263]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [176, 331, 186, 678, 721, 528, 514, 679, 738, 159, 49, 249, 267, 722, 522, 260, 500, 359, 657, 470, 410, 46, 393, 198, 72, 776, 546, 130, 777, 584, 529, 690, 139, 265, 416, 663, 157, 426, 155, 316, 321, 100, 421, 532, 633, 538, 580, 127, 247, 215, 647, 355, 520, 563, 120, 311, 716, 554, 196, 631, 60, 302, 304, 451, 95, 770, 163, 31, 146, 474, 168, 124, 128, 674, 471, 435, 577, 698, 356, 414, 160, 74, 600, 539, 507, 505, 279, 288, 232, 244, 138, 384, 308, 309, 258, 162, 536, 131, 519, 510, 268, 683, 622, 276, 301, 50, 272, 112, 366, 65, 29, 773, 97, 114, 200, 574, 218, 212, 296, 408, 608, 612, 581, 537, 441, 703, 693, 585, 638, 365, 469, 70, 262, 439, 326, 397, 241, 104, 390, 518, 642, 230, 531, 257, 338, 731, 477, 705, 699, 280, 425, 125, 2, 403, 199, 371, 556, 203, 486, 758, 412, 771, 668, 111, 323, 473, 177, 202, 373, 99, 13, 483, 747, 378, 298, 361, 609, 720, 245, 411, 700, 588, 526, 43, 634, 661, 341, 402, 53, 278, 238, 651, 557, 525, 224, 733, 547, 670, 252, 133, 697, 56, 627, 152, 701, 665, 101, 374, 79, 487, 424, 295, 98, 144, 210, 641, 766, 117, 389, 636, 328, 172, 183, 672, 243, 645, 752, 368, 644, 61, 605, 562, 648, 81, 533, 35, 607, 757, 748, 768, 26, 530, 292, 396, 254, 494, 472, 561, 342, 116, 409, 214, 310, 694, 148, 313, 28, 102, 649, 118, 623, 274, 294, 55, 625, 726, 178, 569, 251, 369, 553, 41, 235, 42, 545, 692, 391, 736, 32, 598, 175, 264, 717, 772, 63, 495, 222, 333, 769, 388, 103, 221, 658, 753, 476, 586, 180, 516, 626, 220, 351, 656, 774, 92, 440, 746, 611, 289, 234, 635, 22, 646, 325, 261, 624, 115, 209, 591, 493, 225, 248, 158, 400, 352, 523, 149, 749, 534, 256, 629, 16, 165, 480, 335, 45, 497, 604, 765, 273, 73, 659, 285, 253, 573, 442, 565, 662, 484, 767, 40, 75, 517, 436, 64, 192, 182, 380, 346, 501, 464, 377, 496, 543, 94, 187, 606, 680, 36, 195, 432, 615, 171, 30, 290, 11, 348, 27, 277, 137, 398, 422, 552, 153, 318, 760, 266, 460, 269, 491, 756, 193, 515, 725, 754, 312, 3, 559, 113, 653, 242, 485, 293, 17, 66, 107, 108, 603, 37, 488, 4, 24, 286, 420, 12, 334, 93, 332, 709, 284, 140, 570, 419, 340, 750, 69, 630, 463, 320, 462, 5, 691, 299, 381, 142, 427, 89, 737, 708, 582, 226, 513, 126, 564, 466, 349, 10, 727, 589, 134, 319, 322, 535, 444, 329, 179, 121, 696, 597, 707, 551, 739, 578, 239, 492, 90, 14, 452, 263, 686, 682, 759, 456, 47, 395, 652, 740, 616, 632, 689, 132, 619, 363, 364, 360, 83, 639, 188, 687, 314, 524, 618, 86, 567, 423, 490, 181, 711, 724, 499, 730, 44, 1, 315, 405, 468, 508, 161, 465, 283, 592, 710, 353, 58, 548, 723, 386, 164, 372, 109, 379, 169, 478, 763, 443, 85, 713, 743, 560, 540, 521, 354, 673, 467, 590, 745, 732, 38, 637, 76, 347, 428, 576, 457, 506, 52, 527, 170, 291, 339, 549, 666, 458, 119, 675, 303, 594, 681, 317, 122, 755, 383, 145, 654, 327, 643, 593, 18, 300, 59, 728, 599, 385, 227, 229, 136, 542, 336, 21, 20, 219, 173, 7, 695, 448, 417, 702, 407, 33, 706, 744, 204, 394, 509, 228, 418, 761, 392, 362, 207, 233, 399, 741, 455, 764, 217, 655, 558, 498, 640, 775, 382, 297, 8, 19, 376, 194, 88, 67, 0, 197, 714, 762, 453]\n",
            "Testing indices: [502, 48, 350, 445, 206, 617, 446, 503, 729, 345, 404, 712, 82, 667, 184, 259, 208, 583, 579, 434, 482, 614, 39, 343, 613, 141, 57, 358, 620, 305, 270, 454, 401, 602, 231, 447, 105, 660, 190, 406, 555, 344, 357, 481, 735, 572, 25, 677, 587, 167, 718, 685, 213, 80, 255, 330, 110, 62, 375, 337, 154, 71, 156, 324, 575, 129, 223, 566, 281, 174, 6, 438, 237, 489, 87, 684, 664, 185, 54, 51, 430, 669, 461, 151, 541, 596, 628, 550, 78, 431, 211, 676, 511, 704, 479, 719, 166, 150, 601, 143, 544, 475, 449, 271, 688, 671, 571, 387, 216, 504, 84, 367, 650, 106, 250, 9, 459, 450, 282, 275, 246, 415, 23, 205, 191, 370, 77, 734, 236, 201, 715, 413, 96, 147, 34, 307, 433, 742, 306, 595, 621, 240, 15, 68, 610, 751, 123, 429, 287, 189, 512, 135, 568, 437, 91]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [176, 331, 186, 678, 721, 528, 514, 679, 738, 159, 49, 249, 267, 722, 522, 260, 500, 359, 657, 470, 410, 46, 393, 198, 72, 776, 546, 130, 777, 584, 529, 690, 139, 265, 416, 663, 157, 426, 155, 316, 321, 100, 421, 532, 633, 538, 580, 127, 247, 215, 647, 355, 520, 563, 120, 311, 716, 554, 196, 631, 60, 302, 304, 451, 95, 770, 163, 31, 146, 474, 168, 124, 128, 674, 471, 435, 577, 698, 356, 414, 160, 74, 600, 539, 507, 505, 279, 288, 232, 244, 138, 384, 308, 309, 258, 162, 536, 131, 519, 510, 268, 683, 622, 276, 301, 50, 272, 112, 366, 65, 29, 773, 97, 114, 200, 574, 218, 212, 296, 408, 608, 612, 581, 537, 441, 703, 693, 585, 638, 365, 469, 70, 262, 439, 326, 397, 241, 104, 390, 518, 642, 230, 531, 257, 338, 731, 477, 705, 699, 280, 425, 125, 2, 403, 199, 371, 556, 203, 486, 758, 412, 771, 668, 111, 323, 473, 177, 202, 373, 99, 13, 483, 747, 378, 298, 361, 609, 720, 245, 411, 700, 588, 526, 43, 634, 661, 341, 402, 53, 278, 238, 651, 557, 525, 224, 733, 547, 670, 252, 133, 697, 56, 627, 152, 701, 665, 101, 374, 79, 487, 424, 295, 98, 144, 210, 641, 766, 117, 389, 636, 328, 172, 183, 672, 243, 645, 752, 368, 644, 61, 605, 562, 648, 81, 533, 35, 607, 757, 748, 768, 26, 530, 292, 396, 254, 494, 472, 561, 342, 116, 409, 214, 310, 694, 148, 313, 28, 102, 649, 118, 623, 274, 294, 55, 625, 726, 178, 569, 251, 369, 553, 41, 235, 42, 545, 692, 391, 736, 32, 598, 175, 264, 717, 772, 63, 495, 222, 333, 769, 388, 103, 221, 658, 753, 476, 586, 180, 516, 626, 220, 351, 656, 774, 92, 440, 746, 611, 289, 234, 635, 22, 646, 325, 261, 624, 115, 209, 591, 493, 225, 248, 158, 400, 352, 523, 149, 749, 534, 256, 629, 16, 165, 480, 335, 45, 497, 604, 765, 273, 73, 659, 285, 253, 573, 442, 565, 662, 484, 767, 40, 75, 517, 436, 64, 192, 182, 380, 346, 501, 464, 377, 496, 543, 94, 187, 606, 680, 36, 195, 432, 615, 171, 30, 290, 11, 348, 27, 277, 137, 398, 422, 552, 153, 318, 760, 266, 460, 269, 491, 756, 193, 515, 725, 754, 312, 3, 559, 113, 653, 242, 485, 293, 17, 66, 107, 108, 603, 37, 488, 4, 24, 286, 420, 12, 334, 93, 332, 709, 284, 140, 570, 419, 340, 750, 69, 630, 463, 320, 462, 5, 691, 299, 381, 142, 427, 89, 737, 708, 582, 226, 513, 126, 564, 466, 349, 10, 727, 589, 134, 319, 322, 535, 444, 329, 179, 121, 696, 597, 707, 551, 739, 578, 239, 492, 90, 14, 452, 263, 502, 48, 350, 445, 206, 617, 446, 503, 729, 345, 404, 712, 82, 667, 184, 259, 208, 583, 579, 434, 482, 614, 39, 343, 613, 141, 57, 358, 620, 305, 270, 454, 401, 602, 231, 447, 105, 660, 190, 406, 555, 344, 357, 481, 735, 572, 25, 677, 587, 167, 718, 685, 213, 80, 255, 330, 110, 62, 375, 337, 154, 71, 156, 324, 575, 129, 223, 566, 281, 174, 6, 438, 237, 489, 87, 684, 664, 185, 54, 51, 430, 669, 461, 151, 541, 596, 628, 550, 78, 431, 211, 676, 511, 704, 479, 719, 166, 150, 601, 143, 544, 475, 449, 271, 688, 671, 571, 387, 216, 504, 84, 367, 650, 106, 250, 9, 459, 450, 282, 275, 246, 415, 23, 205, 191, 370, 77, 734, 236, 201, 715, 413, 96, 147, 34, 307, 433, 742, 306, 595, 621, 240, 15, 68, 610, 751, 123, 429, 287, 189, 512, 135, 568, 437, 91]\n",
            "Testing indices: [686, 682, 759, 456, 47, 395, 652, 740, 616, 632, 689, 132, 619, 363, 364, 360, 83, 639, 188, 687, 314, 524, 618, 86, 567, 423, 490, 181, 711, 724, 499, 730, 44, 1, 315, 405, 468, 508, 161, 465, 283, 592, 710, 353, 58, 548, 723, 386, 164, 372, 109, 379, 169, 478, 763, 443, 85, 713, 743, 560, 540, 521, 354, 673, 467, 590, 745, 732, 38, 637, 76, 347, 428, 576, 457, 506, 52, 527, 170, 291, 339, 549, 666, 458, 119, 675, 303, 594, 681, 317, 122, 755, 383, 145, 654, 327, 643, 593, 18, 300, 59, 728, 599, 385, 227, 229, 136, 542, 336, 21, 20, 219, 173, 7, 695, 448, 417, 702, 407, 33, 706, 744, 204, 394, 509, 228, 418, 761, 392, 362, 207, 233, 399, 741, 455, 764, 217, 655, 558, 498, 640, 775, 382, 297, 8, 19, 376, 194, 88, 67, 0, 197, 714, 762, 453]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [170, 45, 143, 136, 152, 84, 158, 126, 93, 123, 168, 60, 79, 51, 182, 11, 13, 135, 85, 10, 97, 52, 75, 44, 125, 31, 194, 134, 160, 179, 118, 154, 110, 98, 64, 17, 46, 147, 177, 144, 0, 102, 188, 145, 159, 133, 37, 99, 169, 73, 76, 105, 163, 107, 172, 55, 165, 18, 157, 34, 140, 153, 193, 190, 106, 19, 111, 146, 69, 43, 173, 57, 156, 94, 92, 91, 20, 95, 53, 128, 49, 80, 50, 139, 82, 32, 23, 87, 89, 116, 78, 28, 138, 114, 192, 101, 47, 104, 59, 22, 4, 119, 127, 129, 35, 61, 48, 8, 54, 171, 151, 39, 103, 121, 71, 63, 122, 40, 24, 164, 81, 100, 68, 112, 56, 149, 137, 161, 109, 12, 1, 166, 141, 176, 83, 124, 7, 70, 132, 90, 88, 14, 162, 113, 155, 38, 66, 72, 16, 117, 167, 27, 6, 142, 42, 86]\n",
            "Testing indices: [131, 74, 181, 3, 120, 26, 9, 62, 33, 15, 2, 150, 36, 41, 191, 189, 5, 183, 184, 185, 175, 21, 148, 77, 30, 67, 174, 180, 186, 187, 96, 65, 115, 25, 58, 130, 108, 178, 29]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [131, 74, 181, 3, 120, 26, 9, 62, 33, 15, 2, 150, 36, 41, 191, 189, 5, 183, 184, 185, 175, 21, 148, 77, 30, 67, 174, 180, 186, 187, 96, 65, 115, 25, 58, 130, 108, 178, 29, 144, 0, 102, 188, 145, 159, 133, 37, 99, 169, 73, 76, 105, 163, 107, 172, 55, 165, 18, 157, 34, 140, 153, 193, 190, 106, 19, 111, 146, 69, 43, 173, 57, 156, 94, 92, 91, 20, 95, 53, 128, 49, 80, 50, 139, 82, 32, 23, 87, 89, 116, 78, 28, 138, 114, 192, 101, 47, 104, 59, 22, 4, 119, 127, 129, 35, 61, 48, 8, 54, 171, 151, 39, 103, 121, 71, 63, 122, 40, 24, 164, 81, 100, 68, 112, 56, 149, 137, 161, 109, 12, 1, 166, 141, 176, 83, 124, 7, 70, 132, 90, 88, 14, 162, 113, 155, 38, 66, 72, 16, 117, 167, 27, 6, 142, 42, 86]\n",
            "Testing indices: [170, 45, 143, 136, 152, 84, 158, 126, 93, 123, 168, 60, 79, 51, 182, 11, 13, 135, 85, 10, 97, 52, 75, 44, 125, 31, 194, 134, 160, 179, 118, 154, 110, 98, 64, 17, 46, 147, 177]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [131, 74, 181, 3, 120, 26, 9, 62, 33, 15, 2, 150, 36, 41, 191, 189, 5, 183, 184, 185, 175, 21, 148, 77, 30, 67, 174, 180, 186, 187, 96, 65, 115, 25, 58, 130, 108, 178, 29, 170, 45, 143, 136, 152, 84, 158, 126, 93, 123, 168, 60, 79, 51, 182, 11, 13, 135, 85, 10, 97, 52, 75, 44, 125, 31, 194, 134, 160, 179, 118, 154, 110, 98, 64, 17, 46, 147, 177, 53, 128, 49, 80, 50, 139, 82, 32, 23, 87, 89, 116, 78, 28, 138, 114, 192, 101, 47, 104, 59, 22, 4, 119, 127, 129, 35, 61, 48, 8, 54, 171, 151, 39, 103, 121, 71, 63, 122, 40, 24, 164, 81, 100, 68, 112, 56, 149, 137, 161, 109, 12, 1, 166, 141, 176, 83, 124, 7, 70, 132, 90, 88, 14, 162, 113, 155, 38, 66, 72, 16, 117, 167, 27, 6, 142, 42, 86]\n",
            "Testing indices: [144, 0, 102, 188, 145, 159, 133, 37, 99, 169, 73, 76, 105, 163, 107, 172, 55, 165, 18, 157, 34, 140, 153, 193, 190, 106, 19, 111, 146, 69, 43, 173, 57, 156, 94, 92, 91, 20, 95]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [131, 74, 181, 3, 120, 26, 9, 62, 33, 15, 2, 150, 36, 41, 191, 189, 5, 183, 184, 185, 175, 21, 148, 77, 30, 67, 174, 180, 186, 187, 96, 65, 115, 25, 58, 130, 108, 178, 29, 170, 45, 143, 136, 152, 84, 158, 126, 93, 123, 168, 60, 79, 51, 182, 11, 13, 135, 85, 10, 97, 52, 75, 44, 125, 31, 194, 134, 160, 179, 118, 154, 110, 98, 64, 17, 46, 147, 177, 144, 0, 102, 188, 145, 159, 133, 37, 99, 169, 73, 76, 105, 163, 107, 172, 55, 165, 18, 157, 34, 140, 153, 193, 190, 106, 19, 111, 146, 69, 43, 173, 57, 156, 94, 92, 91, 20, 95, 40, 24, 164, 81, 100, 68, 112, 56, 149, 137, 161, 109, 12, 1, 166, 141, 176, 83, 124, 7, 70, 132, 90, 88, 14, 162, 113, 155, 38, 66, 72, 16, 117, 167, 27, 6, 142, 42, 86]\n",
            "Testing indices: [53, 128, 49, 80, 50, 139, 82, 32, 23, 87, 89, 116, 78, 28, 138, 114, 192, 101, 47, 104, 59, 22, 4, 119, 127, 129, 35, 61, 48, 8, 54, 171, 151, 39, 103, 121, 71, 63, 122]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [131, 74, 181, 3, 120, 26, 9, 62, 33, 15, 2, 150, 36, 41, 191, 189, 5, 183, 184, 185, 175, 21, 148, 77, 30, 67, 174, 180, 186, 187, 96, 65, 115, 25, 58, 130, 108, 178, 29, 170, 45, 143, 136, 152, 84, 158, 126, 93, 123, 168, 60, 79, 51, 182, 11, 13, 135, 85, 10, 97, 52, 75, 44, 125, 31, 194, 134, 160, 179, 118, 154, 110, 98, 64, 17, 46, 147, 177, 144, 0, 102, 188, 145, 159, 133, 37, 99, 169, 73, 76, 105, 163, 107, 172, 55, 165, 18, 157, 34, 140, 153, 193, 190, 106, 19, 111, 146, 69, 43, 173, 57, 156, 94, 92, 91, 20, 95, 53, 128, 49, 80, 50, 139, 82, 32, 23, 87, 89, 116, 78, 28, 138, 114, 192, 101, 47, 104, 59, 22, 4, 119, 127, 129, 35, 61, 48, 8, 54, 171, 151, 39, 103, 121, 71, 63, 122]\n",
            "Testing indices: [40, 24, 164, 81, 100, 68, 112, 56, 149, 137, 161, 109, 12, 1, 166, 141, 176, 83, 124, 7, 70, 132, 90, 88, 14, 162, 113, 155, 38, 66, 72, 16, 117, 167, 27, 6, 142, 42, 86]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "--------- Iteration 3 ---------\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 32,  0,  0],\n",
            "       [ 0, 69,  0,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0, 10,  0,  0]]), array([[ 0, 31,  0,  0],\n",
            "       [ 0, 76,  0,  0],\n",
            "       [ 0, 40,  0,  0],\n",
            "       [ 0,  9,  0,  0]]), array([[ 0, 34,  0,  0],\n",
            "       [ 0, 72,  0,  0],\n",
            "       [ 0, 40,  0,  0],\n",
            "       [ 0, 10,  0,  0]]), array([[ 0, 43,  0,  0],\n",
            "       [ 0, 65,  0,  0],\n",
            "       [ 0, 39,  0,  0],\n",
            "       [ 0,  8,  0,  0]]), array([[ 0, 40,  0,  0],\n",
            "       [ 0, 66,  0,  0],\n",
            "       [ 0, 38,  0,  0],\n",
            "       [ 0, 11,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        32\\n          a2    0.44231   1.00000   0.61333        69\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.44231       156\\n   macro avg    0.11058   0.25000   0.15333       156\\nweighted avg    0.19564   0.44231   0.27128       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        31\\n          a2    0.48718   1.00000   0.65517        76\\n          a3    0.00000   0.00000   0.00000        40\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.48718       156\\n   macro avg    0.12179   0.25000   0.16379       156\\nweighted avg    0.23734   0.48718   0.31919       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        34\\n          a2    0.46154   1.00000   0.63158        72\\n          a3    0.00000   0.00000   0.00000        40\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.46154       156\\n   macro avg    0.11538   0.25000   0.15789       156\\nweighted avg    0.21302   0.46154   0.29150       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        43\\n          a2    0.41935   1.00000   0.59091        65\\n          a3    0.00000   0.00000   0.00000        39\\n         a35    0.00000   0.00000   0.00000         8\\n\\n    accuracy                        0.41935       155\\n   macro avg    0.10484   0.25000   0.14773       155\\nweighted avg    0.17586   0.41935   0.24780       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        40\\n          a2    0.42581   1.00000   0.59729        66\\n          a3    0.00000   0.00000   0.00000        38\\n         a35    0.00000   0.00000   0.00000        11\\n\\n    accuracy                        0.42581       155\\n   macro avg    0.10645   0.25000   0.14932       155\\nweighted avg    0.18131   0.42581   0.25433       155\\n']\n",
            "Mean Accuracy: 0.4472373862696443\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 2, 30,  0,  0],\n",
            "       [ 0, 69,  0,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0, 10,  0,  0]]), array([[ 5, 26,  0,  0],\n",
            "       [ 9, 67,  0,  0],\n",
            "       [ 0, 40,  0,  0],\n",
            "       [ 0,  9,  0,  0]]), array([[ 3, 31,  0,  0],\n",
            "       [ 2, 70,  0,  0],\n",
            "       [ 3, 37,  0,  0],\n",
            "       [ 1,  9,  0,  0]]), array([[ 3, 40,  0,  0],\n",
            "       [ 2, 62,  1,  0],\n",
            "       [ 1, 38,  0,  0],\n",
            "       [ 0,  8,  0,  0]]), array([[ 1, 39,  0,  0],\n",
            "       [ 1, 64,  1,  0],\n",
            "       [ 0, 38,  0,  0],\n",
            "       [ 0, 11,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    1.00000   0.06250   0.11765        32\\n          a2    0.44805   1.00000   0.61883        69\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.45513       156\\n   macro avg    0.36201   0.26562   0.18412       156\\nweighted avg    0.40331   0.45513   0.29785       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.35714   0.16129   0.22222        31\\n          a2    0.47183   0.88158   0.61468        76\\n          a3    0.00000   0.00000   0.00000        40\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.46154       156\\n   macro avg    0.20724   0.26072   0.20923       156\\nweighted avg    0.30084   0.46154   0.34362       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.33333   0.08824   0.13953        34\\n          a2    0.47619   0.97222   0.63927        72\\n          a3    0.00000   0.00000   0.00000        40\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.46795       156\\n   macro avg    0.20238   0.26511   0.19470       156\\nweighted avg    0.29243   0.46795   0.32546       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.50000   0.06977   0.12245        43\\n          a2    0.41892   0.95385   0.58216        65\\n          a3    0.00000   0.00000   0.00000        39\\n         a35    0.00000   0.00000   0.00000         8\\n\\n    accuracy                        0.41935       155\\n   macro avg    0.22973   0.25590   0.17615       155\\nweighted avg    0.31439   0.41935   0.27810       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.50000   0.02500   0.04762        40\\n          a2    0.42105   0.96970   0.58716        66\\n          a3    0.00000   0.00000   0.00000        38\\n         a35    0.00000   0.00000   0.00000        11\\n\\n    accuracy                        0.41935       155\\n   macro avg    0.23026   0.24867   0.15869       155\\nweighted avg    0.30832   0.41935   0.26230       155\\n']\n",
            "Mean Accuracy: 0.4446650124069479\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[12, 14,  5,  1],\n",
            "       [10, 25, 29,  5],\n",
            "       [10, 19, 11,  5],\n",
            "       [ 0,  5,  4,  1]]), array([[14,  7, 10,  0],\n",
            "       [21, 28, 24,  3],\n",
            "       [ 8, 18,  9,  5],\n",
            "       [ 1,  5,  3,  0]]), array([[ 4, 18,  9,  3],\n",
            "       [16, 32, 17,  7],\n",
            "       [ 5, 26,  6,  3],\n",
            "       [ 0,  7,  3,  0]]), array([[17, 16,  8,  2],\n",
            "       [15, 29, 17,  4],\n",
            "       [ 9, 16, 11,  3],\n",
            "       [ 2,  4,  1,  1]]), array([[11, 20,  9,  0],\n",
            "       [10, 30, 23,  3],\n",
            "       [ 6, 14, 14,  4],\n",
            "       [ 1,  6,  2,  2]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.37500   0.37500   0.37500        32\\n          a2    0.39683   0.36232   0.37879        69\\n          a3    0.22449   0.24444   0.23404        45\\n         a35    0.08333   0.10000   0.09091        10\\n\\n    accuracy                        0.31410       156\\n   macro avg    0.26991   0.27044   0.26968       156\\nweighted avg    0.32254   0.31410   0.31780       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.31818   0.45161   0.37333        31\\n          a2    0.48276   0.36842   0.41791        76\\n          a3    0.19565   0.22500   0.20930        40\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.32692       156\\n   macro avg    0.24915   0.26126   0.25014       156\\nweighted avg    0.34859   0.32692   0.33145       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.16000   0.11765   0.13559        34\\n          a2    0.38554   0.44444   0.41290        72\\n          a3    0.17143   0.15000   0.16000        40\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.26923       156\\n   macro avg    0.17924   0.17802   0.17712       156\\nweighted avg    0.25677   0.26923   0.26115       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.39535   0.39535   0.39535        43\\n          a2    0.44615   0.44615   0.44615        65\\n          a3    0.29730   0.28205   0.28947        39\\n         a35    0.10000   0.12500   0.11111         8\\n\\n    accuracy                        0.37419       155\\n   macro avg    0.30970   0.31214   0.31052       155\\nweighted avg    0.37674   0.37419   0.37534       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.39286   0.27500   0.32353        40\\n          a2    0.42857   0.45455   0.44118        66\\n          a3    0.29167   0.36842   0.32558        38\\n         a35    0.22222   0.18182   0.20000        11\\n\\n    accuracy                        0.36774       155\\n   macro avg    0.33383   0.31995   0.32257       155\\nweighted avg    0.37115   0.36774   0.36536       155\\n']\n",
            "Mean Accuracy: 0.33043837882547555\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0,  8,  0],\n",
            "       [ 0, 21,  0],\n",
            "       [ 0, 10,  0]]), array([[ 0,  7,  0,  0],\n",
            "       [ 0, 18,  0,  0],\n",
            "       [ 0, 11,  0,  0],\n",
            "       [ 0,  3,  0,  0]]), array([[ 0,  9,  0,  0],\n",
            "       [ 0, 17,  0,  0],\n",
            "       [ 0,  7,  0,  0],\n",
            "       [ 0,  6,  0,  0]]), array([[ 0, 10,  0,  0],\n",
            "       [ 0, 22,  0,  0],\n",
            "       [ 0,  6,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0, 10,  0,  0],\n",
            "       [ 0, 13,  0,  0],\n",
            "       [ 0, 13,  0,  0],\n",
            "       [ 0,  3,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         8\\n          a2    0.53846   1.00000   0.70000        21\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         0\\n\\n   micro avg    0.53846   0.53846   0.53846        39\\n   macro avg    0.13462   0.25000   0.17500        39\\nweighted avg    0.28994   0.53846   0.37692        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         7\\n          a2    0.46154   1.00000   0.63158        18\\n          a3    0.00000   0.00000   0.00000        11\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11538   0.25000   0.15789        39\\nweighted avg    0.21302   0.46154   0.29150        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         9\\n          a2    0.43590   1.00000   0.60714        17\\n          a3    0.00000   0.00000   0.00000         7\\n         a35    0.00000   0.00000   0.00000         6\\n\\n    accuracy                        0.43590        39\\n   macro avg    0.10897   0.25000   0.15179        39\\nweighted avg    0.19001   0.43590   0.26465        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        10\\n          a2    0.56410   1.00000   0.72131        22\\n          a3    0.00000   0.00000   0.00000         6\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.56410        39\\n   macro avg    0.14103   0.25000   0.18033        39\\nweighted avg    0.31821   0.56410   0.40689        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        10\\n          a2    0.33333   1.00000   0.50000        13\\n          a3    0.00000   0.00000   0.00000        13\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.33333        39\\n   macro avg    0.08333   0.25000   0.12500        39\\nweighted avg    0.11111   0.33333   0.16667        39\\n']\n",
            "Mean Accuracy: 0.4666666666666667\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0,  8,  0],\n",
            "       [ 0, 20,  1],\n",
            "       [ 0, 10,  0]]), array([[ 0,  7,  0,  0],\n",
            "       [ 0, 18,  0,  0],\n",
            "       [ 0, 11,  0,  0],\n",
            "       [ 0,  3,  0,  0]]), array([[ 0,  9,  0,  0],\n",
            "       [ 0, 17,  0,  0],\n",
            "       [ 0,  7,  0,  0],\n",
            "       [ 0,  6,  0,  0]]), array([[ 0, 10,  0,  0],\n",
            "       [ 0, 22,  0,  0],\n",
            "       [ 0,  6,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0, 10,  0,  0],\n",
            "       [ 0, 13,  0,  0],\n",
            "       [ 0, 13,  0,  0],\n",
            "       [ 0,  3,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         8\\n          a2    0.52632   0.95238   0.67797        21\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         0\\n\\n   micro avg    0.51282   0.51282   0.51282        39\\n   macro avg    0.13158   0.23810   0.16949        39\\nweighted avg    0.28340   0.51282   0.36506        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         7\\n          a2    0.46154   1.00000   0.63158        18\\n          a3    0.00000   0.00000   0.00000        11\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11538   0.25000   0.15789        39\\nweighted avg    0.21302   0.46154   0.29150        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         9\\n          a2    0.43590   1.00000   0.60714        17\\n          a3    0.00000   0.00000   0.00000         7\\n         a35    0.00000   0.00000   0.00000         6\\n\\n    accuracy                        0.43590        39\\n   macro avg    0.10897   0.25000   0.15179        39\\nweighted avg    0.19001   0.43590   0.26465        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        10\\n          a2    0.56410   1.00000   0.72131        22\\n          a3    0.00000   0.00000   0.00000         6\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.56410        39\\n   macro avg    0.14103   0.25000   0.18033        39\\nweighted avg    0.31821   0.56410   0.40689        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        10\\n          a2    0.33333   1.00000   0.50000        13\\n          a3    0.00000   0.00000   0.00000        13\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.33333        39\\n   macro avg    0.08333   0.25000   0.12500        39\\nweighted avg    0.11111   0.33333   0.16667        39\\n']\n",
            "Mean Accuracy: 0.4615384615384615\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[2, 5, 1, 0],\n",
            "       [3, 8, 7, 3],\n",
            "       [2, 2, 4, 2],\n",
            "       [0, 0, 0, 0]]), array([[3, 4, 0, 0],\n",
            "       [2, 9, 4, 3],\n",
            "       [2, 7, 2, 0],\n",
            "       [1, 0, 1, 1]]), array([[ 3,  5,  1,  0],\n",
            "       [ 4, 11,  2,  0],\n",
            "       [ 1,  3,  3,  0],\n",
            "       [ 2,  2,  2,  0]]), array([[2, 4, 3, 1],\n",
            "       [8, 8, 6, 0],\n",
            "       [0, 2, 3, 1],\n",
            "       [1, 0, 0, 0]]), array([[1, 6, 3, 0],\n",
            "       [4, 5, 4, 0],\n",
            "       [1, 4, 8, 0],\n",
            "       [0, 0, 2, 1]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.28571   0.25000   0.26667         8\\n          a2    0.53333   0.38095   0.44444        21\\n          a3    0.33333   0.40000   0.36364        10\\n         a35    0.00000   0.00000   0.00000         0\\n\\n    accuracy                        0.35897        39\\n   macro avg    0.28810   0.25774   0.26869        39\\nweighted avg    0.43126   0.35897   0.38726        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.37500   0.42857   0.40000         7\\n          a2    0.45000   0.50000   0.47368        18\\n          a3    0.28571   0.18182   0.22222        11\\n         a35    0.25000   0.33333   0.28571         3\\n\\n    accuracy                        0.38462        39\\n   macro avg    0.34018   0.36093   0.34541        39\\nweighted avg    0.37482   0.38462   0.37507        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.30000   0.33333   0.31579         9\\n          a2    0.52381   0.64706   0.57895        17\\n          a3    0.37500   0.42857   0.40000         7\\n         a35    0.00000   0.00000   0.00000         6\\n\\n    accuracy                        0.43590        39\\n   macro avg    0.29970   0.35224   0.32368        39\\nweighted avg    0.36487   0.43590   0.39703        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.18182   0.20000   0.19048        10\\n          a2    0.57143   0.36364   0.44444        22\\n          a3    0.25000   0.50000   0.33333         6\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.33333        39\\n   macro avg    0.25081   0.26591   0.24206        39\\nweighted avg    0.40743   0.33333   0.35083        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.16667   0.10000   0.12500        10\\n          a2    0.33333   0.38462   0.35714        13\\n          a3    0.47059   0.61538   0.53333        13\\n         a35    1.00000   0.33333   0.50000         3\\n\\n    accuracy                        0.38462        39\\n   macro avg    0.49265   0.35833   0.37887        39\\nweighted avg    0.38763   0.38462   0.36734        39\\n']\n",
            "Mean Accuracy: 0.37948717948717947\n",
            "--------- End of Iteration ---------\n",
            "\n",
            "Training indices: [377, 217, 104, 763, 670, 769, 101, 657, 559, 271, 36, 114, 643, 344, 537, 247, 540, 22, 261, 138, 332, 607, 157, 365, 19, 363, 274, 146, 229, 236, 265, 318, 524, 286, 544, 415, 360, 588, 15, 134, 250, 21, 204, 243, 97, 196, 151, 177, 679, 753, 126, 474, 83, 703, 477, 283, 47, 113, 691, 553, 62, 309, 239, 279, 475, 410, 467, 315, 230, 658, 175, 759, 458, 158, 277, 695, 722, 162, 107, 320, 681, 11, 483, 380, 304, 396, 505, 181, 180, 234, 567, 208, 440, 748, 564, 466, 731, 306, 682, 522, 739, 361, 269, 84, 503, 439, 387, 135, 446, 198, 637, 541, 709, 547, 59, 485, 272, 614, 719, 72, 262, 249, 316, 715, 375, 9, 584, 516, 586, 371, 419, 342, 646, 333, 718, 552, 675, 631, 747, 760, 85, 389, 92, 530, 740, 525, 86, 170, 736, 459, 630, 153, 255, 482, 766, 645, 17, 495, 416, 339, 727, 772, 184, 502, 432, 192, 203, 589, 728, 666, 539, 278, 587, 508, 129, 551, 556, 27, 369, 353, 348, 468, 171, 123, 388, 393, 513, 767, 642, 252, 716, 54, 199, 444, 330, 436, 755, 24, 77, 750, 611, 66, 31, 2, 484, 202, 319, 601, 4, 211, 443, 325, 358, 245, 762, 321, 370, 298, 565, 237, 118, 743, 100, 517, 663, 328, 251, 103, 496, 386, 60, 347, 364, 506, 548, 150, 16, 291, 569, 712, 758, 143, 308, 680, 194, 109, 141, 44, 57, 626, 700, 115, 110, 52, 401, 331, 487, 276, 381, 543, 303, 335, 617, 529, 494, 130, 293, 577, 220, 441, 704, 563, 620, 79, 212, 580, 300, 219, 382, 558, 498, 105, 738, 447, 188, 627, 168, 367, 690, 322, 174, 145, 215, 742, 720, 527, 737, 667, 172, 6, 200, 189, 413, 37, 706, 121, 602, 596, 356, 311, 383, 267, 411, 281, 297, 65, 384, 504, 169, 418, 233, 99, 590, 593, 638, 777, 244, 48, 351, 61, 425, 676, 280, 51, 536, 284, 473, 312, 427, 724, 735, 270, 598, 102, 634, 182, 423, 571, 463, 18, 566, 20, 90, 112, 362, 664, 518, 224, 768, 179, 256, 39, 471, 604, 734, 209, 64, 397, 692, 535, 197, 510, 455, 399, 684, 94, 488, 324, 89, 493, 385, 125, 42, 116, 497, 30, 701, 3, 640, 668, 470, 573, 449, 705, 655, 258, 711, 615, 299, 98, 231, 232, 354, 373, 696, 70, 346, 260, 207, 765, 422, 13, 457, 95, 14, 74, 560, 137, 555, 431, 428, 685, 238, 288, 8, 173, 591, 409, 122, 451, 296, 702, 689, 0, 464, 673, 32, 764, 545, 241, 492, 520, 606, 404, 379, 398, 549, 242, 649, 152, 218, 292, 616, 521, 357, 289, 91, 56, 582, 334, 38, 23, 515, 314, 55, 49, 25, 579, 187, 338, 608, 313, 708, 405, 770, 472, 28, 226, 257, 450, 462, 190, 557, 534, 206, 246, 160, 41, 131, 111, 479, 282, 775, 665, 223, 761, 225, 345, 707, 621, 461, 406, 438, 349, 68, 378, 108, 605, 340, 632, 149, 12, 96, 480, 512, 671, 420, 445, 323, 448, 106, 216, 578, 78, 774, 33, 710, 741, 119, 412, 10, 155, 603, 599, 612, 214, 729, 132, 195, 434, 127, 732, 337, 147, 63, 352, 326, 46, 87, 633, 366, 581, 341, 647, 662, 500, 221, 374, 183, 80, 514, 469, 81, 476, 368, 491, 618, 746, 628, 610, 392, 501, 562, 550, 754, 395, 93, 751, 71, 528, 144, 687, 597, 595, 576, 699, 532, 629, 35, 713, 222, 210, 641, 717, 697, 542, 235, 154, 721, 240, 538, 1, 624, 744, 355, 623, 453, 619, 159, 460, 29, 613, 523, 400, 58, 69, 372, 635, 686, 266, 88, 622]\n",
            "Testing indices: [259, 178, 430, 773, 336, 421, 408, 636, 40, 50, 478, 456, 733, 730, 53, 519, 327, 176, 128, 656, 403, 264, 136, 725, 644, 329, 120, 575, 698, 402, 489, 454, 76, 533, 424, 452, 254, 273, 285, 310, 301, 435, 390, 7, 376, 694, 490, 677, 585, 568, 651, 442, 248, 294, 305, 600, 295, 253, 639, 669, 73, 343, 164, 526, 165, 275, 417, 201, 191, 688, 359, 546, 290, 45, 583, 185, 142, 756, 465, 652, 592, 609, 67, 511, 437, 693, 594, 228, 650, 166, 213, 674, 268, 302, 186, 499, 507, 531, 140, 745, 752, 486, 572, 307, 661, 317, 672, 263, 26, 723, 414, 570, 625, 653, 509, 394, 433, 757, 227, 429, 205, 124, 574, 193, 771, 714, 749, 163, 776, 648, 148, 161, 156, 407, 75, 5, 34, 561, 554, 167, 654, 426, 481, 133, 350, 678, 683, 659, 43, 391, 660, 139, 117, 82, 726, 287]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [259, 178, 430, 773, 336, 421, 408, 636, 40, 50, 478, 456, 733, 730, 53, 519, 327, 176, 128, 656, 403, 264, 136, 725, 644, 329, 120, 575, 698, 402, 489, 454, 76, 533, 424, 452, 254, 273, 285, 310, 301, 435, 390, 7, 376, 694, 490, 677, 585, 568, 651, 442, 248, 294, 305, 600, 295, 253, 639, 669, 73, 343, 164, 526, 165, 275, 417, 201, 191, 688, 359, 546, 290, 45, 583, 185, 142, 756, 465, 652, 592, 609, 67, 511, 437, 693, 594, 228, 650, 166, 213, 674, 268, 302, 186, 499, 507, 531, 140, 745, 752, 486, 572, 307, 661, 317, 672, 263, 26, 723, 414, 570, 625, 653, 509, 394, 433, 757, 227, 429, 205, 124, 574, 193, 771, 714, 749, 163, 776, 648, 148, 161, 156, 407, 75, 5, 34, 561, 554, 167, 654, 426, 481, 133, 350, 678, 683, 659, 43, 391, 660, 139, 117, 82, 726, 287, 17, 495, 416, 339, 727, 772, 184, 502, 432, 192, 203, 589, 728, 666, 539, 278, 587, 508, 129, 551, 556, 27, 369, 353, 348, 468, 171, 123, 388, 393, 513, 767, 642, 252, 716, 54, 199, 444, 330, 436, 755, 24, 77, 750, 611, 66, 31, 2, 484, 202, 319, 601, 4, 211, 443, 325, 358, 245, 762, 321, 370, 298, 565, 237, 118, 743, 100, 517, 663, 328, 251, 103, 496, 386, 60, 347, 364, 506, 548, 150, 16, 291, 569, 712, 758, 143, 308, 680, 194, 109, 141, 44, 57, 626, 700, 115, 110, 52, 401, 331, 487, 276, 381, 543, 303, 335, 617, 529, 494, 130, 293, 577, 220, 441, 704, 563, 620, 79, 212, 580, 300, 219, 382, 558, 498, 105, 738, 447, 188, 627, 168, 367, 690, 322, 174, 145, 215, 742, 720, 527, 737, 667, 172, 6, 200, 189, 413, 37, 706, 121, 602, 596, 356, 311, 383, 267, 411, 281, 297, 65, 384, 504, 169, 418, 233, 99, 590, 593, 638, 777, 244, 48, 351, 61, 425, 676, 280, 51, 536, 284, 473, 312, 427, 724, 735, 270, 598, 102, 634, 182, 423, 571, 463, 18, 566, 20, 90, 112, 362, 664, 518, 224, 768, 179, 256, 39, 471, 604, 734, 209, 64, 397, 692, 535, 197, 510, 455, 399, 684, 94, 488, 324, 89, 493, 385, 125, 42, 116, 497, 30, 701, 3, 640, 668, 470, 573, 449, 705, 655, 258, 711, 615, 299, 98, 231, 232, 354, 373, 696, 70, 346, 260, 207, 765, 422, 13, 457, 95, 14, 74, 560, 137, 555, 431, 428, 685, 238, 288, 8, 173, 591, 409, 122, 451, 296, 702, 689, 0, 464, 673, 32, 764, 545, 241, 492, 520, 606, 404, 379, 398, 549, 242, 649, 152, 218, 292, 616, 521, 357, 289, 91, 56, 582, 334, 38, 23, 515, 314, 55, 49, 25, 579, 187, 338, 608, 313, 708, 405, 770, 472, 28, 226, 257, 450, 462, 190, 557, 534, 206, 246, 160, 41, 131, 111, 479, 282, 775, 665, 223, 761, 225, 345, 707, 621, 461, 406, 438, 349, 68, 378, 108, 605, 340, 632, 149, 12, 96, 480, 512, 671, 420, 445, 323, 448, 106, 216, 578, 78, 774, 33, 710, 741, 119, 412, 10, 155, 603, 599, 612, 214, 729, 132, 195, 434, 127, 732, 337, 147, 63, 352, 326, 46, 87, 633, 366, 581, 341, 647, 662, 500, 221, 374, 183, 80, 514, 469, 81, 476, 368, 491, 618, 746, 628, 610, 392, 501, 562, 550, 754, 395, 93, 751, 71, 528, 144, 687, 597, 595, 576, 699, 532, 629, 35, 713, 222, 210, 641, 717, 697, 542, 235, 154, 721, 240, 538, 1, 624, 744, 355, 623, 453, 619, 159, 460, 29, 613, 523, 400, 58, 69, 372, 635, 686, 266, 88, 622]\n",
            "Testing indices: [377, 217, 104, 763, 670, 769, 101, 657, 559, 271, 36, 114, 643, 344, 537, 247, 540, 22, 261, 138, 332, 607, 157, 365, 19, 363, 274, 146, 229, 236, 265, 318, 524, 286, 544, 415, 360, 588, 15, 134, 250, 21, 204, 243, 97, 196, 151, 177, 679, 753, 126, 474, 83, 703, 477, 283, 47, 113, 691, 553, 62, 309, 239, 279, 475, 410, 467, 315, 230, 658, 175, 759, 458, 158, 277, 695, 722, 162, 107, 320, 681, 11, 483, 380, 304, 396, 505, 181, 180, 234, 567, 208, 440, 748, 564, 466, 731, 306, 682, 522, 739, 361, 269, 84, 503, 439, 387, 135, 446, 198, 637, 541, 709, 547, 59, 485, 272, 614, 719, 72, 262, 249, 316, 715, 375, 9, 584, 516, 586, 371, 419, 342, 646, 333, 718, 552, 675, 631, 747, 760, 85, 389, 92, 530, 740, 525, 86, 170, 736, 459, 630, 153, 255, 482, 766, 645]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [259, 178, 430, 773, 336, 421, 408, 636, 40, 50, 478, 456, 733, 730, 53, 519, 327, 176, 128, 656, 403, 264, 136, 725, 644, 329, 120, 575, 698, 402, 489, 454, 76, 533, 424, 452, 254, 273, 285, 310, 301, 435, 390, 7, 376, 694, 490, 677, 585, 568, 651, 442, 248, 294, 305, 600, 295, 253, 639, 669, 73, 343, 164, 526, 165, 275, 417, 201, 191, 688, 359, 546, 290, 45, 583, 185, 142, 756, 465, 652, 592, 609, 67, 511, 437, 693, 594, 228, 650, 166, 213, 674, 268, 302, 186, 499, 507, 531, 140, 745, 752, 486, 572, 307, 661, 317, 672, 263, 26, 723, 414, 570, 625, 653, 509, 394, 433, 757, 227, 429, 205, 124, 574, 193, 771, 714, 749, 163, 776, 648, 148, 161, 156, 407, 75, 5, 34, 561, 554, 167, 654, 426, 481, 133, 350, 678, 683, 659, 43, 391, 660, 139, 117, 82, 726, 287, 377, 217, 104, 763, 670, 769, 101, 657, 559, 271, 36, 114, 643, 344, 537, 247, 540, 22, 261, 138, 332, 607, 157, 365, 19, 363, 274, 146, 229, 236, 265, 318, 524, 286, 544, 415, 360, 588, 15, 134, 250, 21, 204, 243, 97, 196, 151, 177, 679, 753, 126, 474, 83, 703, 477, 283, 47, 113, 691, 553, 62, 309, 239, 279, 475, 410, 467, 315, 230, 658, 175, 759, 458, 158, 277, 695, 722, 162, 107, 320, 681, 11, 483, 380, 304, 396, 505, 181, 180, 234, 567, 208, 440, 748, 564, 466, 731, 306, 682, 522, 739, 361, 269, 84, 503, 439, 387, 135, 446, 198, 637, 541, 709, 547, 59, 485, 272, 614, 719, 72, 262, 249, 316, 715, 375, 9, 584, 516, 586, 371, 419, 342, 646, 333, 718, 552, 675, 631, 747, 760, 85, 389, 92, 530, 740, 525, 86, 170, 736, 459, 630, 153, 255, 482, 766, 645, 411, 281, 297, 65, 384, 504, 169, 418, 233, 99, 590, 593, 638, 777, 244, 48, 351, 61, 425, 676, 280, 51, 536, 284, 473, 312, 427, 724, 735, 270, 598, 102, 634, 182, 423, 571, 463, 18, 566, 20, 90, 112, 362, 664, 518, 224, 768, 179, 256, 39, 471, 604, 734, 209, 64, 397, 692, 535, 197, 510, 455, 399, 684, 94, 488, 324, 89, 493, 385, 125, 42, 116, 497, 30, 701, 3, 640, 668, 470, 573, 449, 705, 655, 258, 711, 615, 299, 98, 231, 232, 354, 373, 696, 70, 346, 260, 207, 765, 422, 13, 457, 95, 14, 74, 560, 137, 555, 431, 428, 685, 238, 288, 8, 173, 591, 409, 122, 451, 296, 702, 689, 0, 464, 673, 32, 764, 545, 241, 492, 520, 606, 404, 379, 398, 549, 242, 649, 152, 218, 292, 616, 521, 357, 289, 91, 56, 582, 334, 38, 23, 515, 314, 55, 49, 25, 579, 187, 338, 608, 313, 708, 405, 770, 472, 28, 226, 257, 450, 462, 190, 557, 534, 206, 246, 160, 41, 131, 111, 479, 282, 775, 665, 223, 761, 225, 345, 707, 621, 461, 406, 438, 349, 68, 378, 108, 605, 340, 632, 149, 12, 96, 480, 512, 671, 420, 445, 323, 448, 106, 216, 578, 78, 774, 33, 710, 741, 119, 412, 10, 155, 603, 599, 612, 214, 729, 132, 195, 434, 127, 732, 337, 147, 63, 352, 326, 46, 87, 633, 366, 581, 341, 647, 662, 500, 221, 374, 183, 80, 514, 469, 81, 476, 368, 491, 618, 746, 628, 610, 392, 501, 562, 550, 754, 395, 93, 751, 71, 528, 144, 687, 597, 595, 576, 699, 532, 629, 35, 713, 222, 210, 641, 717, 697, 542, 235, 154, 721, 240, 538, 1, 624, 744, 355, 623, 453, 619, 159, 460, 29, 613, 523, 400, 58, 69, 372, 635, 686, 266, 88, 622]\n",
            "Testing indices: [17, 495, 416, 339, 727, 772, 184, 502, 432, 192, 203, 589, 728, 666, 539, 278, 587, 508, 129, 551, 556, 27, 369, 353, 348, 468, 171, 123, 388, 393, 513, 767, 642, 252, 716, 54, 199, 444, 330, 436, 755, 24, 77, 750, 611, 66, 31, 2, 484, 202, 319, 601, 4, 211, 443, 325, 358, 245, 762, 321, 370, 298, 565, 237, 118, 743, 100, 517, 663, 328, 251, 103, 496, 386, 60, 347, 364, 506, 548, 150, 16, 291, 569, 712, 758, 143, 308, 680, 194, 109, 141, 44, 57, 626, 700, 115, 110, 52, 401, 331, 487, 276, 381, 543, 303, 335, 617, 529, 494, 130, 293, 577, 220, 441, 704, 563, 620, 79, 212, 580, 300, 219, 382, 558, 498, 105, 738, 447, 188, 627, 168, 367, 690, 322, 174, 145, 215, 742, 720, 527, 737, 667, 172, 6, 200, 189, 413, 37, 706, 121, 602, 596, 356, 311, 383, 267]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [259, 178, 430, 773, 336, 421, 408, 636, 40, 50, 478, 456, 733, 730, 53, 519, 327, 176, 128, 656, 403, 264, 136, 725, 644, 329, 120, 575, 698, 402, 489, 454, 76, 533, 424, 452, 254, 273, 285, 310, 301, 435, 390, 7, 376, 694, 490, 677, 585, 568, 651, 442, 248, 294, 305, 600, 295, 253, 639, 669, 73, 343, 164, 526, 165, 275, 417, 201, 191, 688, 359, 546, 290, 45, 583, 185, 142, 756, 465, 652, 592, 609, 67, 511, 437, 693, 594, 228, 650, 166, 213, 674, 268, 302, 186, 499, 507, 531, 140, 745, 752, 486, 572, 307, 661, 317, 672, 263, 26, 723, 414, 570, 625, 653, 509, 394, 433, 757, 227, 429, 205, 124, 574, 193, 771, 714, 749, 163, 776, 648, 148, 161, 156, 407, 75, 5, 34, 561, 554, 167, 654, 426, 481, 133, 350, 678, 683, 659, 43, 391, 660, 139, 117, 82, 726, 287, 377, 217, 104, 763, 670, 769, 101, 657, 559, 271, 36, 114, 643, 344, 537, 247, 540, 22, 261, 138, 332, 607, 157, 365, 19, 363, 274, 146, 229, 236, 265, 318, 524, 286, 544, 415, 360, 588, 15, 134, 250, 21, 204, 243, 97, 196, 151, 177, 679, 753, 126, 474, 83, 703, 477, 283, 47, 113, 691, 553, 62, 309, 239, 279, 475, 410, 467, 315, 230, 658, 175, 759, 458, 158, 277, 695, 722, 162, 107, 320, 681, 11, 483, 380, 304, 396, 505, 181, 180, 234, 567, 208, 440, 748, 564, 466, 731, 306, 682, 522, 739, 361, 269, 84, 503, 439, 387, 135, 446, 198, 637, 541, 709, 547, 59, 485, 272, 614, 719, 72, 262, 249, 316, 715, 375, 9, 584, 516, 586, 371, 419, 342, 646, 333, 718, 552, 675, 631, 747, 760, 85, 389, 92, 530, 740, 525, 86, 170, 736, 459, 630, 153, 255, 482, 766, 645, 17, 495, 416, 339, 727, 772, 184, 502, 432, 192, 203, 589, 728, 666, 539, 278, 587, 508, 129, 551, 556, 27, 369, 353, 348, 468, 171, 123, 388, 393, 513, 767, 642, 252, 716, 54, 199, 444, 330, 436, 755, 24, 77, 750, 611, 66, 31, 2, 484, 202, 319, 601, 4, 211, 443, 325, 358, 245, 762, 321, 370, 298, 565, 237, 118, 743, 100, 517, 663, 328, 251, 103, 496, 386, 60, 347, 364, 506, 548, 150, 16, 291, 569, 712, 758, 143, 308, 680, 194, 109, 141, 44, 57, 626, 700, 115, 110, 52, 401, 331, 487, 276, 381, 543, 303, 335, 617, 529, 494, 130, 293, 577, 220, 441, 704, 563, 620, 79, 212, 580, 300, 219, 382, 558, 498, 105, 738, 447, 188, 627, 168, 367, 690, 322, 174, 145, 215, 742, 720, 527, 737, 667, 172, 6, 200, 189, 413, 37, 706, 121, 602, 596, 356, 311, 383, 267, 579, 187, 338, 608, 313, 708, 405, 770, 472, 28, 226, 257, 450, 462, 190, 557, 534, 206, 246, 160, 41, 131, 111, 479, 282, 775, 665, 223, 761, 225, 345, 707, 621, 461, 406, 438, 349, 68, 378, 108, 605, 340, 632, 149, 12, 96, 480, 512, 671, 420, 445, 323, 448, 106, 216, 578, 78, 774, 33, 710, 741, 119, 412, 10, 155, 603, 599, 612, 214, 729, 132, 195, 434, 127, 732, 337, 147, 63, 352, 326, 46, 87, 633, 366, 581, 341, 647, 662, 500, 221, 374, 183, 80, 514, 469, 81, 476, 368, 491, 618, 746, 628, 610, 392, 501, 562, 550, 754, 395, 93, 751, 71, 528, 144, 687, 597, 595, 576, 699, 532, 629, 35, 713, 222, 210, 641, 717, 697, 542, 235, 154, 721, 240, 538, 1, 624, 744, 355, 623, 453, 619, 159, 460, 29, 613, 523, 400, 58, 69, 372, 635, 686, 266, 88, 622]\n",
            "Testing indices: [411, 281, 297, 65, 384, 504, 169, 418, 233, 99, 590, 593, 638, 777, 244, 48, 351, 61, 425, 676, 280, 51, 536, 284, 473, 312, 427, 724, 735, 270, 598, 102, 634, 182, 423, 571, 463, 18, 566, 20, 90, 112, 362, 664, 518, 224, 768, 179, 256, 39, 471, 604, 734, 209, 64, 397, 692, 535, 197, 510, 455, 399, 684, 94, 488, 324, 89, 493, 385, 125, 42, 116, 497, 30, 701, 3, 640, 668, 470, 573, 449, 705, 655, 258, 711, 615, 299, 98, 231, 232, 354, 373, 696, 70, 346, 260, 207, 765, 422, 13, 457, 95, 14, 74, 560, 137, 555, 431, 428, 685, 238, 288, 8, 173, 591, 409, 122, 451, 296, 702, 689, 0, 464, 673, 32, 764, 545, 241, 492, 520, 606, 404, 379, 398, 549, 242, 649, 152, 218, 292, 616, 521, 357, 289, 91, 56, 582, 334, 38, 23, 515, 314, 55, 49, 25]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [259, 178, 430, 773, 336, 421, 408, 636, 40, 50, 478, 456, 733, 730, 53, 519, 327, 176, 128, 656, 403, 264, 136, 725, 644, 329, 120, 575, 698, 402, 489, 454, 76, 533, 424, 452, 254, 273, 285, 310, 301, 435, 390, 7, 376, 694, 490, 677, 585, 568, 651, 442, 248, 294, 305, 600, 295, 253, 639, 669, 73, 343, 164, 526, 165, 275, 417, 201, 191, 688, 359, 546, 290, 45, 583, 185, 142, 756, 465, 652, 592, 609, 67, 511, 437, 693, 594, 228, 650, 166, 213, 674, 268, 302, 186, 499, 507, 531, 140, 745, 752, 486, 572, 307, 661, 317, 672, 263, 26, 723, 414, 570, 625, 653, 509, 394, 433, 757, 227, 429, 205, 124, 574, 193, 771, 714, 749, 163, 776, 648, 148, 161, 156, 407, 75, 5, 34, 561, 554, 167, 654, 426, 481, 133, 350, 678, 683, 659, 43, 391, 660, 139, 117, 82, 726, 287, 377, 217, 104, 763, 670, 769, 101, 657, 559, 271, 36, 114, 643, 344, 537, 247, 540, 22, 261, 138, 332, 607, 157, 365, 19, 363, 274, 146, 229, 236, 265, 318, 524, 286, 544, 415, 360, 588, 15, 134, 250, 21, 204, 243, 97, 196, 151, 177, 679, 753, 126, 474, 83, 703, 477, 283, 47, 113, 691, 553, 62, 309, 239, 279, 475, 410, 467, 315, 230, 658, 175, 759, 458, 158, 277, 695, 722, 162, 107, 320, 681, 11, 483, 380, 304, 396, 505, 181, 180, 234, 567, 208, 440, 748, 564, 466, 731, 306, 682, 522, 739, 361, 269, 84, 503, 439, 387, 135, 446, 198, 637, 541, 709, 547, 59, 485, 272, 614, 719, 72, 262, 249, 316, 715, 375, 9, 584, 516, 586, 371, 419, 342, 646, 333, 718, 552, 675, 631, 747, 760, 85, 389, 92, 530, 740, 525, 86, 170, 736, 459, 630, 153, 255, 482, 766, 645, 17, 495, 416, 339, 727, 772, 184, 502, 432, 192, 203, 589, 728, 666, 539, 278, 587, 508, 129, 551, 556, 27, 369, 353, 348, 468, 171, 123, 388, 393, 513, 767, 642, 252, 716, 54, 199, 444, 330, 436, 755, 24, 77, 750, 611, 66, 31, 2, 484, 202, 319, 601, 4, 211, 443, 325, 358, 245, 762, 321, 370, 298, 565, 237, 118, 743, 100, 517, 663, 328, 251, 103, 496, 386, 60, 347, 364, 506, 548, 150, 16, 291, 569, 712, 758, 143, 308, 680, 194, 109, 141, 44, 57, 626, 700, 115, 110, 52, 401, 331, 487, 276, 381, 543, 303, 335, 617, 529, 494, 130, 293, 577, 220, 441, 704, 563, 620, 79, 212, 580, 300, 219, 382, 558, 498, 105, 738, 447, 188, 627, 168, 367, 690, 322, 174, 145, 215, 742, 720, 527, 737, 667, 172, 6, 200, 189, 413, 37, 706, 121, 602, 596, 356, 311, 383, 267, 411, 281, 297, 65, 384, 504, 169, 418, 233, 99, 590, 593, 638, 777, 244, 48, 351, 61, 425, 676, 280, 51, 536, 284, 473, 312, 427, 724, 735, 270, 598, 102, 634, 182, 423, 571, 463, 18, 566, 20, 90, 112, 362, 664, 518, 224, 768, 179, 256, 39, 471, 604, 734, 209, 64, 397, 692, 535, 197, 510, 455, 399, 684, 94, 488, 324, 89, 493, 385, 125, 42, 116, 497, 30, 701, 3, 640, 668, 470, 573, 449, 705, 655, 258, 711, 615, 299, 98, 231, 232, 354, 373, 696, 70, 346, 260, 207, 765, 422, 13, 457, 95, 14, 74, 560, 137, 555, 431, 428, 685, 238, 288, 8, 173, 591, 409, 122, 451, 296, 702, 689, 0, 464, 673, 32, 764, 545, 241, 492, 520, 606, 404, 379, 398, 549, 242, 649, 152, 218, 292, 616, 521, 357, 289, 91, 56, 582, 334, 38, 23, 515, 314, 55, 49, 25]\n",
            "Testing indices: [579, 187, 338, 608, 313, 708, 405, 770, 472, 28, 226, 257, 450, 462, 190, 557, 534, 206, 246, 160, 41, 131, 111, 479, 282, 775, 665, 223, 761, 225, 345, 707, 621, 461, 406, 438, 349, 68, 378, 108, 605, 340, 632, 149, 12, 96, 480, 512, 671, 420, 445, 323, 448, 106, 216, 578, 78, 774, 33, 710, 741, 119, 412, 10, 155, 603, 599, 612, 214, 729, 132, 195, 434, 127, 732, 337, 147, 63, 352, 326, 46, 87, 633, 366, 581, 341, 647, 662, 500, 221, 374, 183, 80, 514, 469, 81, 476, 368, 491, 618, 746, 628, 610, 392, 501, 562, 550, 754, 395, 93, 751, 71, 528, 144, 687, 597, 595, 576, 699, 532, 629, 35, 713, 222, 210, 641, 717, 697, 542, 235, 154, 721, 240, 538, 1, 624, 744, 355, 623, 453, 619, 159, 460, 29, 613, 523, 400, 58, 69, 372, 635, 686, 266, 88, 622]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [164, 102, 0, 178, 121, 118, 57, 31, 110, 1, 145, 73, 81, 43, 122, 92, 3, 170, 29, 176, 183, 161, 155, 42, 59, 100, 150, 139, 133, 76, 130, 2, 179, 152, 146, 120, 128, 93, 54, 24, 131, 30, 115, 70, 114, 182, 113, 11, 168, 16, 60, 169, 18, 90, 94, 159, 107, 83, 50, 61, 175, 69, 165, 172, 137, 141, 186, 99, 142, 65, 89, 187, 34, 5, 27, 88, 21, 33, 45, 35, 85, 91, 97, 140, 194, 6, 192, 106, 53, 96, 25, 58, 191, 44, 79, 32, 55, 135, 84, 37, 166, 66, 156, 188, 193, 72, 125, 9, 124, 20, 36, 101, 129, 23, 4, 82, 119, 39, 157, 177, 149, 151, 136, 148, 46, 180, 28, 71, 184, 153, 95, 52, 171, 132, 154, 117, 15, 8, 147, 189, 123, 78, 160, 138, 64, 105, 116, 162, 62, 98, 181, 174, 80, 40, 63, 144]\n",
            "Testing indices: [10, 126, 67, 143, 173, 7, 109, 190, 22, 19, 68, 75, 51, 13, 26, 17, 14, 112, 87, 127, 103, 134, 163, 111, 47, 12, 48, 167, 86, 49, 104, 108, 56, 185, 77, 38, 41, 158, 74]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [10, 126, 67, 143, 173, 7, 109, 190, 22, 19, 68, 75, 51, 13, 26, 17, 14, 112, 87, 127, 103, 134, 163, 111, 47, 12, 48, 167, 86, 49, 104, 108, 56, 185, 77, 38, 41, 158, 74, 24, 131, 30, 115, 70, 114, 182, 113, 11, 168, 16, 60, 169, 18, 90, 94, 159, 107, 83, 50, 61, 175, 69, 165, 172, 137, 141, 186, 99, 142, 65, 89, 187, 34, 5, 27, 88, 21, 33, 45, 35, 85, 91, 97, 140, 194, 6, 192, 106, 53, 96, 25, 58, 191, 44, 79, 32, 55, 135, 84, 37, 166, 66, 156, 188, 193, 72, 125, 9, 124, 20, 36, 101, 129, 23, 4, 82, 119, 39, 157, 177, 149, 151, 136, 148, 46, 180, 28, 71, 184, 153, 95, 52, 171, 132, 154, 117, 15, 8, 147, 189, 123, 78, 160, 138, 64, 105, 116, 162, 62, 98, 181, 174, 80, 40, 63, 144]\n",
            "Testing indices: [164, 102, 0, 178, 121, 118, 57, 31, 110, 1, 145, 73, 81, 43, 122, 92, 3, 170, 29, 176, 183, 161, 155, 42, 59, 100, 150, 139, 133, 76, 130, 2, 179, 152, 146, 120, 128, 93, 54]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [10, 126, 67, 143, 173, 7, 109, 190, 22, 19, 68, 75, 51, 13, 26, 17, 14, 112, 87, 127, 103, 134, 163, 111, 47, 12, 48, 167, 86, 49, 104, 108, 56, 185, 77, 38, 41, 158, 74, 164, 102, 0, 178, 121, 118, 57, 31, 110, 1, 145, 73, 81, 43, 122, 92, 3, 170, 29, 176, 183, 161, 155, 42, 59, 100, 150, 139, 133, 76, 130, 2, 179, 152, 146, 120, 128, 93, 54, 45, 35, 85, 91, 97, 140, 194, 6, 192, 106, 53, 96, 25, 58, 191, 44, 79, 32, 55, 135, 84, 37, 166, 66, 156, 188, 193, 72, 125, 9, 124, 20, 36, 101, 129, 23, 4, 82, 119, 39, 157, 177, 149, 151, 136, 148, 46, 180, 28, 71, 184, 153, 95, 52, 171, 132, 154, 117, 15, 8, 147, 189, 123, 78, 160, 138, 64, 105, 116, 162, 62, 98, 181, 174, 80, 40, 63, 144]\n",
            "Testing indices: [24, 131, 30, 115, 70, 114, 182, 113, 11, 168, 16, 60, 169, 18, 90, 94, 159, 107, 83, 50, 61, 175, 69, 165, 172, 137, 141, 186, 99, 142, 65, 89, 187, 34, 5, 27, 88, 21, 33]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [10, 126, 67, 143, 173, 7, 109, 190, 22, 19, 68, 75, 51, 13, 26, 17, 14, 112, 87, 127, 103, 134, 163, 111, 47, 12, 48, 167, 86, 49, 104, 108, 56, 185, 77, 38, 41, 158, 74, 164, 102, 0, 178, 121, 118, 57, 31, 110, 1, 145, 73, 81, 43, 122, 92, 3, 170, 29, 176, 183, 161, 155, 42, 59, 100, 150, 139, 133, 76, 130, 2, 179, 152, 146, 120, 128, 93, 54, 24, 131, 30, 115, 70, 114, 182, 113, 11, 168, 16, 60, 169, 18, 90, 94, 159, 107, 83, 50, 61, 175, 69, 165, 172, 137, 141, 186, 99, 142, 65, 89, 187, 34, 5, 27, 88, 21, 33, 39, 157, 177, 149, 151, 136, 148, 46, 180, 28, 71, 184, 153, 95, 52, 171, 132, 154, 117, 15, 8, 147, 189, 123, 78, 160, 138, 64, 105, 116, 162, 62, 98, 181, 174, 80, 40, 63, 144]\n",
            "Testing indices: [45, 35, 85, 91, 97, 140, 194, 6, 192, 106, 53, 96, 25, 58, 191, 44, 79, 32, 55, 135, 84, 37, 166, 66, 156, 188, 193, 72, 125, 9, 124, 20, 36, 101, 129, 23, 4, 82, 119]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [10, 126, 67, 143, 173, 7, 109, 190, 22, 19, 68, 75, 51, 13, 26, 17, 14, 112, 87, 127, 103, 134, 163, 111, 47, 12, 48, 167, 86, 49, 104, 108, 56, 185, 77, 38, 41, 158, 74, 164, 102, 0, 178, 121, 118, 57, 31, 110, 1, 145, 73, 81, 43, 122, 92, 3, 170, 29, 176, 183, 161, 155, 42, 59, 100, 150, 139, 133, 76, 130, 2, 179, 152, 146, 120, 128, 93, 54, 24, 131, 30, 115, 70, 114, 182, 113, 11, 168, 16, 60, 169, 18, 90, 94, 159, 107, 83, 50, 61, 175, 69, 165, 172, 137, 141, 186, 99, 142, 65, 89, 187, 34, 5, 27, 88, 21, 33, 45, 35, 85, 91, 97, 140, 194, 6, 192, 106, 53, 96, 25, 58, 191, 44, 79, 32, 55, 135, 84, 37, 166, 66, 156, 188, 193, 72, 125, 9, 124, 20, 36, 101, 129, 23, 4, 82, 119]\n",
            "Testing indices: [39, 157, 177, 149, 151, 136, 148, 46, 180, 28, 71, 184, 153, 95, 52, 171, 132, 154, 117, 15, 8, 147, 189, 123, 78, 160, 138, 64, 105, 116, 162, 62, 98, 181, 174, 80, 40, 63, 144]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "--------- Iteration 4 ---------\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 30,  0,  0],\n",
            "       [ 0, 73,  0,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0,  8,  0,  0]]), array([[ 0, 31,  0,  0],\n",
            "       [ 0, 78,  0,  0],\n",
            "       [ 0, 37,  0,  0],\n",
            "       [ 0, 10,  0,  0]]), array([[ 0, 30,  0,  0],\n",
            "       [ 0, 77,  0,  0],\n",
            "       [ 0, 37,  0,  0],\n",
            "       [ 0, 12,  0,  0]]), array([[ 0, 40,  0,  0],\n",
            "       [ 0, 67,  0,  0],\n",
            "       [ 0, 39,  0,  0],\n",
            "       [ 0,  9,  0,  0]]), array([[ 0, 43,  0,  0],\n",
            "       [ 0, 65,  0,  0],\n",
            "       [ 0, 37,  0,  0],\n",
            "       [ 0, 10,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        30\\n          a2    0.46795   1.00000   0.63755        73\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000         8\\n\\n    accuracy                        0.46795       156\\n   macro avg    0.11699   0.25000   0.15939       156\\nweighted avg    0.21898   0.46795   0.29834       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        31\\n          a2    0.50000   1.00000   0.66667        78\\n          a3    0.00000   0.00000   0.00000        37\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.50000       156\\n   macro avg    0.12500   0.25000   0.16667       156\\nweighted avg    0.25000   0.50000   0.33333       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        30\\n          a2    0.49359   1.00000   0.66094        77\\n          a3    0.00000   0.00000   0.00000        37\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.49359       156\\n   macro avg    0.12340   0.25000   0.16524       156\\nweighted avg    0.24363   0.49359   0.32624       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        40\\n          a2    0.43226   1.00000   0.60360        67\\n          a3    0.00000   0.00000   0.00000        39\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.43226       155\\n   macro avg    0.10806   0.25000   0.15090       155\\nweighted avg    0.18685   0.43226   0.26091       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        43\\n          a2    0.41935   1.00000   0.59091        65\\n          a3    0.00000   0.00000   0.00000        37\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.41935       155\\n   macro avg    0.10484   0.25000   0.14773       155\\nweighted avg    0.17586   0.41935   0.24780       155\\n']\n",
            "Mean Accuracy: 0.46263027295285364\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 30,  0,  0],\n",
            "       [ 0, 69,  4,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0,  8,  0,  0]]), array([[ 0, 31,  0,  0],\n",
            "       [ 0, 77,  1,  0],\n",
            "       [ 0, 37,  0,  0],\n",
            "       [ 0,  9,  1,  0]]), array([[ 0, 30,  0,  0],\n",
            "       [ 0, 77,  0,  0],\n",
            "       [ 0, 37,  0,  0],\n",
            "       [ 0, 12,  0,  0]]), array([[ 0, 39,  1,  0],\n",
            "       [ 0, 67,  0,  0],\n",
            "       [ 0, 39,  0,  0],\n",
            "       [ 0,  9,  0,  0]]), array([[ 0, 43,  0,  0],\n",
            "       [ 0, 64,  1,  0],\n",
            "       [ 0, 37,  0,  0],\n",
            "       [ 0, 10,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        30\\n          a2    0.45395   0.94521   0.61333        73\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000         8\\n\\n    accuracy                        0.44231       156\\n   macro avg    0.11349   0.23630   0.15333       156\\nweighted avg    0.21242   0.44231   0.28701       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        31\\n          a2    0.50000   0.98718   0.66379        78\\n          a3    0.00000   0.00000   0.00000        37\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.49359       156\\n   macro avg    0.12500   0.24679   0.16595       156\\nweighted avg    0.25000   0.49359   0.33190       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        30\\n          a2    0.49359   1.00000   0.66094        77\\n          a3    0.00000   0.00000   0.00000        37\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.49359       156\\n   macro avg    0.12340   0.25000   0.16524       156\\nweighted avg    0.24363   0.49359   0.32624       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        40\\n          a2    0.43506   1.00000   0.60633        67\\n          a3    0.00000   0.00000   0.00000        39\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.43226       155\\n   macro avg    0.10877   0.25000   0.15158       155\\nweighted avg    0.18806   0.43226   0.26209       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        43\\n          a2    0.41558   0.98462   0.58447        65\\n          a3    0.00000   0.00000   0.00000        37\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.41290       155\\n   macro avg    0.10390   0.24615   0.14612       155\\nweighted avg    0.17428   0.41290   0.24510       155\\n']\n",
            "Mean Accuracy: 0.4549296939619521\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 5, 15,  8,  2],\n",
            "       [17, 34, 16,  6],\n",
            "       [10, 19, 10,  6],\n",
            "       [ 5,  1,  2,  0]]), array([[11, 18,  2,  0],\n",
            "       [15, 43, 18,  2],\n",
            "       [ 9, 13, 12,  3],\n",
            "       [ 2,  3,  4,  1]]), array([[15, 10,  4,  1],\n",
            "       [21, 32, 20,  4],\n",
            "       [ 7, 19, 10,  1],\n",
            "       [ 2,  4,  5,  1]]), array([[14, 15, 11,  0],\n",
            "       [15, 28, 21,  3],\n",
            "       [ 8, 21,  4,  6],\n",
            "       [ 0,  4,  5,  0]]), array([[13, 15, 14,  1],\n",
            "       [14, 27, 22,  2],\n",
            "       [ 5, 16, 14,  2],\n",
            "       [ 2,  4,  2,  2]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.13514   0.16667   0.14925        30\\n          a2    0.49275   0.46575   0.47887        73\\n          a3    0.27778   0.22222   0.24691        45\\n         a35    0.00000   0.00000   0.00000         8\\n\\n    accuracy                        0.31410       156\\n   macro avg    0.22642   0.21366   0.21876       156\\nweighted avg    0.33670   0.31410   0.32402       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.29730   0.35484   0.32353        31\\n          a2    0.55844   0.55128   0.55484        78\\n          a3    0.33333   0.32432   0.32877        37\\n         a35    0.16667   0.10000   0.12500        10\\n\\n    accuracy                        0.42949       156\\n   macro avg    0.33893   0.33261   0.33303       156\\nweighted avg    0.42804   0.42949   0.42770       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.33333   0.50000   0.40000        30\\n          a2    0.49231   0.41558   0.45070        77\\n          a3    0.25641   0.27027   0.26316        37\\n         a35    0.14286   0.08333   0.10526        12\\n\\n    accuracy                        0.37179       156\\n   macro avg    0.30623   0.31730   0.30478       156\\nweighted avg    0.37890   0.37179   0.36990       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.37838   0.35000   0.36364        40\\n          a2    0.41176   0.41791   0.41481        67\\n          a3    0.09756   0.10256   0.10000        39\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.29677       155\\n   macro avg    0.22193   0.21762   0.21961       155\\nweighted avg    0.30018   0.29677   0.29831       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.38235   0.30233   0.33766        43\\n          a2    0.43548   0.41538   0.42520        65\\n          a3    0.26923   0.37838   0.31461        37\\n         a35    0.28571   0.20000   0.23529        10\\n\\n    accuracy                        0.36129       155\\n   macro avg    0.34320   0.32402   0.32819       155\\nweighted avg    0.37140   0.36129   0.36226       155\\n']\n",
            "Mean Accuracy: 0.35468982630272955\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0,  8,  0,  0],\n",
            "       [ 0, 18,  0,  0],\n",
            "       [ 0, 10,  0,  0],\n",
            "       [ 0,  3,  0,  0]]), array([[ 0, 10,  0,  0],\n",
            "       [ 0, 14,  0,  0],\n",
            "       [ 0, 14,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0, 11,  0,  0],\n",
            "       [ 0, 14,  0,  0],\n",
            "       [ 0, 10,  0,  0],\n",
            "       [ 0,  4,  0,  0]]), array([[ 0, 11,  0,  0],\n",
            "       [ 0, 21,  0,  0],\n",
            "       [ 0,  6,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0, 10,  0,  0],\n",
            "       [ 0, 12,  0,  0],\n",
            "       [ 0, 14,  0,  0],\n",
            "       [ 0,  3,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         8\\n          a2    0.46154   1.00000   0.63158        18\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11538   0.25000   0.15789        39\\nweighted avg    0.21302   0.46154   0.29150        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        10\\n          a2    0.35897   1.00000   0.52830        14\\n          a3    0.00000   0.00000   0.00000        14\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.35897        39\\n   macro avg    0.08974   0.25000   0.13208        39\\nweighted avg    0.12886   0.35897   0.18965        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        11\\n          a2    0.35897   1.00000   0.52830        14\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         4\\n\\n    accuracy                        0.35897        39\\n   macro avg    0.08974   0.25000   0.13208        39\\nweighted avg    0.12886   0.35897   0.18965        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        11\\n          a2    0.53846   1.00000   0.70000        21\\n          a3    0.00000   0.00000   0.00000         6\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.53846        39\\n   macro avg    0.13462   0.25000   0.17500        39\\nweighted avg    0.28994   0.53846   0.37692        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        10\\n          a2    0.30769   1.00000   0.47059        12\\n          a3    0.00000   0.00000   0.00000        14\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.30769        39\\n   macro avg    0.07692   0.25000   0.11765        39\\nweighted avg    0.09467   0.30769   0.14480        39\\n']\n",
            "Mean Accuracy: 0.40512820512820513\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 2,  6,  0,  0],\n",
            "       [ 1, 17,  0,  0],\n",
            "       [ 0, 10,  0,  0],\n",
            "       [ 0,  3,  0,  0]]), array([[ 1,  9,  0,  0],\n",
            "       [ 0, 14,  0,  0],\n",
            "       [ 0, 14,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0, 11,  0,  0],\n",
            "       [ 0, 14,  0,  0],\n",
            "       [ 0, 10,  0,  0],\n",
            "       [ 0,  4,  0,  0]]), array([[ 1, 10,  0,  0],\n",
            "       [ 0, 21,  0,  0],\n",
            "       [ 0,  6,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0, 10,  0,  0],\n",
            "       [ 0, 12,  0,  0],\n",
            "       [ 0, 14,  0,  0],\n",
            "       [ 0,  3,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.66667   0.25000   0.36364         8\\n          a2    0.47222   0.94444   0.62963        18\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.48718        39\\n   macro avg    0.28472   0.29861   0.24832        39\\nweighted avg    0.35470   0.48718   0.36519        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    1.00000   0.10000   0.18182        10\\n          a2    0.36842   1.00000   0.53846        14\\n          a3    0.00000   0.00000   0.00000        14\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.38462        39\\n   macro avg    0.34211   0.27500   0.18007        39\\nweighted avg    0.38866   0.38462   0.23991        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        11\\n          a2    0.35897   1.00000   0.52830        14\\n          a3    0.00000   0.00000   0.00000        10\\n         a35    0.00000   0.00000   0.00000         4\\n\\n    accuracy                        0.35897        39\\n   macro avg    0.08974   0.25000   0.13208        39\\nweighted avg    0.12886   0.35897   0.18965        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    1.00000   0.09091   0.16667        11\\n          a2    0.55263   1.00000   0.71186        21\\n          a3    0.00000   0.00000   0.00000         6\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.56410        39\\n   macro avg    0.38816   0.27273   0.21963        39\\nweighted avg    0.57962   0.56410   0.43032        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        10\\n          a2    0.30769   1.00000   0.47059        12\\n          a3    0.00000   0.00000   0.00000        14\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.30769        39\\n   macro avg    0.07692   0.25000   0.11765        39\\nweighted avg    0.09467   0.30769   0.14480        39\\n']\n",
            "Mean Accuracy: 0.4205128205128205\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[2, 2, 4, 0],\n",
            "       [4, 6, 7, 1],\n",
            "       [2, 2, 6, 0],\n",
            "       [0, 0, 1, 2]]), array([[6, 3, 0, 1],\n",
            "       [3, 8, 3, 0],\n",
            "       [0, 9, 2, 3],\n",
            "       [0, 1, 0, 0]]), array([[6, 3, 2, 0],\n",
            "       [6, 4, 3, 1],\n",
            "       [1, 3, 6, 0],\n",
            "       [0, 2, 2, 0]]), array([[4, 5, 1, 1],\n",
            "       [6, 7, 6, 2],\n",
            "       [2, 3, 1, 0],\n",
            "       [0, 1, 0, 0]]), array([[1, 7, 2, 0],\n",
            "       [3, 4, 4, 1],\n",
            "       [4, 4, 5, 1],\n",
            "       [1, 0, 2, 0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.25000   0.25000   0.25000         8\\n          a2    0.60000   0.33333   0.42857        18\\n          a3    0.33333   0.60000   0.42857        10\\n         a35    0.66667   0.66667   0.66667         3\\n\\n    accuracy                        0.41026        39\\n   macro avg    0.46250   0.46250   0.44345        39\\nweighted avg    0.46496   0.41026   0.41026        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.66667   0.60000   0.63158        10\\n          a2    0.38095   0.57143   0.45714        14\\n          a3    0.40000   0.14286   0.21053        14\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.41026        39\\n   macro avg    0.36190   0.32857   0.32481        39\\nweighted avg    0.45128   0.41026   0.40162        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.46154   0.54545   0.50000        11\\n          a2    0.33333   0.28571   0.30769        14\\n          a3    0.46154   0.60000   0.52174        10\\n         a35    0.00000   0.00000   0.00000         4\\n\\n    accuracy                        0.41026        39\\n   macro avg    0.31410   0.35779   0.33236        39\\nweighted avg    0.36818   0.41026   0.38526        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.33333   0.36364   0.34783        11\\n          a2    0.43750   0.33333   0.37838        21\\n          a3    0.12500   0.16667   0.14286         6\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.30769        39\\n   macro avg    0.22396   0.21591   0.21727        39\\nweighted avg    0.34882   0.30769   0.32383        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.11111   0.10000   0.10526        10\\n          a2    0.26667   0.33333   0.29630        12\\n          a3    0.38462   0.35714   0.37037        14\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.25641        39\\n   macro avg    0.19060   0.19762   0.19298        39\\nweighted avg    0.24861   0.25641   0.25111        39\\n']\n",
            "Mean Accuracy: 0.358974358974359\n",
            "--------- End of Iteration ---------\n",
            "\n",
            "Training indices: [597, 83, 461, 356, 674, 20, 377, 501, 418, 488, 406, 565, 200, 679, 295, 114, 367, 387, 743, 165, 672, 583, 469, 364, 472, 217, 476, 538, 15, 485, 691, 177, 730, 563, 125, 79, 465, 557, 703, 578, 84, 669, 404, 287, 484, 112, 579, 750, 310, 534, 576, 35, 615, 57, 185, 596, 526, 683, 447, 211, 636, 444, 143, 46, 528, 342, 309, 373, 136, 219, 752, 123, 347, 416, 175, 65, 22, 268, 59, 361, 592, 645, 408, 140, 107, 202, 522, 535, 322, 129, 513, 440, 128, 149, 551, 500, 215, 423, 482, 706, 612, 97, 318, 118, 7, 12, 603, 716, 186, 55, 124, 99, 580, 771, 316, 90, 3, 629, 568, 542, 481, 507, 51, 676, 156, 755, 642, 685, 127, 400, 505, 555, 651, 682, 263, 765, 8, 722, 218, 732, 591, 133, 713, 473, 281, 210, 395, 58, 698, 439, 283, 376, 529, 371, 686, 199, 91, 369, 620, 293, 76, 562, 344, 559, 205, 307, 510, 508, 50, 333, 402, 246, 647, 157, 300, 222, 468, 525, 745, 680, 244, 649, 462, 378, 95, 261, 169, 315, 503, 479, 280, 98, 477, 575, 768, 266, 527, 290, 678, 491, 766, 357, 359, 756, 154, 170, 586, 536, 390, 407, 619, 243, 621, 420, 545, 346, 216, 235, 159, 521, 296, 345, 625, 741, 301, 614, 28, 341, 421, 512, 694, 458, 549, 17, 533, 188, 595, 241, 227, 633, 101, 34, 490, 105, 453, 6, 546, 265, 753, 294, 21, 772, 23, 443, 511, 489, 109, 370, 353, 145, 775, 317, 415, 628, 412, 623, 515, 656, 93, 303, 230, 486, 53, 764, 582, 320, 483, 374, 570, 518, 225, 209, 13, 336, 362, 32, 564, 100, 460, 196, 207, 724, 446, 604, 311, 569, 571, 648, 312, 605, 392, 197, 516, 189, 566, 403, 269, 111, 495, 742, 773, 183, 191, 121, 432, 115, 117, 291, 692, 448, 383, 64, 226, 494, 658, 762, 640, 81, 506, 1, 288, 86, 351, 548, 436, 330, 381, 92, 340, 438, 2, 389, 399, 329, 707, 302, 718, 631, 509, 73, 450, 632, 292, 666, 248, 532, 456, 744, 71, 699, 717, 610, 213, 445, 155, 38, 711, 180, 338, 777, 675, 319, 194, 696, 16, 504, 150, 433, 537, 760, 471, 375, 728, 337, 304, 524, 147, 232, 231, 327, 746, 158, 144, 688, 208, 25, 410, 184, 56, 643, 655, 162, 644, 11, 599, 221, 635, 414, 616, 684, 712, 360, 379, 452, 727, 492, 434, 72, 609, 348, 332, 238, 558, 396, 132, 314, 27, 657, 137, 229, 598, 386, 702, 740, 284, 747, 355, 139, 40, 282, 428, 343, 352, 259, 273, 122, 622, 560, 470, 634, 153, 451, 600, 530, 54, 201, 754, 734, 44, 298, 664, 719, 9, 135, 697, 630, 723, 106, 24, 608, 394, 763, 176, 677, 160, 720, 617, 179, 671, 104, 413, 725, 30, 639, 464, 276, 102, 497, 138, 308, 87, 391, 26, 437, 151, 264, 36, 220, 650, 606, 240, 29, 172, 80, 496, 543, 455, 572, 181, 769, 306, 767, 626, 277, 424, 759, 523, 134, 442, 233, 425, 190, 561, 168, 638, 331, 350, 668, 654, 693, 108, 242, 69, 89, 435, 602, 611, 541, 554, 245, 366, 493, 321, 251, 776, 260, 0, 130, 48, 326, 667, 704, 49, 334, 349, 478, 735, 553, 247, 74, 618, 757, 474, 313, 142, 182, 256, 380, 164, 5, 738, 641, 271, 475, 255, 422, 731, 131, 103, 148, 463, 236, 531, 397, 94, 574, 237, 187, 748, 328, 689, 297, 613, 77, 427, 203, 761, 681, 670, 173, 737, 267, 661, 601, 252, 517, 405, 587, 721, 749, 547, 204, 499, 467, 228, 487, 457, 41, 624, 426, 384, 708]\n",
            "Testing indices: [363, 258, 37, 372, 254, 120, 714, 10, 567, 249, 285, 4, 449, 770, 42, 323, 67, 646, 78, 224, 733, 270, 419, 577, 324, 573, 594, 161, 223, 167, 82, 234, 339, 673, 250, 75, 514, 39, 171, 411, 581, 498, 18, 119, 459, 729, 262, 174, 278, 739, 715, 62, 590, 178, 454, 584, 659, 388, 398, 539, 192, 726, 63, 88, 502, 520, 588, 163, 662, 113, 274, 417, 607, 393, 665, 627, 146, 441, 299, 70, 325, 690, 279, 409, 593, 358, 286, 652, 19, 52, 68, 653, 60, 519, 701, 354, 758, 550, 45, 272, 33, 212, 305, 116, 585, 206, 239, 66, 141, 214, 705, 637, 253, 85, 544, 687, 556, 195, 774, 751, 700, 96, 709, 365, 401, 710, 198, 47, 429, 382, 660, 368, 431, 335, 166, 430, 152, 540, 43, 31, 466, 589, 552, 663, 695, 257, 385, 736, 480, 61, 289, 126, 275, 14, 110, 193]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [363, 258, 37, 372, 254, 120, 714, 10, 567, 249, 285, 4, 449, 770, 42, 323, 67, 646, 78, 224, 733, 270, 419, 577, 324, 573, 594, 161, 223, 167, 82, 234, 339, 673, 250, 75, 514, 39, 171, 411, 581, 498, 18, 119, 459, 729, 262, 174, 278, 739, 715, 62, 590, 178, 454, 584, 659, 388, 398, 539, 192, 726, 63, 88, 502, 520, 588, 163, 662, 113, 274, 417, 607, 393, 665, 627, 146, 441, 299, 70, 325, 690, 279, 409, 593, 358, 286, 652, 19, 52, 68, 653, 60, 519, 701, 354, 758, 550, 45, 272, 33, 212, 305, 116, 585, 206, 239, 66, 141, 214, 705, 637, 253, 85, 544, 687, 556, 195, 774, 751, 700, 96, 709, 365, 401, 710, 198, 47, 429, 382, 660, 368, 431, 335, 166, 430, 152, 540, 43, 31, 466, 589, 552, 663, 695, 257, 385, 736, 480, 61, 289, 126, 275, 14, 110, 193, 91, 369, 620, 293, 76, 562, 344, 559, 205, 307, 510, 508, 50, 333, 402, 246, 647, 157, 300, 222, 468, 525, 745, 680, 244, 649, 462, 378, 95, 261, 169, 315, 503, 479, 280, 98, 477, 575, 768, 266, 527, 290, 678, 491, 766, 357, 359, 756, 154, 170, 586, 536, 390, 407, 619, 243, 621, 420, 545, 346, 216, 235, 159, 521, 296, 345, 625, 741, 301, 614, 28, 341, 421, 512, 694, 458, 549, 17, 533, 188, 595, 241, 227, 633, 101, 34, 490, 105, 453, 6, 546, 265, 753, 294, 21, 772, 23, 443, 511, 489, 109, 370, 353, 145, 775, 317, 415, 628, 412, 623, 515, 656, 93, 303, 230, 486, 53, 764, 582, 320, 483, 374, 570, 518, 225, 209, 13, 336, 362, 32, 564, 100, 460, 196, 207, 724, 446, 604, 311, 569, 571, 648, 312, 605, 392, 197, 516, 189, 566, 403, 269, 111, 495, 742, 773, 183, 191, 121, 432, 115, 117, 291, 692, 448, 383, 64, 226, 494, 658, 762, 640, 81, 506, 1, 288, 86, 351, 548, 436, 330, 381, 92, 340, 438, 2, 389, 399, 329, 707, 302, 718, 631, 509, 73, 450, 632, 292, 666, 248, 532, 456, 744, 71, 699, 717, 610, 213, 445, 155, 38, 711, 180, 338, 777, 675, 319, 194, 696, 16, 504, 150, 433, 537, 760, 471, 375, 728, 337, 304, 524, 147, 232, 231, 327, 746, 158, 144, 688, 208, 25, 410, 184, 56, 643, 655, 162, 644, 11, 599, 221, 635, 414, 616, 684, 712, 360, 379, 452, 727, 492, 434, 72, 609, 348, 332, 238, 558, 396, 132, 314, 27, 657, 137, 229, 598, 386, 702, 740, 284, 747, 355, 139, 40, 282, 428, 343, 352, 259, 273, 122, 622, 560, 470, 634, 153, 451, 600, 530, 54, 201, 754, 734, 44, 298, 664, 719, 9, 135, 697, 630, 723, 106, 24, 608, 394, 763, 176, 677, 160, 720, 617, 179, 671, 104, 413, 725, 30, 639, 464, 276, 102, 497, 138, 308, 87, 391, 26, 437, 151, 264, 36, 220, 650, 606, 240, 29, 172, 80, 496, 543, 455, 572, 181, 769, 306, 767, 626, 277, 424, 759, 523, 134, 442, 233, 425, 190, 561, 168, 638, 331, 350, 668, 654, 693, 108, 242, 69, 89, 435, 602, 611, 541, 554, 245, 366, 493, 321, 251, 776, 260, 0, 130, 48, 326, 667, 704, 49, 334, 349, 478, 735, 553, 247, 74, 618, 757, 474, 313, 142, 182, 256, 380, 164, 5, 738, 641, 271, 475, 255, 422, 731, 131, 103, 148, 463, 236, 531, 397, 94, 574, 237, 187, 748, 328, 689, 297, 613, 77, 427, 203, 761, 681, 670, 173, 737, 267, 661, 601, 252, 517, 405, 587, 721, 749, 547, 204, 499, 467, 228, 487, 457, 41, 624, 426, 384, 708]\n",
            "Testing indices: [597, 83, 461, 356, 674, 20, 377, 501, 418, 488, 406, 565, 200, 679, 295, 114, 367, 387, 743, 165, 672, 583, 469, 364, 472, 217, 476, 538, 15, 485, 691, 177, 730, 563, 125, 79, 465, 557, 703, 578, 84, 669, 404, 287, 484, 112, 579, 750, 310, 534, 576, 35, 615, 57, 185, 596, 526, 683, 447, 211, 636, 444, 143, 46, 528, 342, 309, 373, 136, 219, 752, 123, 347, 416, 175, 65, 22, 268, 59, 361, 592, 645, 408, 140, 107, 202, 522, 535, 322, 129, 513, 440, 128, 149, 551, 500, 215, 423, 482, 706, 612, 97, 318, 118, 7, 12, 603, 716, 186, 55, 124, 99, 580, 771, 316, 90, 3, 629, 568, 542, 481, 507, 51, 676, 156, 755, 642, 685, 127, 400, 505, 555, 651, 682, 263, 765, 8, 722, 218, 732, 591, 133, 713, 473, 281, 210, 395, 58, 698, 439, 283, 376, 529, 371, 686, 199]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [363, 258, 37, 372, 254, 120, 714, 10, 567, 249, 285, 4, 449, 770, 42, 323, 67, 646, 78, 224, 733, 270, 419, 577, 324, 573, 594, 161, 223, 167, 82, 234, 339, 673, 250, 75, 514, 39, 171, 411, 581, 498, 18, 119, 459, 729, 262, 174, 278, 739, 715, 62, 590, 178, 454, 584, 659, 388, 398, 539, 192, 726, 63, 88, 502, 520, 588, 163, 662, 113, 274, 417, 607, 393, 665, 627, 146, 441, 299, 70, 325, 690, 279, 409, 593, 358, 286, 652, 19, 52, 68, 653, 60, 519, 701, 354, 758, 550, 45, 272, 33, 212, 305, 116, 585, 206, 239, 66, 141, 214, 705, 637, 253, 85, 544, 687, 556, 195, 774, 751, 700, 96, 709, 365, 401, 710, 198, 47, 429, 382, 660, 368, 431, 335, 166, 430, 152, 540, 43, 31, 466, 589, 552, 663, 695, 257, 385, 736, 480, 61, 289, 126, 275, 14, 110, 193, 597, 83, 461, 356, 674, 20, 377, 501, 418, 488, 406, 565, 200, 679, 295, 114, 367, 387, 743, 165, 672, 583, 469, 364, 472, 217, 476, 538, 15, 485, 691, 177, 730, 563, 125, 79, 465, 557, 703, 578, 84, 669, 404, 287, 484, 112, 579, 750, 310, 534, 576, 35, 615, 57, 185, 596, 526, 683, 447, 211, 636, 444, 143, 46, 528, 342, 309, 373, 136, 219, 752, 123, 347, 416, 175, 65, 22, 268, 59, 361, 592, 645, 408, 140, 107, 202, 522, 535, 322, 129, 513, 440, 128, 149, 551, 500, 215, 423, 482, 706, 612, 97, 318, 118, 7, 12, 603, 716, 186, 55, 124, 99, 580, 771, 316, 90, 3, 629, 568, 542, 481, 507, 51, 676, 156, 755, 642, 685, 127, 400, 505, 555, 651, 682, 263, 765, 8, 722, 218, 732, 591, 133, 713, 473, 281, 210, 395, 58, 698, 439, 283, 376, 529, 371, 686, 199, 191, 121, 432, 115, 117, 291, 692, 448, 383, 64, 226, 494, 658, 762, 640, 81, 506, 1, 288, 86, 351, 548, 436, 330, 381, 92, 340, 438, 2, 389, 399, 329, 707, 302, 718, 631, 509, 73, 450, 632, 292, 666, 248, 532, 456, 744, 71, 699, 717, 610, 213, 445, 155, 38, 711, 180, 338, 777, 675, 319, 194, 696, 16, 504, 150, 433, 537, 760, 471, 375, 728, 337, 304, 524, 147, 232, 231, 327, 746, 158, 144, 688, 208, 25, 410, 184, 56, 643, 655, 162, 644, 11, 599, 221, 635, 414, 616, 684, 712, 360, 379, 452, 727, 492, 434, 72, 609, 348, 332, 238, 558, 396, 132, 314, 27, 657, 137, 229, 598, 386, 702, 740, 284, 747, 355, 139, 40, 282, 428, 343, 352, 259, 273, 122, 622, 560, 470, 634, 153, 451, 600, 530, 54, 201, 754, 734, 44, 298, 664, 719, 9, 135, 697, 630, 723, 106, 24, 608, 394, 763, 176, 677, 160, 720, 617, 179, 671, 104, 413, 725, 30, 639, 464, 276, 102, 497, 138, 308, 87, 391, 26, 437, 151, 264, 36, 220, 650, 606, 240, 29, 172, 80, 496, 543, 455, 572, 181, 769, 306, 767, 626, 277, 424, 759, 523, 134, 442, 233, 425, 190, 561, 168, 638, 331, 350, 668, 654, 693, 108, 242, 69, 89, 435, 602, 611, 541, 554, 245, 366, 493, 321, 251, 776, 260, 0, 130, 48, 326, 667, 704, 49, 334, 349, 478, 735, 553, 247, 74, 618, 757, 474, 313, 142, 182, 256, 380, 164, 5, 738, 641, 271, 475, 255, 422, 731, 131, 103, 148, 463, 236, 531, 397, 94, 574, 237, 187, 748, 328, 689, 297, 613, 77, 427, 203, 761, 681, 670, 173, 737, 267, 661, 601, 252, 517, 405, 587, 721, 749, 547, 204, 499, 467, 228, 487, 457, 41, 624, 426, 384, 708]\n",
            "Testing indices: [91, 369, 620, 293, 76, 562, 344, 559, 205, 307, 510, 508, 50, 333, 402, 246, 647, 157, 300, 222, 468, 525, 745, 680, 244, 649, 462, 378, 95, 261, 169, 315, 503, 479, 280, 98, 477, 575, 768, 266, 527, 290, 678, 491, 766, 357, 359, 756, 154, 170, 586, 536, 390, 407, 619, 243, 621, 420, 545, 346, 216, 235, 159, 521, 296, 345, 625, 741, 301, 614, 28, 341, 421, 512, 694, 458, 549, 17, 533, 188, 595, 241, 227, 633, 101, 34, 490, 105, 453, 6, 546, 265, 753, 294, 21, 772, 23, 443, 511, 489, 109, 370, 353, 145, 775, 317, 415, 628, 412, 623, 515, 656, 93, 303, 230, 486, 53, 764, 582, 320, 483, 374, 570, 518, 225, 209, 13, 336, 362, 32, 564, 100, 460, 196, 207, 724, 446, 604, 311, 569, 571, 648, 312, 605, 392, 197, 516, 189, 566, 403, 269, 111, 495, 742, 773, 183]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [363, 258, 37, 372, 254, 120, 714, 10, 567, 249, 285, 4, 449, 770, 42, 323, 67, 646, 78, 224, 733, 270, 419, 577, 324, 573, 594, 161, 223, 167, 82, 234, 339, 673, 250, 75, 514, 39, 171, 411, 581, 498, 18, 119, 459, 729, 262, 174, 278, 739, 715, 62, 590, 178, 454, 584, 659, 388, 398, 539, 192, 726, 63, 88, 502, 520, 588, 163, 662, 113, 274, 417, 607, 393, 665, 627, 146, 441, 299, 70, 325, 690, 279, 409, 593, 358, 286, 652, 19, 52, 68, 653, 60, 519, 701, 354, 758, 550, 45, 272, 33, 212, 305, 116, 585, 206, 239, 66, 141, 214, 705, 637, 253, 85, 544, 687, 556, 195, 774, 751, 700, 96, 709, 365, 401, 710, 198, 47, 429, 382, 660, 368, 431, 335, 166, 430, 152, 540, 43, 31, 466, 589, 552, 663, 695, 257, 385, 736, 480, 61, 289, 126, 275, 14, 110, 193, 597, 83, 461, 356, 674, 20, 377, 501, 418, 488, 406, 565, 200, 679, 295, 114, 367, 387, 743, 165, 672, 583, 469, 364, 472, 217, 476, 538, 15, 485, 691, 177, 730, 563, 125, 79, 465, 557, 703, 578, 84, 669, 404, 287, 484, 112, 579, 750, 310, 534, 576, 35, 615, 57, 185, 596, 526, 683, 447, 211, 636, 444, 143, 46, 528, 342, 309, 373, 136, 219, 752, 123, 347, 416, 175, 65, 22, 268, 59, 361, 592, 645, 408, 140, 107, 202, 522, 535, 322, 129, 513, 440, 128, 149, 551, 500, 215, 423, 482, 706, 612, 97, 318, 118, 7, 12, 603, 716, 186, 55, 124, 99, 580, 771, 316, 90, 3, 629, 568, 542, 481, 507, 51, 676, 156, 755, 642, 685, 127, 400, 505, 555, 651, 682, 263, 765, 8, 722, 218, 732, 591, 133, 713, 473, 281, 210, 395, 58, 698, 439, 283, 376, 529, 371, 686, 199, 91, 369, 620, 293, 76, 562, 344, 559, 205, 307, 510, 508, 50, 333, 402, 246, 647, 157, 300, 222, 468, 525, 745, 680, 244, 649, 462, 378, 95, 261, 169, 315, 503, 479, 280, 98, 477, 575, 768, 266, 527, 290, 678, 491, 766, 357, 359, 756, 154, 170, 586, 536, 390, 407, 619, 243, 621, 420, 545, 346, 216, 235, 159, 521, 296, 345, 625, 741, 301, 614, 28, 341, 421, 512, 694, 458, 549, 17, 533, 188, 595, 241, 227, 633, 101, 34, 490, 105, 453, 6, 546, 265, 753, 294, 21, 772, 23, 443, 511, 489, 109, 370, 353, 145, 775, 317, 415, 628, 412, 623, 515, 656, 93, 303, 230, 486, 53, 764, 582, 320, 483, 374, 570, 518, 225, 209, 13, 336, 362, 32, 564, 100, 460, 196, 207, 724, 446, 604, 311, 569, 571, 648, 312, 605, 392, 197, 516, 189, 566, 403, 269, 111, 495, 742, 773, 183, 106, 24, 608, 394, 763, 176, 677, 160, 720, 617, 179, 671, 104, 413, 725, 30, 639, 464, 276, 102, 497, 138, 308, 87, 391, 26, 437, 151, 264, 36, 220, 650, 606, 240, 29, 172, 80, 496, 543, 455, 572, 181, 769, 306, 767, 626, 277, 424, 759, 523, 134, 442, 233, 425, 190, 561, 168, 638, 331, 350, 668, 654, 693, 108, 242, 69, 89, 435, 602, 611, 541, 554, 245, 366, 493, 321, 251, 776, 260, 0, 130, 48, 326, 667, 704, 49, 334, 349, 478, 735, 553, 247, 74, 618, 757, 474, 313, 142, 182, 256, 380, 164, 5, 738, 641, 271, 475, 255, 422, 731, 131, 103, 148, 463, 236, 531, 397, 94, 574, 237, 187, 748, 328, 689, 297, 613, 77, 427, 203, 761, 681, 670, 173, 737, 267, 661, 601, 252, 517, 405, 587, 721, 749, 547, 204, 499, 467, 228, 487, 457, 41, 624, 426, 384, 708]\n",
            "Testing indices: [191, 121, 432, 115, 117, 291, 692, 448, 383, 64, 226, 494, 658, 762, 640, 81, 506, 1, 288, 86, 351, 548, 436, 330, 381, 92, 340, 438, 2, 389, 399, 329, 707, 302, 718, 631, 509, 73, 450, 632, 292, 666, 248, 532, 456, 744, 71, 699, 717, 610, 213, 445, 155, 38, 711, 180, 338, 777, 675, 319, 194, 696, 16, 504, 150, 433, 537, 760, 471, 375, 728, 337, 304, 524, 147, 232, 231, 327, 746, 158, 144, 688, 208, 25, 410, 184, 56, 643, 655, 162, 644, 11, 599, 221, 635, 414, 616, 684, 712, 360, 379, 452, 727, 492, 434, 72, 609, 348, 332, 238, 558, 396, 132, 314, 27, 657, 137, 229, 598, 386, 702, 740, 284, 747, 355, 139, 40, 282, 428, 343, 352, 259, 273, 122, 622, 560, 470, 634, 153, 451, 600, 530, 54, 201, 754, 734, 44, 298, 664, 719, 9, 135, 697, 630, 723]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [363, 258, 37, 372, 254, 120, 714, 10, 567, 249, 285, 4, 449, 770, 42, 323, 67, 646, 78, 224, 733, 270, 419, 577, 324, 573, 594, 161, 223, 167, 82, 234, 339, 673, 250, 75, 514, 39, 171, 411, 581, 498, 18, 119, 459, 729, 262, 174, 278, 739, 715, 62, 590, 178, 454, 584, 659, 388, 398, 539, 192, 726, 63, 88, 502, 520, 588, 163, 662, 113, 274, 417, 607, 393, 665, 627, 146, 441, 299, 70, 325, 690, 279, 409, 593, 358, 286, 652, 19, 52, 68, 653, 60, 519, 701, 354, 758, 550, 45, 272, 33, 212, 305, 116, 585, 206, 239, 66, 141, 214, 705, 637, 253, 85, 544, 687, 556, 195, 774, 751, 700, 96, 709, 365, 401, 710, 198, 47, 429, 382, 660, 368, 431, 335, 166, 430, 152, 540, 43, 31, 466, 589, 552, 663, 695, 257, 385, 736, 480, 61, 289, 126, 275, 14, 110, 193, 597, 83, 461, 356, 674, 20, 377, 501, 418, 488, 406, 565, 200, 679, 295, 114, 367, 387, 743, 165, 672, 583, 469, 364, 472, 217, 476, 538, 15, 485, 691, 177, 730, 563, 125, 79, 465, 557, 703, 578, 84, 669, 404, 287, 484, 112, 579, 750, 310, 534, 576, 35, 615, 57, 185, 596, 526, 683, 447, 211, 636, 444, 143, 46, 528, 342, 309, 373, 136, 219, 752, 123, 347, 416, 175, 65, 22, 268, 59, 361, 592, 645, 408, 140, 107, 202, 522, 535, 322, 129, 513, 440, 128, 149, 551, 500, 215, 423, 482, 706, 612, 97, 318, 118, 7, 12, 603, 716, 186, 55, 124, 99, 580, 771, 316, 90, 3, 629, 568, 542, 481, 507, 51, 676, 156, 755, 642, 685, 127, 400, 505, 555, 651, 682, 263, 765, 8, 722, 218, 732, 591, 133, 713, 473, 281, 210, 395, 58, 698, 439, 283, 376, 529, 371, 686, 199, 91, 369, 620, 293, 76, 562, 344, 559, 205, 307, 510, 508, 50, 333, 402, 246, 647, 157, 300, 222, 468, 525, 745, 680, 244, 649, 462, 378, 95, 261, 169, 315, 503, 479, 280, 98, 477, 575, 768, 266, 527, 290, 678, 491, 766, 357, 359, 756, 154, 170, 586, 536, 390, 407, 619, 243, 621, 420, 545, 346, 216, 235, 159, 521, 296, 345, 625, 741, 301, 614, 28, 341, 421, 512, 694, 458, 549, 17, 533, 188, 595, 241, 227, 633, 101, 34, 490, 105, 453, 6, 546, 265, 753, 294, 21, 772, 23, 443, 511, 489, 109, 370, 353, 145, 775, 317, 415, 628, 412, 623, 515, 656, 93, 303, 230, 486, 53, 764, 582, 320, 483, 374, 570, 518, 225, 209, 13, 336, 362, 32, 564, 100, 460, 196, 207, 724, 446, 604, 311, 569, 571, 648, 312, 605, 392, 197, 516, 189, 566, 403, 269, 111, 495, 742, 773, 183, 191, 121, 432, 115, 117, 291, 692, 448, 383, 64, 226, 494, 658, 762, 640, 81, 506, 1, 288, 86, 351, 548, 436, 330, 381, 92, 340, 438, 2, 389, 399, 329, 707, 302, 718, 631, 509, 73, 450, 632, 292, 666, 248, 532, 456, 744, 71, 699, 717, 610, 213, 445, 155, 38, 711, 180, 338, 777, 675, 319, 194, 696, 16, 504, 150, 433, 537, 760, 471, 375, 728, 337, 304, 524, 147, 232, 231, 327, 746, 158, 144, 688, 208, 25, 410, 184, 56, 643, 655, 162, 644, 11, 599, 221, 635, 414, 616, 684, 712, 360, 379, 452, 727, 492, 434, 72, 609, 348, 332, 238, 558, 396, 132, 314, 27, 657, 137, 229, 598, 386, 702, 740, 284, 747, 355, 139, 40, 282, 428, 343, 352, 259, 273, 122, 622, 560, 470, 634, 153, 451, 600, 530, 54, 201, 754, 734, 44, 298, 664, 719, 9, 135, 697, 630, 723]\n",
            "Testing indices: [106, 24, 608, 394, 763, 176, 677, 160, 720, 617, 179, 671, 104, 413, 725, 30, 639, 464, 276, 102, 497, 138, 308, 87, 391, 26, 437, 151, 264, 36, 220, 650, 606, 240, 29, 172, 80, 496, 543, 455, 572, 181, 769, 306, 767, 626, 277, 424, 759, 523, 134, 442, 233, 425, 190, 561, 168, 638, 331, 350, 668, 654, 693, 108, 242, 69, 89, 435, 602, 611, 541, 554, 245, 366, 493, 321, 251, 776, 260, 0, 130, 48, 326, 667, 704, 49, 334, 349, 478, 735, 553, 247, 74, 618, 757, 474, 313, 142, 182, 256, 380, 164, 5, 738, 641, 271, 475, 255, 422, 731, 131, 103, 148, 463, 236, 531, 397, 94, 574, 237, 187, 748, 328, 689, 297, 613, 77, 427, 203, 761, 681, 670, 173, 737, 267, 661, 601, 252, 517, 405, 587, 721, 749, 547, 204, 499, 467, 228, 487, 457, 41, 624, 426, 384, 708]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [165, 106, 173, 84, 140, 21, 68, 15, 6, 89, 45, 174, 93, 133, 22, 123, 24, 182, 156, 113, 148, 26, 38, 134, 67, 63, 13, 137, 42, 11, 12, 164, 187, 118, 92, 117, 80, 25, 131, 48, 176, 65, 170, 87, 151, 119, 61, 114, 104, 189, 163, 14, 47, 72, 122, 127, 167, 91, 1, 190, 188, 40, 144, 27, 139, 46, 50, 66, 55, 73, 132, 179, 193, 7, 112, 44, 31, 136, 116, 23, 130, 60, 166, 97, 64, 20, 103, 147, 39, 82, 28, 59, 126, 171, 138, 129, 158, 90, 120, 149, 56, 177, 75, 58, 125, 57, 34, 109, 186, 192, 41, 152, 183, 0, 184, 101, 124, 18, 169, 154, 29, 159, 78, 155, 146, 79, 35, 69, 16, 102, 150, 83, 194, 143, 191, 62, 128, 88, 111, 43, 33, 180, 49, 98, 53, 108, 157, 181, 2, 161, 141, 36, 81, 178, 168, 105]\n",
            "Testing indices: [121, 30, 9, 142, 77, 37, 10, 115, 110, 86, 107, 70, 172, 8, 51, 5, 4, 96, 54, 17, 99, 94, 95, 162, 153, 19, 71, 32, 185, 175, 76, 85, 135, 3, 74, 52, 145, 160, 100]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [121, 30, 9, 142, 77, 37, 10, 115, 110, 86, 107, 70, 172, 8, 51, 5, 4, 96, 54, 17, 99, 94, 95, 162, 153, 19, 71, 32, 185, 175, 76, 85, 135, 3, 74, 52, 145, 160, 100, 48, 176, 65, 170, 87, 151, 119, 61, 114, 104, 189, 163, 14, 47, 72, 122, 127, 167, 91, 1, 190, 188, 40, 144, 27, 139, 46, 50, 66, 55, 73, 132, 179, 193, 7, 112, 44, 31, 136, 116, 23, 130, 60, 166, 97, 64, 20, 103, 147, 39, 82, 28, 59, 126, 171, 138, 129, 158, 90, 120, 149, 56, 177, 75, 58, 125, 57, 34, 109, 186, 192, 41, 152, 183, 0, 184, 101, 124, 18, 169, 154, 29, 159, 78, 155, 146, 79, 35, 69, 16, 102, 150, 83, 194, 143, 191, 62, 128, 88, 111, 43, 33, 180, 49, 98, 53, 108, 157, 181, 2, 161, 141, 36, 81, 178, 168, 105]\n",
            "Testing indices: [165, 106, 173, 84, 140, 21, 68, 15, 6, 89, 45, 174, 93, 133, 22, 123, 24, 182, 156, 113, 148, 26, 38, 134, 67, 63, 13, 137, 42, 11, 12, 164, 187, 118, 92, 117, 80, 25, 131]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [121, 30, 9, 142, 77, 37, 10, 115, 110, 86, 107, 70, 172, 8, 51, 5, 4, 96, 54, 17, 99, 94, 95, 162, 153, 19, 71, 32, 185, 175, 76, 85, 135, 3, 74, 52, 145, 160, 100, 165, 106, 173, 84, 140, 21, 68, 15, 6, 89, 45, 174, 93, 133, 22, 123, 24, 182, 156, 113, 148, 26, 38, 134, 67, 63, 13, 137, 42, 11, 12, 164, 187, 118, 92, 117, 80, 25, 131, 116, 23, 130, 60, 166, 97, 64, 20, 103, 147, 39, 82, 28, 59, 126, 171, 138, 129, 158, 90, 120, 149, 56, 177, 75, 58, 125, 57, 34, 109, 186, 192, 41, 152, 183, 0, 184, 101, 124, 18, 169, 154, 29, 159, 78, 155, 146, 79, 35, 69, 16, 102, 150, 83, 194, 143, 191, 62, 128, 88, 111, 43, 33, 180, 49, 98, 53, 108, 157, 181, 2, 161, 141, 36, 81, 178, 168, 105]\n",
            "Testing indices: [48, 176, 65, 170, 87, 151, 119, 61, 114, 104, 189, 163, 14, 47, 72, 122, 127, 167, 91, 1, 190, 188, 40, 144, 27, 139, 46, 50, 66, 55, 73, 132, 179, 193, 7, 112, 44, 31, 136]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [121, 30, 9, 142, 77, 37, 10, 115, 110, 86, 107, 70, 172, 8, 51, 5, 4, 96, 54, 17, 99, 94, 95, 162, 153, 19, 71, 32, 185, 175, 76, 85, 135, 3, 74, 52, 145, 160, 100, 165, 106, 173, 84, 140, 21, 68, 15, 6, 89, 45, 174, 93, 133, 22, 123, 24, 182, 156, 113, 148, 26, 38, 134, 67, 63, 13, 137, 42, 11, 12, 164, 187, 118, 92, 117, 80, 25, 131, 48, 176, 65, 170, 87, 151, 119, 61, 114, 104, 189, 163, 14, 47, 72, 122, 127, 167, 91, 1, 190, 188, 40, 144, 27, 139, 46, 50, 66, 55, 73, 132, 179, 193, 7, 112, 44, 31, 136, 18, 169, 154, 29, 159, 78, 155, 146, 79, 35, 69, 16, 102, 150, 83, 194, 143, 191, 62, 128, 88, 111, 43, 33, 180, 49, 98, 53, 108, 157, 181, 2, 161, 141, 36, 81, 178, 168, 105]\n",
            "Testing indices: [116, 23, 130, 60, 166, 97, 64, 20, 103, 147, 39, 82, 28, 59, 126, 171, 138, 129, 158, 90, 120, 149, 56, 177, 75, 58, 125, 57, 34, 109, 186, 192, 41, 152, 183, 0, 184, 101, 124]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Training indices: [121, 30, 9, 142, 77, 37, 10, 115, 110, 86, 107, 70, 172, 8, 51, 5, 4, 96, 54, 17, 99, 94, 95, 162, 153, 19, 71, 32, 185, 175, 76, 85, 135, 3, 74, 52, 145, 160, 100, 165, 106, 173, 84, 140, 21, 68, 15, 6, 89, 45, 174, 93, 133, 22, 123, 24, 182, 156, 113, 148, 26, 38, 134, 67, 63, 13, 137, 42, 11, 12, 164, 187, 118, 92, 117, 80, 25, 131, 48, 176, 65, 170, 87, 151, 119, 61, 114, 104, 189, 163, 14, 47, 72, 122, 127, 167, 91, 1, 190, 188, 40, 144, 27, 139, 46, 50, 66, 55, 73, 132, 179, 193, 7, 112, 44, 31, 136, 116, 23, 130, 60, 166, 97, 64, 20, 103, 147, 39, 82, 28, 59, 126, 171, 138, 129, 158, 90, 120, 149, 56, 177, 75, 58, 125, 57, 34, 109, 186, 192, 41, 152, 183, 0, 184, 101, 124]\n",
            "Testing indices: [18, 169, 154, 29, 159, 78, 155, 146, 79, 35, 69, 16, 102, 150, 83, 194, 143, 191, 62, 128, 88, 111, 43, 33, 180, 49, 98, 53, 108, 157, 181, 2, 161, 141, 36, 81, 178, 168, 105]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\n",
            "--------- Iteration 5 ---------\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 33,  0,  0],\n",
            "       [ 0, 69,  0,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0,  9,  0,  0]]), array([[ 0, 34,  0,  0],\n",
            "       [ 0, 71,  0,  0],\n",
            "       [ 0, 41,  0,  0],\n",
            "       [ 0, 10,  0,  0]]), array([[ 0, 34,  0,  0],\n",
            "       [ 0, 78,  0,  0],\n",
            "       [ 0, 32,  0,  0],\n",
            "       [ 0, 12,  0,  0]]), array([[ 0, 41,  0,  0],\n",
            "       [ 0, 66,  0,  0],\n",
            "       [ 0, 39,  0,  0],\n",
            "       [ 0,  9,  0,  0]]), array([[ 0, 38,  0,  0],\n",
            "       [ 0, 65,  0,  0],\n",
            "       [ 0, 40,  0,  0],\n",
            "       [ 0, 12,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        33\\n          a2    0.44231   1.00000   0.61333        69\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.44231       156\\n   macro avg    0.11058   0.25000   0.15333       156\\nweighted avg    0.19564   0.44231   0.27128       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        34\\n          a2    0.45513   1.00000   0.62555        71\\n          a3    0.00000   0.00000   0.00000        41\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.45513       156\\n   macro avg    0.11378   0.25000   0.15639       156\\nweighted avg    0.20714   0.45513   0.28471       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        34\\n          a2    0.50000   1.00000   0.66667        78\\n          a3    0.00000   0.00000   0.00000        32\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.50000       156\\n   macro avg    0.12500   0.25000   0.16667       156\\nweighted avg    0.25000   0.50000   0.33333       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        41\\n          a2    0.42581   1.00000   0.59729        66\\n          a3    0.00000   0.00000   0.00000        39\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.42581       155\\n   macro avg    0.10645   0.25000   0.14932       155\\nweighted avg    0.18131   0.42581   0.25433       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        38\\n          a2    0.41935   1.00000   0.59091        65\\n          a3    0.00000   0.00000   0.00000        40\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.41935       155\\n   macro avg    0.10484   0.25000   0.14773       155\\nweighted avg    0.17586   0.41935   0.24780       155\\n']\n",
            "Mean Accuracy: 0.4485194375516956\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0, 33,  0,  0],\n",
            "       [ 0, 66,  3,  0],\n",
            "       [ 0, 45,  0,  0],\n",
            "       [ 0,  6,  3,  0]]), array([[ 0, 34,  0,  0],\n",
            "       [ 0, 69,  2,  0],\n",
            "       [ 0, 39,  2,  0],\n",
            "       [ 0,  9,  1,  0]]), array([[ 0, 33,  1,  0],\n",
            "       [ 0, 77,  1,  0],\n",
            "       [ 0, 30,  2,  0],\n",
            "       [ 0, 12,  0,  0]]), array([[ 0, 40,  1,  0],\n",
            "       [ 0, 65,  1,  0],\n",
            "       [ 0, 38,  1,  0],\n",
            "       [ 0,  6,  3,  0]]), array([[ 0, 38,  0,  0],\n",
            "       [ 0, 65,  0,  0],\n",
            "       [ 0, 40,  0,  0],\n",
            "       [ 0, 12,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        33\\n          a2    0.44000   0.95652   0.60274        69\\n          a3    0.00000   0.00000   0.00000        45\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.42308       156\\n   macro avg    0.11000   0.23913   0.15068       156\\nweighted avg    0.19462   0.42308   0.26660       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        34\\n          a2    0.45695   0.97183   0.62162        71\\n          a3    0.40000   0.04878   0.08696        41\\n         a35    0.00000   0.00000   0.00000        10\\n\\n    accuracy                        0.45513       156\\n   macro avg    0.21424   0.25515   0.17714       156\\nweighted avg    0.31310   0.45513   0.30577       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        34\\n          a2    0.50658   0.98718   0.66957        78\\n          a3    0.50000   0.06250   0.11111        32\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.50641       156\\n   macro avg    0.25164   0.26242   0.19517       156\\nweighted avg    0.35585   0.50641   0.35757       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        41\\n          a2    0.43624   0.98485   0.60465        66\\n          a3    0.16667   0.02564   0.04444        39\\n         a35    0.00000   0.00000   0.00000         9\\n\\n    accuracy                        0.42581       155\\n   macro avg    0.15073   0.25262   0.16227       155\\nweighted avg    0.22769   0.42581   0.26865       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        38\\n          a2    0.41935   1.00000   0.59091        65\\n          a3    0.00000   0.00000   0.00000        40\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.41935       155\\n   macro avg    0.10484   0.25000   0.14773       155\\nweighted avg    0.17586   0.41935   0.24780       155\\n']\n",
            "Mean Accuracy: 0.44595533498759304\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[14, 14,  5,  0],\n",
            "       [11, 38, 15,  5],\n",
            "       [ 8, 21, 14,  2],\n",
            "       [ 3,  3,  1,  2]]), array([[12, 14,  6,  2],\n",
            "       [20, 30, 16,  5],\n",
            "       [ 9, 20,  9,  3],\n",
            "       [ 2,  4,  3,  1]]), array([[12, 13,  9,  0],\n",
            "       [13, 39, 20,  6],\n",
            "       [ 4, 16,  9,  3],\n",
            "       [ 2,  4,  6,  0]]), array([[12, 14, 13,  2],\n",
            "       [21, 23, 16,  6],\n",
            "       [10, 19,  8,  2],\n",
            "       [ 2,  2,  3,  2]]), array([[ 6, 20, 12,  0],\n",
            "       [15, 33, 15,  2],\n",
            "       [ 6, 14, 17,  3],\n",
            "       [ 3,  5,  2,  2]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.38889   0.42424   0.40580        33\\n          a2    0.50000   0.55072   0.52414        69\\n          a3    0.40000   0.31111   0.35000        45\\n         a35    0.22222   0.22222   0.22222         9\\n\\n    accuracy                        0.43590       156\\n   macro avg    0.37778   0.37708   0.37554       156\\nweighted avg    0.43162   0.43590   0.43145       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.27907   0.35294   0.31169        34\\n          a2    0.44118   0.42254   0.43165        71\\n          a3    0.26471   0.21951   0.24000        41\\n         a35    0.09091   0.10000   0.09524        10\\n\\n    accuracy                        0.33333       156\\n   macro avg    0.26897   0.27375   0.26965       156\\nweighted avg    0.33701   0.33333   0.33357       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.38710   0.35294   0.36923        34\\n          a2    0.54167   0.50000   0.52000        78\\n          a3    0.20455   0.28125   0.23684        32\\n         a35    0.00000   0.00000   0.00000        12\\n\\n    accuracy                        0.38462       156\\n   macro avg    0.28333   0.28355   0.28152       156\\nweighted avg    0.39716   0.38462   0.38906       156\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.26667   0.29268   0.27907        41\\n          a2    0.39655   0.34848   0.37097        66\\n          a3    0.20000   0.20513   0.20253        39\\n         a35    0.16667   0.22222   0.19048         9\\n\\n    accuracy                        0.29032       155\\n   macro avg    0.25747   0.26713   0.26076       155\\nweighted avg    0.29939   0.29032   0.29380       155\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.20000   0.15789   0.17647        38\\n          a2    0.45833   0.50769   0.48175        65\\n          a3    0.36957   0.42500   0.39535        40\\n         a35    0.28571   0.16667   0.21053        12\\n\\n    accuracy                        0.37419       155\\n   macro avg    0.32840   0.31431   0.31602       155\\nweighted avg    0.35873   0.37419   0.36361       155\\n']\n",
            "Mean Accuracy: 0.36367245657568237\n",
            "\n",
            "------- SVM Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0,  7,  0,  0],\n",
            "       [ 0, 23,  0,  0],\n",
            "       [ 0,  8,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0,  5,  0,  0],\n",
            "       [ 0, 19,  0,  0],\n",
            "       [ 0, 13,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0,  6,  0,  0],\n",
            "       [ 0, 18,  0,  0],\n",
            "       [ 0, 12,  0,  0],\n",
            "       [ 0,  3,  0,  0]]), array([[ 0, 11,  0,  0],\n",
            "       [ 0, 18,  0,  0],\n",
            "       [ 0,  8,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0, 15,  0,  0],\n",
            "       [ 0, 12,  0,  0],\n",
            "       [ 0, 11,  0,  0],\n",
            "       [ 0,  1,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         7\\n          a2    0.58974   1.00000   0.74194        23\\n          a3    0.00000   0.00000   0.00000         8\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.58974        39\\n   macro avg    0.14744   0.25000   0.18548        39\\nweighted avg    0.34780   0.58974   0.43755        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         5\\n          a2    0.48718   1.00000   0.65517        19\\n          a3    0.00000   0.00000   0.00000        13\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.48718        39\\n   macro avg    0.12179   0.25000   0.16379        39\\nweighted avg    0.23734   0.48718   0.31919        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         6\\n          a2    0.46154   1.00000   0.63158        18\\n          a3    0.00000   0.00000   0.00000        12\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11538   0.25000   0.15789        39\\nweighted avg    0.21302   0.46154   0.29150        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        11\\n          a2    0.46154   1.00000   0.63158        18\\n          a3    0.00000   0.00000   0.00000         8\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11538   0.25000   0.15789        39\\nweighted avg    0.21302   0.46154   0.29150        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        15\\n          a2    0.30769   1.00000   0.47059        12\\n          a3    0.00000   0.00000   0.00000        11\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.30769        39\\n   macro avg    0.07692   0.25000   0.11765        39\\nweighted avg    0.09467   0.30769   0.14480        39\\n']\n",
            "Mean Accuracy: 0.4615384615384615\n",
            "\n",
            "------- Decision Tree Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 0,  7,  0,  0],\n",
            "       [ 0, 23,  0,  0],\n",
            "       [ 0,  8,  0,  0],\n",
            "       [ 0,  1,  0,  0]]), array([[ 0,  5,  0,  0],\n",
            "       [ 1, 18,  0,  0],\n",
            "       [ 0, 13,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0,  6,  0,  0],\n",
            "       [ 0, 18,  0,  0],\n",
            "       [ 0, 12,  0,  0],\n",
            "       [ 0,  3,  0,  0]]), array([[ 0, 11,  0,  0],\n",
            "       [ 0, 18,  0,  0],\n",
            "       [ 0,  8,  0,  0],\n",
            "       [ 0,  2,  0,  0]]), array([[ 0, 15,  0,  0],\n",
            "       [ 0, 12,  0,  0],\n",
            "       [ 0, 11,  0,  0],\n",
            "       [ 0,  1,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         7\\n          a2    0.58974   1.00000   0.74194        23\\n          a3    0.00000   0.00000   0.00000         8\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.58974        39\\n   macro avg    0.14744   0.25000   0.18548        39\\nweighted avg    0.34780   0.58974   0.43755        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         5\\n          a2    0.47368   0.94737   0.63158        19\\n          a3    0.00000   0.00000   0.00000        13\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11842   0.23684   0.15789        39\\nweighted avg    0.23077   0.46154   0.30769        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         6\\n          a2    0.46154   1.00000   0.63158        18\\n          a3    0.00000   0.00000   0.00000        12\\n         a35    0.00000   0.00000   0.00000         3\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11538   0.25000   0.15789        39\\nweighted avg    0.21302   0.46154   0.29150        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        11\\n          a2    0.46154   1.00000   0.63158        18\\n          a3    0.00000   0.00000   0.00000         8\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.11538   0.25000   0.15789        39\\nweighted avg    0.21302   0.46154   0.29150        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000        15\\n          a2    0.30769   1.00000   0.47059        12\\n          a3    0.00000   0.00000   0.00000        11\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.30769        39\\n   macro avg    0.07692   0.25000   0.11765        39\\nweighted avg    0.09467   0.30769   0.14480        39\\n']\n",
            "Mean Accuracy: 0.4564102564102564\n",
            "\n",
            "------- KNN Results -------\n",
            "Confusion Matrix:\n",
            " [array([[ 5,  0,  2,  0],\n",
            "       [ 2, 12,  7,  2],\n",
            "       [ 0,  5,  3,  0],\n",
            "       [ 0,  0,  1,  0]]), array([[0, 4, 1, 0],\n",
            "       [5, 8, 5, 1],\n",
            "       [2, 4, 6, 1],\n",
            "       [0, 0, 2, 0]]), array([[4, 2, 0, 0],\n",
            "       [3, 6, 7, 2],\n",
            "       [2, 8, 2, 0],\n",
            "       [0, 1, 0, 2]]), array([[5, 4, 2, 0],\n",
            "       [5, 6, 6, 1],\n",
            "       [2, 3, 1, 2],\n",
            "       [0, 0, 1, 1]]), array([[ 6,  6,  3,  0],\n",
            "       [ 1, 10,  1,  0],\n",
            "       [ 2,  7,  2,  0],\n",
            "       [ 0,  1,  0,  0]])]\n",
            "Classification Report:\n",
            " ['              precision    recall  f1-score   support\\n\\n          a1    0.71429   0.71429   0.71429         7\\n          a2    0.70588   0.52174   0.60000        23\\n          a3    0.23077   0.37500   0.28571         8\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.51282        39\\n   macro avg    0.41273   0.40276   0.40000        39\\nweighted avg    0.59183   0.51282   0.54066        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.00000   0.00000   0.00000         5\\n          a2    0.50000   0.42105   0.45714        19\\n          a3    0.42857   0.46154   0.44444        13\\n         a35    0.00000   0.00000   0.00000         2\\n\\n    accuracy                        0.35897        39\\n   macro avg    0.23214   0.22065   0.22540        39\\nweighted avg    0.38645   0.35897   0.37086        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.44444   0.66667   0.53333         6\\n          a2    0.35294   0.33333   0.34286        18\\n          a3    0.22222   0.16667   0.19048        12\\n         a35    0.50000   0.66667   0.57143         3\\n\\n    accuracy                        0.35897        39\\n   macro avg    0.37990   0.45833   0.40952        39\\nweighted avg    0.33811   0.35897   0.34286        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.41667   0.45455   0.43478        11\\n          a2    0.46154   0.33333   0.38710        18\\n          a3    0.10000   0.12500   0.11111         8\\n         a35    0.25000   0.50000   0.33333         2\\n\\n    accuracy                        0.33333        39\\n   macro avg    0.30705   0.35322   0.31658        39\\nweighted avg    0.36387   0.33333   0.34118        39\\n', '              precision    recall  f1-score   support\\n\\n          a1    0.66667   0.40000   0.50000        15\\n          a2    0.41667   0.83333   0.55556        12\\n          a3    0.33333   0.18182   0.23529        11\\n         a35    0.00000   0.00000   0.00000         1\\n\\n    accuracy                        0.46154        39\\n   macro avg    0.35417   0.35379   0.32271        39\\nweighted avg    0.47863   0.46154   0.42961        39\\n']\n",
            "Mean Accuracy: 0.40512820512820513\n",
            "--------- End of Iteration ---------\n",
            "Experiment execution completed.\n"
          ]
        }
      ],
      "source": [
        "!python main.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MAIN i think i t will work\n",
        "\n",
        "import errno\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import Classification as Cl\n",
        "import FeatureExtraction as fE\n",
        "import PreProcessingData as pD\n",
        "import ReadImages as rI\n",
        "\n",
        "\n",
        "def show(image):\n",
        "    cv.imshow('Imagen ', image)\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()\n",
        "\n",
        "\n",
        "class MainClass:\n",
        "    PROJECT_PATH = os.path.join(os.getcwd(), os.path.pardir)\n",
        "    PATH_IMAGES_ORIGINAL = os.path.abspath(\n",
        "        os.path.join(os.path.join(os.path.join(os.getcwd(), os.pardir), os.pardir), \"DATASET - Original\"))\n",
        "    PATH_Labels = os.path.abspath(\n",
        "        os.path.join(os.path.join(os.path.join(os.getcwd(), os.pardir), os.pardir), \"Labels\"))\n",
        "    PATH_LabelsXML = os.path.abspath(os.path.join(\n",
        "        os.path.join(os.path.join(os.path.join(os.getcwd(), os.pardir), os.pardir), \"Labels\"), \"LabelsXML\"))\n",
        "    PATH_IMAGES = os.path.abspath(\n",
        "        os.path.join(os.path.join(os.path.join(os.getcwd(), os.pardir), os.pardir), \"DATASET\"))\n",
        "    readimages = None\n",
        "    preprocessing = None\n",
        "    featureExtraction = None\n",
        "    clasification = None\n",
        "\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            if not os.path.exists(self.PROJECT_PATH + 'PreProcessing'):\n",
        "                os.mkdir(os.path.join(self.PROJECT_PATH, 'PreProcessing'))\n",
        "                print('Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('PreProcessing Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "        try:\n",
        "            if not os.path.exists(self.PROJECT_PATH + 'FeatureExtraction'):\n",
        "                os.mkdir(os.path.join(self.PROJECT_PATH, 'FeatureExtraction'))\n",
        "                print('Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('FeatureExtraction Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "        try:\n",
        "            if not os.path.exists(self.PROJECT_PATH + 'Sampling'):\n",
        "                os.mkdir(os.path.join(self.PROJECT_PATH, 'Sampling'))\n",
        "                print('Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('Sampling Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "        try:\n",
        "            if not os.path.exists(self.PROJECT_PATH + 'Classification'):\n",
        "                os.mkdir(os.path.join(self.PROJECT_PATH, 'Classification'))\n",
        "                print('Directory Classification Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('Classification Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "        self.readimages = rI.LoadData(self.PATH_IMAGES_ORIGINAL)\n",
        "        self.preProcessing = pD.PreProcessingData(self.PROJECT_PATH, self.PATH_IMAGES_ORIGINAL)\n",
        "        self.featureExtraction = fE.FeatureExtraction(self.PROJECT_PATH, self.PATH_IMAGES_ORIGINAL)\n",
        "        self.clasification = Cl.Classification(self.PROJECT_PATH)\n",
        "\n",
        "    def main_run(self):\n",
        "        # Se declaran las clases para poder utilizar los elementos\n",
        "        read = self.readimages\n",
        "        pp = self.preProcessing\n",
        "        fe = self.featureExtraction\n",
        "\n",
        "        # Se lee el nombre y la imagen que se encuentre en el PATH del dataset ORIGINAL\n",
        "        # img, name = read.read_One_Image(self.PATH_IMAGES)\n",
        "        # Se lee el nombre y la imagen que se encuentre en el PATH del dataset RECORTADO\n",
        "        img, name = read.read_One_Image(self.PATH_IMAGES)\n",
        "\n",
        "        # Se obtiene las dimensiones de la imagen original\n",
        "        height_ori, width_ori, depth_ori = img.shape\n",
        "        # print(\"Image original shape: \\n Height:\", height_ori, \", Width:\", width_ori)\n",
        "\n",
        "        # Se realiza un ajuste de tamaño para reducir la imagen a unas dimensiones de 600x400\n",
        "        img_resize = pp.resize_Image(img, name)\n",
        "\n",
        "        # La imagen reajustada se convierte de BGR a RGB\n",
        "        img_resize = cv.cvtColor(img_resize, cv.COLOR_BGR2RGB)\n",
        "        # Se convierte la imagen de RGB a HSV\n",
        "        hsv_image = pp.rgb_2_HSV(img_resize, name)\n",
        "        # Se saca la imagen en pila de tono de rojos\n",
        "        stack, name = pp.stackColors(hsv_image, name)\n",
        "        # Se saca los histogramas por imagen para determinar el rango de color de los dientes\n",
        "        pp.hsv_hist(hsv_image, name)\n",
        "        #\n",
        "        # plt.imshow(img_resize)\n",
        "        # Blur image slightly\n",
        "        name, blurimage = pp.blurImage(img_resize, name)\n",
        "        pp.show_mask(blurimage, name)\n",
        "        pp.overlay_mask(blurimage, img_resize, name)\n",
        "\n",
        "        # Se obtiene la rueda cromatica de la imágen\n",
        "        # pp.getChromatiColor(img_resize,name,fe)\n",
        "\n",
        "        # img_rgb2ycbcr = pp.rgb_2_YCrCb(img_resize, name)\n",
        "        img_rgb2hsv = pp.rgb_2_HSV(img_resize, name)\n",
        "\n",
        "    '''easygui.msgbox(\"Image original shape: \\n Height:\" + str(height_ori) + \"px, Width:\" + str(width_ori) + \"px\" +\n",
        "                   \"\\n Image Resize shape: \\n Height:\" + str(height_res) + \"px, Width:\" + str(width_res) + \"px\",\n",
        "                   image=os.path.join(os.path.join(os.getcwd(), os.path.pardir),\n",
        "                                      'PreProcessing/ResizeImages/' + name),\n",
        "                   title=\"Image Shape - PreProcessing \")'''\n",
        "\n",
        "    def savebin(self):\n",
        "        read = self.readimages\n",
        "        pp = self.preProcessing\n",
        "        fe = self.featureExtraction\n",
        "        images, names = read.read_Images(self.PATH_IMAGES_P)\n",
        "        for image_point, name_point in zip(images, names):\n",
        "            img_resize = pp.resize_Image(image_point, name_point)\n",
        "            img_resize = cv.cvtColor(img_resize, cv.COLOR_BGR2RGB)\n",
        "            img_resize = cv.cvtColor(img_resize, cv.COLOR_RGB2GRAY)\n",
        "            pp.bin(img_resize, name_point)\n",
        "\n",
        "    def main_alldataset(self):\n",
        "        cc = self.clasification\n",
        "\n",
        "        # Ask for user input for number of iterations and dataset splits\n",
        "        times_execution = int(input('\\nIndicate the number of iterations: '))\n",
        "        folds = int(input('\\nNumber of folds to split the dataset: '))\n",
        "        test_size = float(input('\\nPercentage of test dataset (e.g., 20 for 20%): '))\n",
        "\n",
        "        for i in range(times_execution):\n",
        "            # Read features and labels\n",
        "            filefeaturespath = os.path.join(self.PROJECT_PATH, 'FeatureExtraction', 'features.csv')\n",
        "            names, features = cc.readfeatures(filefeaturespath)\n",
        "            labels = cc.readLabels(self.PATH_Labels)\n",
        "\n",
        "            # Cross-validation\n",
        "            X, Y = cc.CrossValidation(features, labels, test_size / 100)\n",
        "            SVM_results, DT_results, KNN_results = cc.classification(\n",
        "                self.PATH_IMAGES, X, Y, folds, tags=['0', '1', '2', '3'],\n",
        "                target_names=['a1', 'a2', 'a3', 'a35'],\n",
        "                vals_to_replace={'a1': '0', 'a2': '1', 'a3': '2', 'a35': '3'}\n",
        "            )\n",
        "\n",
        "            print(f'\\n--------- Iteration {i+1} ---------')\n",
        "\n",
        "            for SVM_result, DT_result, KNN_result in zip(SVM_results, DT_results, KNN_results):\n",
        "                matrix_confusion_SVM, report_clasification_SVM, score_accuracy_SVM = SVM_result\n",
        "                matrix_confusion_DT, report_clasification_DT, score_accuracy_DT = DT_result\n",
        "                matrix_confusion_KNN, report_clasification_KNN, score_accuracy_KNN = KNN_result\n",
        "\n",
        "                print('\\n------- SVM Results -------')\n",
        "                print('Confusion Matrix:\\n', matrix_confusion_SVM)\n",
        "                print('Classification Report:\\n', report_clasification_SVM)\n",
        "                print('Mean Accuracy:', np.mean(score_accuracy_SVM))\n",
        "\n",
        "                print('\\n------- Decision Tree Results -------')\n",
        "                print('Confusion Matrix:\\n', matrix_confusion_DT)\n",
        "                print('Classification Report:\\n', report_clasification_DT)\n",
        "                print('Mean Accuracy:', np.mean(score_accuracy_DT))\n",
        "\n",
        "                print('\\n------- KNN Results -------')\n",
        "                print('Confusion Matrix:\\n', matrix_confusion_KNN)\n",
        "                print('Classification Report:\\n', report_clasification_KNN)\n",
        "                print('Mean Accuracy:', np.mean(score_accuracy_KNN))\n",
        "\n",
        "            print('--------- End of Iteration ---------')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tesis = MainClass()\n",
        "    tesis.main_alldataset()\n",
        "    print('Experiment execution completed.')\n"
      ],
      "metadata": {
        "id": "Hj-NP-UU2PgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CLASSIFCATRON CLASS\n",
        "import errno\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "class Classification:\n",
        "    def __init__(self, PATH_PROJECT):\n",
        "        self.path_project = os.path.join(PATH_PROJECT, 'Classification')\n",
        "        try:\n",
        "            if not os.path.exists(self.path_project + 'SVM'):\n",
        "                self.path_getColor = os.path.join(self.path_project, 'SVM')\n",
        "                os.mkdir(self.path_getColor)\n",
        "                print('SVM Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('SVM Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    def readfeatures(self, features_Path):\n",
        "        # featuresFile = open(features_Path, \"r\")\n",
        "        # featuresData = csv.reader(featuresFile)\n",
        "        featuresFile = pd.read_csv(features_Path, sep=',', header=None)\n",
        "        names = featuresFile.iloc[:, 0]\n",
        "        features = featuresFile.iloc[:, 1:]\n",
        "        shapefile = featuresFile.shape\n",
        "        col = []\n",
        "        for x in range(0, shapefile[1]):\n",
        "            if x == 0:\n",
        "                col.append(\"NAME\")\n",
        "            else:\n",
        "                col.append(\"VALOR-\" + str(x))\n",
        "        featuresFile.columns = col\n",
        "        # print(featuresFile)\n",
        "        return names, features\n",
        "\n",
        "    def readLabels(self, labels_path):\n",
        "        labels_path = os.path.join(labels_path, 'Labels.csv')\n",
        "        labels = pd.read_csv(labels_path, sep=',', header=[0])\n",
        "        return labels\n",
        "\n",
        "    def classificatorSVM(self, features, labels):\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        clf = svm.SVC(gamma='scale')\n",
        "        clf.fit(X, tags)\n",
        "        return clf\n",
        "\n",
        "    def DecisionTree(self, features, labels):\n",
        "        dt = DecisionTreeClassifier(random_state=30, max_depth=300)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        dt.fit(X, tags)\n",
        "\n",
        "        return dt\n",
        "\n",
        "    def KNN(self, features, labels):\n",
        "        knn = KNeighborsClassifier(n_neighbors=155, algorithm='auto', weights='distance', n_jobs=-1)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        knn.fit(X, tags)\n",
        "        return knn\n",
        "\n",
        "    def classification(self, path_dataset, features, labels, n_splits, tags, target_names, vals_to_replace):\n",
        "        pd.options.mode.chained_assignment = None\n",
        "        onlyfiles = [f for f in listdir(path_dataset) if\n",
        "                     isfile(join(path_dataset, f))]\n",
        "        #print(onlyfiles)\n",
        "        k_folds = KFold(n_splits=n_splits)\n",
        "        SVM = []\n",
        "        KNN = []\n",
        "        DT = []\n",
        "        for stage, feature in zip(labels, features):\n",
        "            stage['Color'] = stage['Color'].map(vals_to_replace)\n",
        "            labels_color = stage['Color'].to_numpy().tolist()\n",
        "            images_name = stage['Nombre de la imagen'].to_numpy().tolist()\n",
        "            svm_training_Score = []\n",
        "            confusion_matrix_svm = []\n",
        "            confusion_matrix_dt = []\n",
        "            confusion_matrix_knn = []\n",
        "            classification_report_svm = []\n",
        "            classification_report_dt = []\n",
        "            classification_report_knn = []\n",
        "            score_accuracy_SVM = []\n",
        "            score_accuracy_DT = []\n",
        "            score_accuracy_KNN = []\n",
        "            #index_images_name = [onlyfiles.index(element) for element in images_name if element in onlyfiles]\n",
        "            index_images_name = [images_name.index(file.split('.')[0]) for file in onlyfiles if file.split('.')[0] in images_name]\n",
        "            #index_images_name = []\n",
        "            k_folds.get_n_splits(index_images_name)\n",
        "            #print(list(images_name.index))\n",
        "\n",
        "            for train_index, test_index in k_folds.split(index_images_name):\n",
        "                train_label = []\n",
        "                test_label = []\n",
        "                train_features = []\n",
        "                test_features = []\n",
        "                print(\"Training indices:\", [index_images_name[i] for i in train_index])\n",
        "                print(\"Testing indices:\", [index_images_name[i] for i in test_index])\n",
        "\n",
        "                for i in train_index:\n",
        "\n",
        "                    currentFilename=images_name[i]\n",
        "                    train_features.append(feature.to_numpy().tolist()[index_images_name[i]])\n",
        "                    # train_features.append(feature.to_numpy()[images_name.str(onlyfiles[i].split('.')[0])])\n",
        "                    train_label.append(labels_color[index_images_name[i]])\n",
        "\n",
        "                SVM_Classifier = self.classificatorSVM(train_features, train_label)\n",
        "                DT_Classifier = self.DecisionTree(train_features, train_label)\n",
        "                KNN_Classifier = self.KNN(train_features, train_label)\n",
        "\n",
        "                for i in test_index:\n",
        "\n",
        "                    test_features.append(feature.to_numpy()[index_images_name[i]])\n",
        "                    test_label.append(labels_color[index_images_name[i]])\n",
        "                predict_label_SVM = SVM_Classifier.predict(test_features)\n",
        "                predict_label_DT = DT_Classifier.predict(test_features)\n",
        "                predict_label_KNN = KNN_Classifier.predict(test_features)\n",
        "\n",
        "                confusionMatrixSVM = confusion_matrix(test_label, predict_label_SVM)\n",
        "                confusionMatrixDT = confusion_matrix(test_label, predict_label_DT)\n",
        "                confusionMatrixKNN = confusion_matrix(test_label, predict_label_KNN)\n",
        "\n",
        "                classification_report_svm.append(\n",
        "                    classification_report(test_label, predict_label_SVM, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_dt.append(\n",
        "                    classification_report(test_label, predict_label_DT, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_knn.append(\n",
        "                    classification_report(test_label, predict_label_KNN, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "\n",
        "                confusion_matrix_svm.append(confusionMatrixSVM)\n",
        "                confusion_matrix_dt.append(confusionMatrixDT)\n",
        "                confusion_matrix_knn.append(confusionMatrixKNN)\n",
        "\n",
        "                score_accuracy_SVM.append(accuracy_score(test_label, predict_label_SVM))\n",
        "                score_accuracy_DT.append(accuracy_score(test_label, predict_label_DT))\n",
        "                score_accuracy_KNN.append(accuracy_score(test_label, predict_label_KNN))\n",
        "            SVM_RESULTS = [confusion_matrix_svm, classification_report_svm, score_accuracy_SVM]\n",
        "            DT_RESULTS = [confusion_matrix_dt, classification_report_dt, score_accuracy_DT]\n",
        "            KNN_RESULTS = [confusion_matrix_knn, classification_report_knn, score_accuracy_KNN]\n",
        "            SVM.append(SVM_RESULTS)\n",
        "            KNN.append(KNN_RESULTS)\n",
        "            DT.append(DT_RESULTS)\n",
        "        return SVM, KNN, DT\n",
        "\n",
        "    def CrossValidation(self, image, labels, test_size):\n",
        "        X = []\n",
        "        Y = []\n",
        "        X_train, X_test, y_train, y_test = train_test_split(image, labels, test_size=test_size)\n",
        "        X.append(X_train)\n",
        "        X.append(X_test)\n",
        "        Y.append(y_train)\n",
        "        Y.append(y_test)\n",
        "        print()\n",
        "        return X, Y\n",
        "\n",
        "    def ROC_CURVE(self, label_test, label_score):\n",
        "        n_classes = label_test.shape\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(label_test[:, i], label_score[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(label_test.ravel(), label_score.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        # Plot of a ROC curve for a specific class\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic example')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"micro\"]))\n",
        "        for i in range(n_classes):\n",
        "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                           ''.format(i, roc_auc[i]))\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "V_u__N5p2hw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this just to know how to solve the Value ERrro in a simple version\n",
        "from sklearn.model_selection import KFold\n",
        "# Define the whole dataset\n",
        "AllData = [\"V\",\"X\", \"Y\", \"T\", \"R\", \"A\", \"O\", \"Q\", \"N\", \"U\", \"G\",\"P\"]\n",
        "\n",
        "# Define the training dataset (70% of AllData)\n",
        "porData = [\"Y\", \"T\", \"R\", \"A\", \"O\", \"Q\", \"N\", \"U\"]\n",
        "\n",
        "# Get the indices of the training dataset in the whole dataset\n",
        "porDataIndex = [AllData.index(element) for element in porData if element in AllData]\n",
        "print(\"AllData:\",AllData)\n",
        "print(\"portData :\",porData)\n",
        "print(\"indes all:\",porDataIndex)\n",
        "\n",
        "# Define the K-fold object with K=5\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "for train_index, test_index in kf.split(porDataIndex):\n",
        "    train_features=[]\n",
        "    test_features=[]\n",
        "\n",
        "    print(\"Training indices:\", [porDataIndex[i] for i in train_index])\n",
        "    print(\"Testing indices:\", [porDataIndex[i] for i in test_index])\n",
        "\n",
        "    for i in train_index:\n",
        "        current=porData[i]\n",
        "        train_features.append(porDataIndex[i])\n",
        "        print(f\"image with index ={porDataIndex[i]} and name {current} is added to training\")\n",
        "\n",
        "    for i in test_index:\n",
        "        current=porData[i]\n",
        "        test_features.append(porDataIndex[i])\n",
        "        print(f\"image with index ={porDataIndex[i]} and name {current} is added to test\")"
      ],
      "metadata": {
        "id": "dZp-N0gkrIsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#important CLASSIFICATION CLOSE FROM\n",
        "import errno\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "class Classification:\n",
        "    def __init__(self, PATH_PROJECT):\n",
        "        self.path_project = os.path.join(PATH_PROJECT, 'Classification')\n",
        "        try:\n",
        "            if not os.path.exists(self.path_project + 'SVM'):\n",
        "                self.path_getColor = os.path.join(self.path_project, 'SVM')\n",
        "                os.mkdir(self.path_getColor)\n",
        "                print('SVM Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('SVM Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    def readfeatures(self, features_Path):\n",
        "        # featuresFile = open(features_Path, \"r\")\n",
        "        # featuresData = csv.reader(featuresFile)\n",
        "        featuresFile = pd.read_csv(features_Path, sep=',', header=None)\n",
        "        names = featuresFile.iloc[:, 0]\n",
        "        features = featuresFile.iloc[:, 1:]\n",
        "        shapefile = featuresFile.shape\n",
        "        col = []\n",
        "        for x in range(0, shapefile[1]):\n",
        "            if x == 0:\n",
        "                col.append(\"NAME\")\n",
        "            else:\n",
        "                col.append(\"VALOR-\" + str(x))\n",
        "        featuresFile.columns = col\n",
        "        # print(featuresFile)\n",
        "        return names, features\n",
        "\n",
        "    def readLabels(self, labels_path):\n",
        "        labels_path = os.path.join(labels_path, 'Labels.csv')\n",
        "        labels = pd.read_csv(labels_path, sep=',', header=[0])\n",
        "        return labels\n",
        "\n",
        "    def classificatorSVM(self, features, labels):\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        clf = svm.SVC(gamma='scale')\n",
        "        clf.fit(X, tags)\n",
        "        return clf\n",
        "\n",
        "    def DecisionTree(self, features, labels):\n",
        "        dt = DecisionTreeClassifier(random_state=30, max_depth=300)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        dt.fit(X, tags)\n",
        "\n",
        "        return dt\n",
        "\n",
        "    def KNN(self, features, labels):\n",
        "        knn = KNeighborsClassifier(n_neighbors=200, algorithm='auto', weights='distance', n_jobs=-1)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        knn.fit(X, tags)\n",
        "        return knn\n",
        "\n",
        "    def classification(self, path_dataset, features, labels, n_splits, tags, target_names, vals_to_replace):\n",
        "        pd.options.mode.chained_assignment = None\n",
        "        onlyfiles = [f for f in listdir(path_dataset) if\n",
        "                     isfile(join(path_dataset, f))]\n",
        "        #print(onlyfiles)\n",
        "        k_folds = KFold(n_splits=n_splits)\n",
        "        SVM = []\n",
        "        KNN = []\n",
        "        DT = []\n",
        "        for stage, feature in zip(labels, features):\n",
        "            stage['Color'] = stage['Color'].map(vals_to_replace)\n",
        "            labels_color = stage['Color'].to_numpy().tolist()\n",
        "            images_name = stage['Nombre de la imagen'].to_numpy().tolist()\n",
        "            svm_training_Score = []\n",
        "            confusion_matrix_svm = []\n",
        "            confusion_matrix_dt = []\n",
        "            confusion_matrix_knn = []\n",
        "            classification_report_svm = []\n",
        "            classification_report_dt = []\n",
        "            classification_report_knn = []\n",
        "            score_accuracy_SVM = []\n",
        "            score_accuracy_DT = []\n",
        "            score_accuracy_KNN = []\n",
        "            index_images_name=[]\n",
        "            # Assuming you have corrected the issue with index_images_name\n",
        "            # Generate index_images_name based on matching base names (without extensions)\n",
        "            index_images_name = [images_name.index(file.split('.')[0]) for file in onlyfiles if file.split('.')[0] in images_name]            # Debugging the index calculation\n",
        "\n",
        "            # Verify the correctness of index_images_name\n",
        "            print(f\"\\nLength of index_images_name: {len(index_images_name)}\",index_images_name[0],index_images_name[-1],\"\\n\")\n",
        "\n",
        "            for train_index, test_index in k_folds.split(index_images_name):\n",
        "                train_label = []\n",
        "                test_label = []\n",
        "                train_features = []\n",
        "                test_features = []\n",
        "                print(f\"\\n the train_index {len(train_index)}=\",train_index ,\"\\n\")\n",
        "                print(f\"\\n the test_index {len(test_index)}=\",test_index ,\"\\n\")\n",
        "\n",
        "                for i in train_index:\n",
        "                    train_features.append(feature.to_numpy().tolist()[images_name.index(onlyfiles[i].split('.')[0])])\n",
        "                    # train_features.append(feature.to_numpy()[images_name.str(onlyfiles[i].split('.')[0])])\n",
        "                    train_label.append(labels_color[images_name.index(onlyfiles[i].split('.')[0])])\n",
        "                SVM_Classifier = self.classificatorSVM(train_features, train_label)\n",
        "                DT_Classifier = self.DecisionTree(train_features, train_label)\n",
        "                KNN_Classifier = self.KNN(train_features, train_label)\n",
        "\n",
        "                for i in test_index:\n",
        "                    test_features.append(feature.to_numpy()[images_name.index(str(onlyfiles[i].split('.')[0]))])\n",
        "                    test_label.append(labels_color[images_name.index(str(onlyfiles[i].split('.')[0]))])\n",
        "                predict_label_SVM = SVM_Classifier.predict(test_features)\n",
        "                predict_label_DT = DT_Classifier.predict(test_features)\n",
        "                predict_label_KNN = KNN_Classifier.predict(test_features)\n",
        "\n",
        "                confusionMatrixSVM = confusion_matrix(test_label, predict_label_SVM)\n",
        "                confusionMatrixDT = confusion_matrix(test_label, predict_label_DT)\n",
        "                confusionMatrixKNN = confusion_matrix(test_label, predict_label_KNN)\n",
        "\n",
        "                classification_report_svm.append(\n",
        "                    classification_report(test_label, predict_label_SVM, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_dt.append(\n",
        "                    classification_report(test_label, predict_label_DT, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_knn.append(\n",
        "                    classification_report(test_label, predict_label_KNN, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "\n",
        "                confusion_matrix_svm.append(confusionMatrixSVM)\n",
        "                confusion_matrix_dt.append(confusionMatrixDT)\n",
        "                confusion_matrix_knn.append(confusionMatrixKNN)\n",
        "\n",
        "                score_accuracy_SVM.append(accuracy_score(test_label, predict_label_SVM))\n",
        "                score_accuracy_DT.append(accuracy_score(test_label, predict_label_DT))\n",
        "                score_accuracy_KNN.append(accuracy_score(test_label, predict_label_KNN))\n",
        "            SVM_RESULTS = [confusion_matrix_svm, classification_report_svm, score_accuracy_SVM]\n",
        "            DT_RESULTS = [confusion_matrix_dt, classification_report_dt, score_accuracy_DT]\n",
        "            KNN_RESULTS = [confusion_matrix_knn, classification_report_knn, score_accuracy_KNN]\n",
        "            SVM.append(SVM_RESULTS)\n",
        "            KNN.append(KNN_RESULTS)\n",
        "            DT.append(DT_RESULTS)\n",
        "        return SVM, KNN, DT\n",
        "\n",
        "    def CrossValidation(self, image, labels, test_size):\n",
        "        X = []\n",
        "        Y = []\n",
        "        X_train, X_test, y_train, y_test = train_test_split(image, labels, test_size=test_size)\n",
        "        X.append(X_train)\n",
        "        X.append(X_test)\n",
        "        Y.append(y_train)\n",
        "        Y.append(y_test)\n",
        "        print()\n",
        "        return X, Y\n",
        "\n",
        "    def ROC_CURVE(self, label_test, label_score):\n",
        "        n_classes = label_test.shape\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(label_test[:, i], label_score[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(label_test.ravel(), label_score.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        # Plot of a ROC curve for a specific class\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic example')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"micro\"]))\n",
        "        for i in range(n_classes):\n",
        "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                           ''.format(i, roc_auc[i]))\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U5Z8JF_773xv",
        "outputId": "8e71e922-26d8-458f-928f-4bfc4d9779c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PreProcessing Directory Already Exists.\n",
            "FeatureExtraction Directory Already Exists.\n",
            "Sampling Directory Already Exists.\n",
            "Classification Directory Already Exists.\n",
            "Segmentation Directory Already Exists.\n",
            "BarPlot Directory Already Exists.\n",
            "BarPlotCh1 Directory Already Exists.\n",
            "BarPlotCh2 Directory Already Exists.\n",
            "BarPlotCh3 Directory Already Exists.\n",
            "Mask Directory Already Exists.\n",
            "MaskOverlay Directory Already Exists.\n",
            "Inverse Directory Already Exists.\n",
            "ResizeImages Directory Already Exists.\n",
            "RGB2YCbCr Directory Already Exists.\n",
            "HSV Directory Already Exists.\n",
            "LAB Directory Already Exists.\n",
            "Lab_ Directory Already Exists.\n",
            "ResizeImages Directory Already Exists.\n",
            "Segmentation Directory Already Exists.\n",
            "BarPlot Directory Already Exists.\n",
            "BarPlotCh1 Directory Already Exists.\n",
            "BarPlotCh2 Directory Already Exists.\n",
            "BarPlotCh3 Directory Already Exists.\n",
            "Mask Directory Already Exists.\n",
            "MaskOverlay Directory Already Exists.\n",
            "Inverse Directory Already Exists.\n",
            "ResizeImages Directory Already Exists.\n",
            "RGB2YCbCr Directory Already Exists.\n",
            "HSV Directory Already Exists.\n",
            "LAB Directory Already Exists.\n",
            "Lab_ Directory Already Exists.\n",
            "SVM Directory Already Exists.\n",
            "Que desea hacer? \n",
            "1. Leer imagenes y obtener caracteristicas\n",
            "2. Leer archivo de caracteristicas y entrenar algoritmo\n",
            "2\n",
            "2\n",
            "\n",
            "Indique la cantidad de veces de ejecución:5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ? times/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cantidad de folios a seperarar el conjunto de datos:5\n",
            "\n",
            " Porcentaje de division del conjunto de datos trianing/test:20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/5 [00:02<?, ? times/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "'101_0138' is not in list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-45b8c450c147>\u001b[0m in \u001b[0;36m<cell line: 245>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mtesis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMainClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMainClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;31m# tesis.main_run()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mtesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain_alldataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;31m# tesis.savebin()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Se ha finalizado la ejecución del experimento'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-45b8c450c147>\u001b[0m in \u001b[0;36mmain_alldataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Porcentaje de division del conjunto de datos trianing/test:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossValidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPATH_IMAGES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvals_to_replace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------- Training ---------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/TEETH-RECOGNITION-WITH-MACHINE-LEARNING/Experiment/Source/Classification.py\u001b[0m in \u001b[0;36mclassification\u001b[0;34m(self, path_dataset, features, labels, n_splits, tags, target_names, vals_to_replace)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mtest_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                 \u001b[0;31m# Assuming `onlyfiles` contains all filenames in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0;31m# `images_name` contains filenames corresponding to the training dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: '101_0138' is not in list"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4Aw3PBQTFU3"
      },
      "source": [
        "# **`Saved codes to run`**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Copyright (c) 2019. Arnold Julian Herrera Quiñones -  Cristhian Camilo Arce García.\n",
        "#  All Rights Reserved\n",
        "#\n",
        "#  This product is protected by copyright and distributed under\n",
        "#  licenses restricting copying, distribution, and decompilation.\n",
        "#  It is forbidden the use partial or global of this algorithm  unless authors written permission.\n",
        "#\n",
        "import errno\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "class Classification:\n",
        "    def __init__(self, PATH_PROJECT):\n",
        "        self.path_project = os.path.join(PATH_PROJECT, 'Classification')\n",
        "        try:\n",
        "            if not os.path.exists(self.path_project + 'SVM'):\n",
        "                self.path_getColor = os.path.join(self.path_project, 'SVM')\n",
        "                os.mkdir(self.path_getColor)\n",
        "                print('SVM Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('SVM Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    def readfeatures(self, features_Path):\n",
        "\n",
        "        featuresFile = pd.read_csv(features_Path, sep=',', header=None)\n",
        "        names = featuresFile.iloc[:, 0]\n",
        "        features = featuresFile.iloc[:, 1:]\n",
        "        shapefile = featuresFile.shape\n",
        "        col = []\n",
        "        for x in range(0, shapefile[1]):\n",
        "            if x == 0:\n",
        "                col.append(\"NAME\")\n",
        "            else:\n",
        "                col.append(\"VALOR-\" + str(x))\n",
        "        featuresFile.columns = col\n",
        "        # print(featuresFile)\n",
        "        return names, features\n",
        "\n",
        "    def readLabels(self, labels_path):\n",
        "        labels_path = os.path.join(labels_path, 'Labels.csv')\n",
        "        labels = pd.read_csv(labels_path, sep=',', header=[0])\n",
        "        return labels\n",
        "\n",
        "    def classificatorSVM(self, features, labels):\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        clf = svm.SVC(gamma='scale')\n",
        "        clf.fit(X, tags)\n",
        "        return clf\n",
        "\n",
        "    def DecisionTree(self, features, labels):\n",
        "        dt = DecisionTreeClassifier(random_state=30, max_depth=300)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        dt.fit(X, tags)\n",
        "\n",
        "        return dt\n",
        "\n",
        "    def KNN(self, features, labels):\n",
        "        knn = KNeighborsClassifier(n_neighbors=200, algorithm='auto', weights='distance', n_jobs=-1)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        knn.fit(X, tags)\n",
        "        return knn\n",
        "\n",
        "    def classification(self, path_dataset, features, labels, n_splits, tags, target_names, vals_to_replace):\n",
        "        pd.options.mode.chained_assignment = None\n",
        "        onlyfiles = [f for f in listdir(path_dataset) if\n",
        "                     isfile(join(path_dataset, f))]\n",
        "        #print(onlyfiles)\n",
        "        k_folds = KFold(n_splits=n_splits)\n",
        "        SVM = []\n",
        "        KNN = []\n",
        "        DT = []\n",
        "        for stage, feature in zip(labels, features):\n",
        "            stage['Color'] = stage['Color'].map(vals_to_replace)\n",
        "            labels_color = stage['Color'].to_numpy().tolist()\n",
        "            images_name = stage['Nombre de la imagen'].to_numpy().tolist()\n",
        "            svm_training_Score = []\n",
        "            confusion_matrix_svm = []\n",
        "            confusion_matrix_dt = []\n",
        "            confusion_matrix_knn = []\n",
        "            classification_report_svm = []\n",
        "            classification_report_dt = []\n",
        "            classification_report_knn = []\n",
        "            score_accuracy_SVM = []\n",
        "            score_accuracy_DT = []\n",
        "            score_accuracy_KNN = []\n",
        "            index_images_name = []\n",
        "            k_folds.get_n_splits(index_images_name)\n",
        "            #print(list(images_name.index))\n",
        "\n",
        "            \"\"\"\n",
        "            1- first thing we need to make a index_images_name list that retreveis the indeces of the image_name list\n",
        "            for example it will takes from 0 to 777 index this its the range of the image_name that included\n",
        "            2- for the for loop when it spilts the k_fold it will spilt the train_index and test_index based on the\n",
        "            list of the index_images_name which contains 0--->777 this means that it takes from the indexcess for example\n",
        "            train_index =(0-->621) and tes_index =(622-->777) this way we guraannte that it takes from the image_name and\n",
        "            now for the for loop of the train_index let's suppose that i = 160 and when we retreves its name from onlyfiles\n",
        "            it gives for example PP.JPG after the spilt('.') the current_filename = \"PP\" and then it will go into if condition\n",
        "            which asks is this image: \" PP \" included in the list image_name(list of names) ?\n",
        "            so it supposed to return True because the index of this image is already taken from index_images_name which are\n",
        "            the list of indices of the image_name itself so it should find this image and then in the appeanding to train_featues\n",
        "            we could use the image_name.index or retireves its value from i\n",
        "            \"\"\"\n",
        "            for train_index, test_index in k_folds.split(index_images_name):\n",
        "                train_label = []\n",
        "                test_label = []\n",
        "                train_features = []\n",
        "                test_features = []\n",
        "                # Assuming `onlyfiles` contains all filenames in the dataset\n",
        "                # `images_name` contains filenames corresponding to the training dataset\n",
        "\n",
        "                for i in train_index:\n",
        "                    if i < len(images_name):  # Ensure i corresponds to a valid index in `images_name`\n",
        "                        current_filename = onlyfiles[i].split('.')[0].strip()\n",
        "                        if current_filename in images_name:  # Check if filename is part of the training dataset\n",
        "                            # Process the current_filename as part of the training dataset\n",
        "                            train_features.append(feature.to_numpy()[images_name.index(str(current_filename))])\n",
        "                            train_label.append(labels_color[images_name.index(str(current_filename))])\n",
        "                        else:\n",
        "                            print(f\"Warning: '{current_filename}' not found in training dataset.\")\n",
        "                    else:\n",
        "                        print(f\"Warning: Index {i} out of range for training dataset.\")\n",
        "\n",
        "                SVM_Classifier = self.classificatorSVM(train_features, train_label)\n",
        "                DT_Classifier = self.DecisionTree(train_features, train_label)\n",
        "                KNN_Classifier = self.KNN(train_features, train_label)\n",
        "                for i in test_index:\n",
        "                    if i < len(onlyfiles):  # Ensure `i` corresponds to a valid index in `onlyfiles`\n",
        "                        current_filename = onlyfiles[i].split('.')[0].strip()\n",
        "                        if current_filename in images_name:  # Check if filename is part of the training dataset\n",
        "                            # Process the `current_filename` as part of the test dataset\n",
        "                            test_features.append(feature.to_numpy()[images_name.index(str(current_filename))])\n",
        "                            test_label.append(labels_color[images_name.index(str(current_filename))])\n",
        "                        else:\n",
        "                            print(f\"Warning: '{current_filename}' not found in training dataset.\")\n",
        "                    else:\n",
        "                        print(f\"Warning: Index {i} out of range for `onlyfiles` dataset.\")\n",
        "\n",
        "\n",
        "                predict_label_SVM = SVM_Classifier.predict(test_features)\n",
        "                predict_label_DT = DT_Classifier.predict(test_features)\n",
        "                predict_label_KNN = KNN_Classifier.predict(test_features)\n",
        "\n",
        "                confusionMatrixSVM = confusion_matrix(test_label, predict_label_SVM)\n",
        "                confusionMatrixDT = confusion_matrix(test_label, predict_label_DT)\n",
        "                confusionMatrixKNN = confusion_matrix(test_label, predict_label_KNN)\n",
        "\n",
        "                classification_report_svm.append(\n",
        "                    classification_report(test_label, predict_label_SVM, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_dt.append(\n",
        "                    classification_report(test_label, predict_label_DT, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_knn.append(\n",
        "                    classification_report(test_label, predict_label_KNN, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "\n",
        "                confusion_matrix_svm.append(confusionMatrixSVM)\n",
        "                confusion_matrix_dt.append(confusionMatrixDT)\n",
        "                confusion_matrix_knn.append(confusionMatrixKNN)\n",
        "\n",
        "                score_accuracy_SVM.append(accuracy_score(test_label, predict_label_SVM))\n",
        "                score_accuracy_DT.append(accuracy_score(test_label, predict_label_DT))\n",
        "                score_accuracy_KNN.append(accuracy_score(test_label, predict_label_KNN))\n",
        "            SVM_RESULTS = [confusion_matrix_svm, classification_report_svm, score_accuracy_SVM]\n",
        "            DT_RESULTS = [confusion_matrix_dt, classification_report_dt, score_accuracy_DT]\n",
        "            KNN_RESULTS = [confusion_matrix_knn, classification_report_knn, score_accuracy_KNN]\n",
        "            SVM.append(SVM_RESULTS)\n",
        "            KNN.append(KNN_RESULTS)\n",
        "            DT.append(DT_RESULTS)\n",
        "        return SVM, KNN, DT\n",
        "\n",
        "    def CrossValidation(self, image, labels, test_size):\n",
        "        X = []\n",
        "        Y = []\n",
        "        X_train, X_test, y_train, y_test = train_test_split(image, labels, test_size=test_size)\n",
        "        X.append(X_train)\n",
        "        X.append(X_test)\n",
        "        Y.append(y_train)\n",
        "        Y.append(y_test)\n",
        "        print()\n",
        "        return X, Y\n",
        "\n",
        "    def ROC_CURVE(self, label_test, label_score):\n",
        "        n_classes = label_test.shape\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(label_test[:, i], label_score[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(label_test.ravel(), label_score.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        # Plot of a ROC curve for a specific class\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic example')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"micro\"]))\n",
        "        for i in range(n_classes):\n",
        "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                           ''.format(i, roc_auc[i]))\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "V8YuW25wHCMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_D_nBsvO9Nf"
      },
      "outputs": [],
      "source": [
        "#CLASSIFICATION ME\n",
        "import errno\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "class Classification:\n",
        "    def __init__(self, PATH_PROJECT):\n",
        "        self.path_project = os.path.join(PATH_PROJECT, 'Classification')\n",
        "        try:\n",
        "            if not os.path.exists(self.path_project + 'SVM'):\n",
        "                self.path_getColor = os.path.join(self.path_project, 'SVM')\n",
        "                os.mkdir(self.path_getColor)\n",
        "                print('SVM Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('SVM Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    def readfeatures(self, features_Path):\n",
        "        # featuresFile = open(features_Path, \"r\")\n",
        "        # featuresData = csv.reader(featuresFile)\n",
        "        featuresFile = pd.read_csv(features_Path, sep=',', header=None)\n",
        "        names = featuresFile.iloc[:, 0]\n",
        "        features = featuresFile.iloc[:, 1:]\n",
        "        shapefile = featuresFile.shape\n",
        "        col = []\n",
        "        for x in range(0, shapefile[1]):\n",
        "            if x == 0:\n",
        "                col.append(\"NAME\")\n",
        "            else:\n",
        "                col.append(\"VALOR-\" + str(x))\n",
        "        featuresFile.columns = col\n",
        "        # print(featuresFile)\n",
        "        print(\"\\nNumber of features :\",len(features),\"\\n\")\n",
        "        print(\"\\nNumber of names :\",len(names),\"\\n\")\n",
        "        return names, features\n",
        "\n",
        "    def readLabels(self, labels_path):\n",
        "        labels_path = os.path.join(labels_path, 'Labels.csv')\n",
        "        labels = pd.read_csv(labels_path, sep=',', header=[0])\n",
        "        print(\"\\nNumber of labels :\",len(labels),\"\\n\")\n",
        "        return labels\n",
        "\n",
        "\n",
        "    def classificatorSVM(self, features, labels):\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        clf = svm.SVC(gamma='scale')\n",
        "        clf.fit(X, tags)\n",
        "        return clf\n",
        "\n",
        "    def DecisionTree(self, features, labels):\n",
        "        dt = DecisionTreeClassifier(random_state=30, max_depth=300)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        dt.fit(X, tags)\n",
        "\n",
        "        return dt\n",
        "\n",
        "    def KNN(self, features, labels):\n",
        "        knn = KNeighborsClassifier(n_neighbors=200, algorithm='auto', weights='distance', n_jobs=-1)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        knn.fit(X, tags)\n",
        "        return knn\n",
        "\n",
        "    def classification(self, path_dataset, features, labels, n_splits, tags, target_names, vals_to_replace):\n",
        "        pd.options.mode.chained_assignment = None\n",
        "        num_images = len(os.listdir(path_dataset))\n",
        "        print(f\"Number of images in dataset Classi def: {num_images}\")\n",
        "        onlyfiles = [f for f in listdir(path_dataset) if\n",
        "                     isfile(join(path_dataset, f))] # all dataset=973\n",
        "        onlyfiles = sorted(onlyfiles)\n",
        "        print(\"\\nNumber of only files :\",len(onlyfiles),\"\\n\")\n",
        "\n",
        "        print(\"\\nNumber of features in classi def :\",len(features),\"\\n\")\n",
        "        print(\"\\nNumber of labels classi def :\",len(labels),\"\\n\")\n",
        "        k_folds = KFold(n_splits=n_splits)\n",
        "        SVM = []\n",
        "        KNN = []\n",
        "        DT = []\n",
        "        for stage, feature in zip(labels, features):\n",
        "            stage['Color'] = stage['Color'].map(vals_to_replace)\n",
        "            labels_color = stage['Color'].to_numpy().tolist()\n",
        "            images_name = stage['Nombre de la imagen'].to_numpy().tolist()\n",
        "            print(f\"Sample of image names in current stage {len(images_name)}:\")\n",
        "            #print(\"Images names from labels.csv:\", images_name)\n",
        "            print(\"\\nNumber of training labels_color in  labels.csv :\",len(labels_color),\"\\n\")\n",
        "            svm_training_Score = []\n",
        "            confusion_matrix_svm = []\n",
        "            confusion_matrix_dt = []\n",
        "            confusion_matrix_knn = []\n",
        "            classification_report_svm = []\n",
        "            classification_report_dt = []\n",
        "            classification_report_knn = []\n",
        "            score_accuracy_SVM = []\n",
        "            score_accuracy_DT = []\n",
        "            score_accuracy_KNN = []\n",
        "            index_images_name = []\n",
        "            k_folds.get_n_splits(index_images_name)\n",
        "            #print(list(images_name.index))\n",
        "            imageIsFound=0\n",
        "            missing_images_count = 0\n",
        "            print(\"\\nonlyfile :\",onlyfiles[:5])\n",
        "            print(\"\\n Image_name :\",images_name[:5])\n",
        "\n",
        "            #missing_images_list = []\n",
        "            for train_index, test_index in k_folds.split(images_name):\n",
        "                print(f\"Train Index: {len(train_index)}\")\n",
        "                print(f\"Test Index: {len(test_index)}\")\n",
        "                print(\"\\hello i'm inside for KFOLD\\n\")\n",
        "                train_label = []\n",
        "                test_label = []\n",
        "                train_features = []\n",
        "                test_features = []\n",
        "\n",
        "                # Assuming `features` is a list of image names or identifiers\n",
        "                print(\"\\nSample of test features\",test_features,\"\\n\")\n",
        "                print(\"\\nSample of train features\",train_features,\"\\n\")\n",
        "                print(\"\\nSample of train label\",train_label,\"\\n\")\n",
        "                print(\"Sample of test label\",test_label,\"\\n\")\n",
        "                print(\"\\nSample of  train_index\",train_index,\"\\n\")\n",
        "                print(\"Sample of test index\",test_index,\"\\n\")\n",
        "\n",
        "\n",
        "\n",
        "                for i in train_index:\n",
        "\n",
        "                  current_filename = onlyfiles[i].split('.')[0].strip()  # Get the filename without extension and strip whitespace\n",
        "\n",
        "                  if current_filename in images_name:\n",
        "                      train_features.append(feature.to_numpy().tolist()[images_name.index(current_filename)])\n",
        "                      #print(f\"\\nhello I'm inside For LOOP for train index of image name: {current_filename}\\n\")\n",
        "                      #print(f\"\\nhello I'm inside For loop of train feature is added to {current_filename}\\n\")\n",
        "                      train_label.append(labels_color[images_name.index(current_filename)])\n",
        "                      #print(f\"\\nhello I'm inside For loop of train label is added to : {current_filename}\\n\")\n",
        "                      imageIsFound += 1\n",
        "                  else:\n",
        "\n",
        "                      print(f\"Warning: '{current_filename}' not found in images_name because its index of {i}. Skipping this image.\")\n",
        "                      missing_images_count +=1\n",
        "\n",
        "                print(f\"Number of found images: {imageIsFound}\")\n",
        "                print(f\"Number of missing images: {missing_images_count}\")\n",
        "                print(f\"Total number of images: {missing_images_count+imageIsFound}\\n\")\n",
        "                print(f\"Total number of Train_features : {len(train_features)}\")\n",
        "                print(f\"Total number of train_label : {len(train_label)}\")\n",
        "                SVM_Classifier = self.classificatorSVM(train_features, train_label)\n",
        "                DT_Classifier = self.DecisionTree(train_features, train_label)\n",
        "                KNN_Classifier = self.KNN(train_features, train_label)\n",
        "                print(f\"\\nhello I'm inside For loop of Train index is **END** to ALL classifiers \\n\")\n",
        "\n",
        "                for i in test_index:\n",
        "                            #print(f\"\\nhello I'm inside For LOOP for Test index of image name: {current_filename}\\n\")\n",
        "                            test_features.append(feature.to_numpy()[images_name.index(str(onlyfiles[i].split('.')[0]))])\n",
        "                            #test_features.append(feature.to_numpy().tolist()[images_name.index(current_filename)])\n",
        "                            print(f\"\\nhello I'm inside For loop of Test  feature is added to {current_filename}\\n\")\n",
        "                            test_label.append(labels_color[images_name.index(str(onlyfiles[i].split('.')[0]))])\n",
        "                            print(f\"\\nhello I'm inside For loop of Test Label is added to {current_filename}\\n\")\n",
        "\n",
        "\n",
        "                predict_label_SVM = SVM_Classifier.predict(test_features)\n",
        "                predict_label_DT = DT_Classifier.predict(test_features)\n",
        "                predict_label_KNN = KNN_Classifier.predict(test_features)\n",
        "                print(f\"\\n I'm inside For loop of test  index is **END** to ALL classifiers of image : {current_filename}\\n\")\n",
        "\n",
        "                confusionMatrixSVM = confusion_matrix(test_label, predict_label_SVM)\n",
        "                confusionMatrixDT = confusion_matrix(test_label, predict_label_DT)\n",
        "                confusionMatrixKNN = confusion_matrix(test_label, predict_label_KNN)\n",
        "                print(f\"\\n I'm inside For loop of Confusion matrix is **ADDED ** to ALL martiecs of image : {current_filename}\\n\")\n",
        "\n",
        "                classification_report_svm.append(\n",
        "                    classification_report(test_label, predict_label_SVM, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_dt.append(\n",
        "                    classification_report(test_label, predict_label_DT, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_knn.append(\n",
        "                    classification_report(test_label, predict_label_KNN, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "\n",
        "                confusion_matrix_svm.append(confusionMatrixSVM)\n",
        "                confusion_matrix_dt.append(confusionMatrixDT)\n",
        "                confusion_matrix_knn.append(confusionMatrixKNN)\n",
        "\n",
        "                score_accuracy_SVM.append(accuracy_score(test_label, predict_label_SVM))\n",
        "                score_accuracy_DT.append(accuracy_score(test_label, predict_label_DT))\n",
        "                score_accuracy_KNN.append(accuracy_score(test_label, predict_label_KNN))\n",
        "            SVM_RESULTS = [confusion_matrix_svm, classification_report_svm, score_accuracy_SVM]\n",
        "            DT_RESULTS = [confusion_matrix_dt, classification_report_dt, score_accuracy_DT]\n",
        "            KNN_RESULTS = [confusion_matrix_knn, classification_report_knn, score_accuracy_KNN]\n",
        "            SVM.append(SVM_RESULTS)\n",
        "            KNN.append(KNN_RESULTS)\n",
        "            DT.append(DT_RESULTS)\n",
        "        return SVM, KNN, DT\n",
        "\n",
        "    def CrossValidation(self, image, labels, test_size):\n",
        "        X = []\n",
        "        Y = []\n",
        "        X_train, X_test, y_train, y_test = train_test_split(image, labels, test_size=test_size)\n",
        "        X.append(X_train)\n",
        "        X.append(X_test)\n",
        "        Y.append(y_train)\n",
        "        Y.append(y_test)\n",
        "        print()\n",
        "        return X, Y\n",
        "\n",
        "    def ROC_CURVE(self, label_test, label_score):\n",
        "        n_classes = label_test.shape\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(label_test[:, i], label_score[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(label_test.ravel(), label_score.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        # Plot of a ROC curve for a specific class\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic example')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"micro\"]))\n",
        "        for i in range(n_classes):\n",
        "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                           ''.format(i, roc_auc[i]))\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CLASSIFICATION ME reshape\n",
        "import errno\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "class Classification:\n",
        "    def __init__(self, PATH_PROJECT):\n",
        "        self.path_project = os.path.join(PATH_PROJECT, 'Classification')\n",
        "        try:\n",
        "            if not os.path.exists(self.path_project + 'SVM'):\n",
        "                self.path_getColor = os.path.join(self.path_project, 'SVM')\n",
        "                os.mkdir(self.path_getColor)\n",
        "                print('SVM Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('SVM Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    def readfeatures(self, features_Path):\n",
        "        # featuresFile = open(features_Path, \"r\")\n",
        "        # featuresData = csv.reader(featuresFile)\n",
        "        featuresFile = pd.read_csv(features_Path, sep=',', header=None)\n",
        "        names = featuresFile.iloc[:, 0]\n",
        "        features = featuresFile.iloc[:, 1:]\n",
        "        shapefile = featuresFile.shape\n",
        "        col = []\n",
        "        for x in range(0, shapefile[1]):\n",
        "            if x == 0:\n",
        "                col.append(\"NAME\")\n",
        "            else:\n",
        "                col.append(\"VALOR-\" + str(x))\n",
        "        featuresFile.columns = col\n",
        "        # print(featuresFile)\n",
        "        print(\"\\nNumber of features :\",len(features),\"\\n\")\n",
        "        print(\"\\nNumber of names :\",len(names),\"\\n\")\n",
        "        return names, features\n",
        "\n",
        "    def readLabels(self, labels_path):\n",
        "        labels_path = os.path.join(labels_path, 'Labels.csv')\n",
        "        labels = pd.read_csv(labels_path, sep=',', header=[0])\n",
        "        print(\"\\nNumber of labels :\",len(labels),\"\\n\")\n",
        "        return labels\n",
        "\n",
        "\n",
        "    def classificatorSVM(self, features, labels):\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        clf = svm.SVC(gamma='scale')\n",
        "        clf.fit(X, tags)\n",
        "        return clf\n",
        "\n",
        "    def DecisionTree(self, features, labels):\n",
        "        dt = DecisionTreeClassifier(random_state=30, max_depth=300)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        dt.fit(X, tags)\n",
        "\n",
        "        return dt\n",
        "\n",
        "    def KNN(self, features, labels):\n",
        "        knn = KNeighborsClassifier(n_neighbors=200, algorithm='auto', weights='distance', n_jobs=-1)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        knn.fit(X, tags)\n",
        "        return knn\n",
        "\n",
        "    def classification(self, path_dataset, features, labels, n_splits, tags, target_names, vals_to_replace):\n",
        "        pd.options.mode.chained_assignment = None\n",
        "        num_images = len(os.listdir(path_dataset))\n",
        "        print(f\"Number of images in dataset Classi def: {num_images}\")\n",
        "        onlyfiles = [f for f in listdir(path_dataset) if\n",
        "                     isfile(join(path_dataset, f))] # all dataset=973\n",
        "        print(\"\\nNumber of only files :\",len(onlyfiles),\"\\n\")\n",
        "\n",
        "        print(\"\\nNumber of features in classi def :\",len(features),\"\\n\")\n",
        "        print(\"\\nNumber of labels classi def :\",len(labels),\"\\n\")\n",
        "        k_folds = KFold(n_splits=n_splits)\n",
        "        SVM = []\n",
        "        KNN = []\n",
        "        DT = []\n",
        "        for stage, feature in zip(labels, features):\n",
        "            stage['Color'] = stage['Color'].map(vals_to_replace)\n",
        "            labels_color = stage['Color'].to_numpy().tolist()\n",
        "            images_name = stage['Nombre de la imagen'].to_numpy().tolist()\n",
        "            print(f\"Sample of image names in current stage {len(images_name)}:\")\n",
        "            #print(\"Images names from labels.csv:\", images_name)\n",
        "            print(\"\\nNumber of training labels_color in  labels.csv :\",len(labels_color),\"\\n\")\n",
        "            trainingDataset=images_name\n",
        "            #testDataset = list(set(onlyfiles) - set(images_name))\n",
        "            #print(f\"\\n training dataset= {len(trainingDataset)} and the test dataset ={len(testDataset)}\\n\")\\\n",
        "\n",
        "\n",
        "            svm_training_Score = []\n",
        "            confusion_matrix_svm = []\n",
        "            confusion_matrix_dt = []\n",
        "            confusion_matrix_knn = []\n",
        "            classification_report_svm = []\n",
        "            classification_report_dt = []\n",
        "            classification_report_knn = []\n",
        "            score_accuracy_SVM = []\n",
        "            score_accuracy_DT = []\n",
        "            score_accuracy_KNN = []\n",
        "            index_images_name = []\n",
        "            k_folds.get_n_splits(index_images_name)\n",
        "            #print(list(images_name.index))\n",
        "            imageIsFoundTrain=0\n",
        "            imageIsFoundTest=0\n",
        "            missingTRain_images_count = 0\n",
        "            missingTest_images_count = 0\n",
        "\n",
        "            print(\"\\nonlyfile :\",onlyfiles[:5])\n",
        "            print(\"\\n Image_name :\",images_name[:5])\n",
        "            fold_num=0\n",
        "            #missing_images_list = []\n",
        "            for train_index, test_index in k_folds.split(trainingDataset):\n",
        "                print(f\"Train Index: {len(train_index)}\")\n",
        "                print(f\"Test Index: {len(test_index)}\")\n",
        "                fold_num+=1\n",
        "                print(f\"\\n hello i'm inside Fold number = {fold_num}\\n\")\n",
        "                train_label = []\n",
        "                test_label = []\n",
        "                train_features = []\n",
        "                test_features = []\n",
        "\n",
        "                # Assuming `features` is a list of image names or identifiers\n",
        "                \"\"\"print(\"\\nSample of test features\",test_features,\"\\n\")\n",
        "                print(\"\\nSample of train features\",train_features,\"\\n\")\n",
        "                print(\"\\nSample of train label\",train_label,\"\\n\")\n",
        "                print(\"Sample of test label\",test_label,\"\\n\")\"\"\"\n",
        "                #print(\"\\nSample of  train_index\",train_index,\"\\n\")\n",
        "                #print(\"Sample of test index\",test_index,\"\\n\")\n",
        "\n",
        "                for i in train_index:\n",
        "\n",
        "                      current_filename = onlyfiles[i].split('.')[0].strip()  # Get the filename without extension and strip whitespace\n",
        "\n",
        "                      if current_filename in trainingDataset:\n",
        "                          train_features.append(feature.to_numpy().tolist()[images_name.index(current_filename)])\n",
        "                          #print(f\"\\nhello I'm inside For LOOP for train index of image name: {current_filename}\\n\")\n",
        "                          #print(f\"\\nhello I'm inside For loop of train feature is added to {current_filename}\\n\")\n",
        "                          train_label.append(labels_color[images_name.index(current_filename)])\n",
        "                          #print(f\"\\nhello I'm inside For loop of train label is added to : {current_filename}\\n\")\n",
        "                          imageIsFoundTrain += 1\n",
        "                      else:\n",
        "\n",
        "                          #print(f\"Warning: '{current_filename}' not found in images_name because its index of {i}.train.\")\n",
        "                          missingTRain_images_count +=1\n",
        "\n",
        "                print(f\"Number of found images train: {imageIsFoundTrain}\")\n",
        "                print(f\"Number of missing images in train: {missingTRain_images_count}\")\n",
        "                print(f\"Total number of images train: {missingTRain_images_count+imageIsFoundTrain}\\n\")\n",
        "                print(f\"Total number of Train_features : {len(train_features)}\")\n",
        "                print(f\"Total number of train_label : {len(train_label)}\")\n",
        "                SVM_Classifier = self.classificatorSVM(train_features, train_label)\n",
        "                DT_Classifier = self.DecisionTree(train_features, train_label)\n",
        "                KNN_Classifier = self.KNN(train_features, train_label)\n",
        "                print(\"\\n **************** END Train_index ******************\\n\")\n",
        "\n",
        "                for i in test_index:\n",
        "                    if current_filename in trainingDataset:\n",
        "                              #print(f\"\\nhello I'm inside For LOOP for Test index of image name: {current_filename}\\n\")\n",
        "                              test_features.append(feature.to_numpy()[images_name.index(str(current_filename))])\n",
        "                              #test_features.append(feature.to_numpy().tolist()[images_name.index(current_filename)])\n",
        "                              #print(f\"\\nhello I'm inside For loop of Test  feature is added to {current_filename}\\n\")\n",
        "                              test_label.append(labels_color[images_name.index(str(current_filename))])\n",
        "                              #print(f\"\\nhello I'm inside For loop of Test Label is added to {current_filename}\\n\")\n",
        "                              imageIsFoundTest +=1\n",
        "\n",
        "                    else:\n",
        "                        #print(f\"Warning: '{current_filename}' not found in images_name because its index of {i}. in test.\")\n",
        "                        missingTest_images_count +=1\n",
        "\n",
        "\n",
        "                print(f\"Number of found images in test: {imageIsFoundTest}\")\n",
        "                print(f\"Number of missing images in test: {missingTest_images_count}\")\n",
        "                print(f\"Total number of images: {missingTest_images_count+imageIsFoundTest}\\n\")\n",
        "                print(f\"Total number of in test features : {len(test_features)}\")\n",
        "                print(f\"Total number of test_label : {len(test_label)}\")\n",
        "                predict_label_SVM = SVM_Classifier.predict(test_features)\n",
        "                predict_label_DT = DT_Classifier.predict(test_features)\n",
        "                predict_label_KNN = KNN_Classifier.predict(test_features)\n",
        "                print(\"\\n **************** END test index ******************\\n\")\n",
        "\n",
        "                confusionMatrixSVM = confusion_matrix(test_label, predict_label_SVM)\n",
        "                confusionMatrixDT = confusion_matrix(test_label, predict_label_DT)\n",
        "                confusionMatrixKNN = confusion_matrix(test_label, predict_label_KNN)\n",
        "                print(f\"\\n I'm inside For loop of Confusion matrix is **ADDED ** \\n\")\n",
        "\n",
        "                classification_report_svm.append(\n",
        "                    classification_report(test_label, predict_label_SVM, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_dt.append(\n",
        "                    classification_report(test_label, predict_label_DT, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_knn.append(\n",
        "                    classification_report(test_label, predict_label_KNN, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "\n",
        "                confusion_matrix_svm.append(confusionMatrixSVM)\n",
        "                confusion_matrix_dt.append(confusionMatrixDT)\n",
        "                confusion_matrix_knn.append(confusionMatrixKNN)\n",
        "                print(f\"\\n -------> Confusion matrix is **APPENDED **\\n\")\n",
        "\n",
        "                score_accuracy_SVM.append(accuracy_score(test_label, predict_label_SVM))\n",
        "                score_accuracy_DT.append(accuracy_score(test_label, predict_label_DT))\n",
        "                score_accuracy_KNN.append(accuracy_score(test_label, predict_label_KNN))\n",
        "            SVM_RESULTS = [confusion_matrix_svm, classification_report_svm, score_accuracy_SVM]\n",
        "            DT_RESULTS = [confusion_matrix_dt, classification_report_dt, score_accuracy_DT]\n",
        "            KNN_RESULTS = [confusion_matrix_knn, classification_report_knn, score_accuracy_KNN]\n",
        "            SVM.append(SVM_RESULTS)\n",
        "            KNN.append(KNN_RESULTS)\n",
        "            DT.append(DT_RESULTS)\n",
        "        return SVM, KNN, DT\n",
        "\n",
        "    def CrossValidation(self, image, labels, test_size):\n",
        "        X = []\n",
        "        Y = []\n",
        "        X_train, X_test, y_train, y_test = train_test_split(image, labels, test_size=test_size)\n",
        "        X.append(X_train)\n",
        "        X.append(X_test)\n",
        "        Y.append(y_train)\n",
        "        Y.append(y_test)\n",
        "        print()\n",
        "        return X, Y\n",
        "\n",
        "    def ROC_CURVE(self, label_test, label_score):\n",
        "        n_classes = label_test.shape\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(label_test[:, i], label_score[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(label_test.ravel(), label_score.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        # Plot of a ROC curve for a specific class\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic example')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"micro\"]))\n",
        "        for i in range(n_classes):\n",
        "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                           ''.format(i, roc_auc[i]))\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "_xG_Wm85RnLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DAskc84OgB8"
      },
      "source": [
        "## **WorstCase**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTcQSKOyOcud"
      },
      "outputs": [],
      "source": [
        "#not good\n",
        "import errno\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "class Classification:\n",
        "    def __init__(self, PATH_PROJECT):\n",
        "        self.path_project = os.path.join(PATH_PROJECT, 'Classification')\n",
        "        try:\n",
        "            if not os.path.exists(self.path_project + 'SVM'):\n",
        "                self.path_getColor = os.path.join(self.path_project, 'SVM')\n",
        "                os.mkdir(self.path_getColor)\n",
        "                print('SVM Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('SVM Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    def readfeatures(self, features_Path):\n",
        "        # featuresFile = open(features_Path, \"r\")\n",
        "        # featuresData = csv.reader(featuresFile)\n",
        "        featuresFile = pd.read_csv(features_Path, sep=',', header=None)\n",
        "        names = featuresFile.iloc[:, 0]\n",
        "        features = featuresFile.iloc[:, 1:]\n",
        "        shapefile = featuresFile.shape\n",
        "        col = []\n",
        "        for x in range(0, shapefile[1]):\n",
        "            if x == 0:\n",
        "                col.append(\"NAME\")\n",
        "            else:\n",
        "                col.append(\"VALOR-\" + str(x))\n",
        "        featuresFile.columns = col\n",
        "        # print(featuresFile)\n",
        "        return names, features\n",
        "\n",
        "    def readLabels(self, labels_path):\n",
        "        labels_path = os.path.join(labels_path, 'Labels.csv')\n",
        "        labels = pd.read_csv(labels_path, sep=',', header=[0])\n",
        "        return labels\n",
        "\n",
        "    def classificatorSVM(self, features, labels):\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        clf = svm.SVC(gamma='scale')\n",
        "        clf.fit(X, tags)\n",
        "        return clf\n",
        "\n",
        "    def DecisionTree(self, features, labels):\n",
        "        dt = DecisionTreeClassifier(random_state=30, max_depth=300)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        dt.fit(X, tags)\n",
        "\n",
        "        return dt\n",
        "\n",
        "    def KNN(self, features, labels):\n",
        "        knn = KNeighborsClassifier(n_neighbors=200, algorithm='auto', weights='distance', n_jobs=-1)\n",
        "        X = []\n",
        "        for f in features:\n",
        "            X.append(f)\n",
        "        tags = []\n",
        "        for tag in labels:\n",
        "            tags.append(tag)\n",
        "        knn.fit(X, tags)\n",
        "        return knn\n",
        "\n",
        "    def classification(self, path_dataset, features, labels, n_splits, tags, target_names, vals_to_replace):\n",
        "        pd.options.mode.chained_assignment = None\n",
        "        onlyfiles = [f for f in listdir(path_dataset) if\n",
        "                     isfile(join(path_dataset, f))]\n",
        "        #print(onlyfiles)\n",
        "        k_folds = KFold(n_splits=n_splits)\n",
        "        SVM = []\n",
        "        KNN = []\n",
        "        DT = []\n",
        "        for stage, feature in zip(labels, features):\n",
        "            stage['Color'] = stage['Color'].map(vals_to_replace)\n",
        "            labels_color = stage['Color'].to_numpy().tolist()\n",
        "            images_name = stage['Nombre de la imagen'].to_numpy().tolist()\n",
        "            svm_training_Score = []\n",
        "            confusion_matrix_svm = []\n",
        "            confusion_matrix_dt = []\n",
        "            confusion_matrix_knn = []\n",
        "            classification_report_svm = []\n",
        "            classification_report_dt = []\n",
        "            classification_report_knn = []\n",
        "            score_accuracy_SVM = []\n",
        "            score_accuracy_DT = []\n",
        "            score_accuracy_KNN = []\n",
        "            index_images_name = []\n",
        "            k_folds.get_n_splits(index_images_name)\n",
        "\n",
        "            for train_index, test_index in k_folds.split(images_name):\n",
        "                train_label = []\n",
        "                test_label = []\n",
        "                train_features = []\n",
        "                test_features = []\n",
        "                for i in train_index:\n",
        "                  try:\n",
        "                      train_features.append(feature.to_numpy().tolist()[images_name.index(onlyfiles[i].split('.')[0])])\n",
        "                      train_label.append(labels_color[images_name.index(onlyfiles[i].split('.')[0])])\n",
        "                  except ValueError:\n",
        "                      print(f\"Warning: '{onlyfiles[i].split('.')[0]}' not found in images_name. Skipping...\")\n",
        "                continue\n",
        "                    #train_features.append(feature.to_numpy().tolist()[images_name.index(onlyfiles[i].split('.')[0])])\n",
        "                    # train_features.append(feature.to_numpy()[images_name.str(onlyfiles[i].split('.')[0])])\n",
        "                    #train_label.append(labels_color[images_name.index(onlyfiles[i].split('.')[0])])\n",
        "                SVM_Classifier = self.classificatorSVM(train_features, train_label)\n",
        "                DT_Classifier = self.DecisionTree(train_features, train_label)\n",
        "                KNN_Classifier = self.KNN(train_features, train_label)\n",
        "\n",
        "                for i in test_index:\n",
        "                    test_features.append(feature.to_numpy()[images_name.index(str(onlyfiles[i].split('.')[0]))])\n",
        "                    test_label.append(labels_color[images_name.index(str(onlyfiles[i].split('.')[0]))])\n",
        "                predict_label_SVM = SVM_Classifier.predict(test_features)\n",
        "                predict_label_DT = DT_Classifier.predict(test_features)\n",
        "                predict_label_KNN = KNN_Classifier.predict(test_features)\n",
        "\n",
        "                confusionMatrixSVM = confusion_matrix(test_label, predict_label_SVM)\n",
        "                confusionMatrixDT = confusion_matrix(test_label, predict_label_DT)\n",
        "                confusionMatrixKNN = confusion_matrix(test_label, predict_label_KNN)\n",
        "\n",
        "                classification_report_svm.append(\n",
        "                    classification_report(test_label, predict_label_SVM, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_dt.append(\n",
        "                    classification_report(test_label, predict_label_DT, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "                classification_report_knn.append(\n",
        "                    classification_report(test_label, predict_label_KNN, labels=tags,\n",
        "                                          target_names=target_names, sample_weight=None, digits=5,\n",
        "                                          output_dict=False))\n",
        "\n",
        "                confusion_matrix_svm.append(confusionMatrixSVM)\n",
        "                confusion_matrix_dt.append(confusionMatrixDT)\n",
        "                confusion_matrix_knn.append(confusionMatrixKNN)\n",
        "\n",
        "                score_accuracy_SVM.append(accuracy_score(test_label, predict_label_SVM))\n",
        "                score_accuracy_DT.append(accuracy_score(test_label, predict_label_DT))\n",
        "                score_accuracy_KNN.append(accuracy_score(test_label, predict_label_KNN))\n",
        "            SVM_RESULTS = [confusion_matrix_svm, classification_report_svm, score_accuracy_SVM]\n",
        "            DT_RESULTS = [confusion_matrix_dt, classification_report_dt, score_accuracy_DT]\n",
        "            KNN_RESULTS = [confusion_matrix_knn, classification_report_knn, score_accuracy_KNN]\n",
        "            SVM.append(SVM_RESULTS)\n",
        "            KNN.append(KNN_RESULTS)\n",
        "            DT.append(DT_RESULTS)\n",
        "        return SVM, KNN, DT\n",
        "\n",
        "    def CrossValidation(self, image, labels, test_size):\n",
        "        X = []\n",
        "        Y = []\n",
        "        X_train, X_test, y_train, y_test = train_test_split(image, labels, test_size=test_size)\n",
        "        X.append(X_train)\n",
        "        X.append(X_test)\n",
        "        Y.append(y_train)\n",
        "        Y.append(y_test)\n",
        "        print()\n",
        "        return X, Y\n",
        "\n",
        "    def ROC_CURVE(self, label_test, label_score):\n",
        "        n_classes = label_test.shape\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        for i in range(n_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(label_test[:, i], label_score[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        # Compute micro-average ROC curve and ROC area\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(label_test.ravel(), label_score.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "        # Plot of a ROC curve for a specific class\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver operating characteristic example')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "                 label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                       ''.format(roc_auc[\"micro\"]))\n",
        "        for i in range(n_classes):\n",
        "            plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                                           ''.format(i, roc_auc[i]))\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfR2DkVbK0tu"
      },
      "outputs": [],
      "source": [
        "#not good\n",
        "\n",
        "import errno\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "import Source.Classification as Cl\n",
        "import Source.FeatureExtraction as fE\n",
        "import Source.PreProcessingData as pD\n",
        "import Source.ReadImages as rI\n",
        "\n",
        "\n",
        "def show(image):\n",
        "    cv.imshow('Imagen ', image)\n",
        "    cv.waitKey(0)\n",
        "    cv.destroyAllWindows()\n",
        "\n",
        "\n",
        "class MainClass:\n",
        "    PROJECT_PATH = os.path.join(os.getcwd(), os.path.pardir)\n",
        "    PATH_IMAGES_ORIGINAL = os.path.abspath(\n",
        "        os.path.join(os.path.join(os.path.join(os.getcwd(), os.pardir), os.pardir), \"DATASET - Original\"))\n",
        "    PATH_Labels = os.path.abspath(\n",
        "        os.path.join(os.path.join(os.path.join(os.getcwd(), os.pardir), os.pardir), \"Labels\"))\n",
        "    PATH_LabelsXML = os.path.abspath(os.path.join(\n",
        "        os.path.join(os.path.join(os.path.join(os.getcwd(), os.pardir), os.pardir), \"Labels\"), \"LabelsXML\"))\n",
        "    PATH_IMAGES = os.path.abspath(\n",
        "        os.path.join(os.path.join(os.path.join(os.getcwd(), os.pardir), os.pardir), \"DATASET\"))\n",
        "    readimages = None\n",
        "    preprocessing = None\n",
        "    featureExtraction = None\n",
        "    clasification = None\n",
        "\n",
        "    def __init__(self):\n",
        "        try:\n",
        "            if not os.path.exists(self.PROJECT_PATH + 'PreProcessing'):\n",
        "                os.mkdir(os.path.join(self.PROJECT_PATH, 'PreProcessing'))\n",
        "                print('Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('PreProcessing Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "        try:\n",
        "            if not os.path.exists(self.PROJECT_PATH + 'FeatureExtraction'):\n",
        "                os.mkdir(os.path.join(self.PROJECT_PATH, 'FeatureExtraction'))\n",
        "                print('Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('FeatureExtraction Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "        try:\n",
        "            if not os.path.exists(self.PROJECT_PATH + 'Sampling'):\n",
        "                os.mkdir(os.path.join(self.PROJECT_PATH, 'Sampling'))\n",
        "                print('Directory Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('Sampling Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "        try:\n",
        "            if not os.path.exists(self.PROJECT_PATH + 'Classification'):\n",
        "                os.mkdir(os.path.join(self.PROJECT_PATH, 'Classification'))\n",
        "                print('Directory Classification Created')\n",
        "        except OSError as e:\n",
        "            if e.errno == errno.EEXIST:\n",
        "                print('Classification Directory Already Exists.')\n",
        "            else:\n",
        "                raise\n",
        "        self.readimages = rI.LoadData(self.PATH_IMAGES_ORIGINAL)\n",
        "        self.preProcessing = pD.PreProcessingData(self.PROJECT_PATH, self.PATH_IMAGES_ORIGINAL)\n",
        "        self.featureExtraction = fE.FeatureExtraction(self.PROJECT_PATH, self.PATH_IMAGES_ORIGINAL)\n",
        "        self.clasification = Cl.Classification(self.PROJECT_PATH)\n",
        "\n",
        "    def main_run(self):\n",
        "        # Se declaran las clases para poder utilizar los elementos\n",
        "        read = self.readimages\n",
        "        pp = self.preProcessing\n",
        "        fe = self.featureExtraction\n",
        "\n",
        "        # Se lee el nombre y la imagen que se encuentre en el PATH del dataset ORIGINAL\n",
        "        # img, name = read.read_One_Image(self.PATH_IMAGES)\n",
        "        # Se lee el nombre y la imagen que se encuentre en el PATH del dataset RECORTADO\n",
        "        img, name = read.read_One_Image(self.PATH_IMAGES)\n",
        "\n",
        "        # Se obtiene las dimensiones de la imagen original\n",
        "        height_ori, width_ori, depth_ori = img.shape\n",
        "        # print(\"Image original shape: \\n Height:\", height_ori, \", Width:\", width_ori)\n",
        "\n",
        "        # Se realiza un ajuste de tamaño para reducir la imagen a unas dimensiones de 600x400\n",
        "        img_resize = pp.resize_Image(img, name)\n",
        "\n",
        "        # La imagen reajustada se convierte de BGR a RGB\n",
        "        img_resize = cv.cvtColor(img_resize, cv.COLOR_BGR2RGB)\n",
        "        # Se convierte la imagen de RGB a HSV\n",
        "        hsv_image = pp.rgb_2_HSV(img_resize, name)\n",
        "        # Se saca la imagen en pila de tono de rojos\n",
        "        stack, name = pp.stackColors(hsv_image, name)\n",
        "        # Se saca los histogramas por imagen para determinar el rango de color de los dientes\n",
        "        pp.hsv_hist(hsv_image, name)\n",
        "        #\n",
        "        # plt.imshow(img_resize)\n",
        "        # Blur image slightly\n",
        "        name, blurimage = pp.blurImage(img_resize, name)\n",
        "        pp.show_mask(blurimage, name)\n",
        "        pp.overlay_mask(blurimage, img_resize, name)\n",
        "\n",
        "        # Se obtiene la rueda cromatica de la imágen\n",
        "        # pp.getChromatiColor(img_resize,name,fe)\n",
        "\n",
        "        # img_rgb2ycbcr = pp.rgb_2_YCrCb(img_resize, name)\n",
        "        img_rgb2hsv = pp.rgb_2_HSV(img_resize, name)\n",
        "\n",
        "    '''easygui.msgbox(\"Image original shape: \\n Height:\" + str(height_ori) + \"px, Width:\" + str(width_ori) + \"px\" +\n",
        "                   \"\\n Image Resize shape: \\n Height:\" + str(height_res) + \"px, Width:\" + str(width_res) + \"px\",\n",
        "                   image=os.path.join(os.path.join(os.getcwd(), os.path.pardir),\n",
        "                                      'PreProcessing/ResizeImages/' + name),\n",
        "                   title=\"Image Shape - PreProcessing \")'''\n",
        "\n",
        "    def savebin(self):\n",
        "        read = self.readimages\n",
        "        pp = self.preProcessing\n",
        "        fe = self.featureExtraction\n",
        "        images, names = read.read_Images(self.PATH_IMAGES_P)\n",
        "        for image_point, name_point in zip(images, names):\n",
        "            img_resize = pp.resize_Image(image_point, name_point)\n",
        "            img_resize = cv.cvtColor(img_resize, cv.COLOR_BGR2RGB)\n",
        "            img_resize = cv.cvtColor(img_resize, cv.COLOR_RGB2GRAY)\n",
        "            pp.bin(img_resize, name_point)\n",
        "\n",
        "    def main_alldataset(self):\n",
        "        # Se declaran las clases para poder utilizar los elementos\n",
        "        read = self.readimages\n",
        "        pp = self.preProcessing\n",
        "        fe = self.featureExtraction\n",
        "        cc = self.clasification\n",
        "        doption = input(\n",
        "            'Que desea hacer? \\n1. Leer imagenes y obtener caracteristicas'\n",
        "            '\\n2. Leer archivo de caracteristicas y entrenar algoritmo\\n')\n",
        "        option = int(doption)\n",
        "        print(option)\n",
        "\n",
        "        if option == 1:\n",
        "            images, names = read.read_Images(self.PATH_IMAGES)\n",
        "            bar = tqdm(images, ncols=len(images), unit=' image')\n",
        "            for image_point, name_point in zip(bar, names):\n",
        "                bar.set_description(\"Procesando imagen %s\" % name_point)\n",
        "                # Se reajusta la imagen a un tamaño de 600x400px\n",
        "                img_resize = pp.resize_Image(image_point, name_point)\n",
        "\n",
        "                # La imagen reajustada se convierte de BGR a RGB\n",
        "                img_resize = cv.cvtColor(img_resize, cv.COLOR_BGR2RGB)\n",
        "\n",
        "                # Se convierte la imagen de RGB a HSV\n",
        "                hsv_image = pp.rgb_2_HSV(img_resize, name_point)\n",
        "\n",
        "                # Se saca la imagen en pila de tono de rojos\n",
        "                stack, name_point = pp.stackColors(hsv_image, name_point)\n",
        "\n",
        "                # Se saca los histogramas por imagen para determinar el rango de color de los dientes\n",
        "                pp.hsv_hist(hsv_image, name_point)\n",
        "\n",
        "                # Blur image slightly\n",
        "                name_point, blurimage = pp.blurImage(img_resize, name_point)\n",
        "                '''file_ = open(os.path.join(self.PROJECT_PATH, 'Pruebas') + name_point + '.txt', \"w\")\n",
        "                for i in blurimage:\n",
        "                    file_.write(str(i))\n",
        "                file_.close()'''\n",
        "\n",
        "                # A partir del rango de color, se saca una máscara donde se ubican los dientes y se procede a buscar el contorno más grande dentro del área objetivo.\n",
        "                mask = pp.findBiggestContour(blurimage, name_point)\n",
        "                # Se separan los canales de la\n",
        "                # imágen en RGB\n",
        "                channelR, channelG, channelB = cv.split(img_resize)\n",
        "                # Se obtienen los momentos de color de cada espacio de color\n",
        "                red = fe.getFeaturesVector(channelR, mask)\n",
        "                green = fe.getFeaturesVector(channelG, mask)\n",
        "                blue = fe.getFeaturesVector(channelB, mask)\n",
        "                # colores = [\"RED\", \"GREEN\", \"BLUE\"]\n",
        "\n",
        "                # Se obtiene una mascara de la imágen compuesta por los valores de los canales donde se encontraron los datos de interes.\n",
        "                imagen = [red, green, blue]\n",
        "                # Se coloca la ruta del archivo de caracteristicas\n",
        "                filefeaturespath = os.path.join(os.path.join(self.PROJECT_PATH, 'FeatureExtraction'), 'features.csv')\n",
        "                # Se escribe en un archivo las caracteristicas del dataset\n",
        "                fe.getFeatures(imagen, filefeaturespath, name_point)\n",
        "                fileLabels = open(os.path.join(self.PATH_Labels, 'Labels.csv'))\n",
        "                pp.show_mask(blurimage, name_point)\n",
        "                pp.overlay_mask(blurimage, img_resize, name_point)\n",
        "        elif option == 2:\n",
        "            times_execution = -1\n",
        "            while times_execution <= 0:\n",
        "                times_execution = int(input('\\nIndique la cantidad de veces de ejecución:'))\n",
        "            bar = tqdm(range(times_execution), unit=' times')\n",
        "            for i in bar:\n",
        "                # Se lee el archivo de caracteristicas donde se encuentran los momentos de color\n",
        "                filefeaturespath = os.path.join(os.path.join(self.PROJECT_PATH, 'FeatureExtraction'), 'features.csv')\n",
        "                names, features = cc.readfeatures(filefeaturespath)\n",
        "                labels = cc.readLabels(self.PATH_Labels)\n",
        "                features_images = features.values\n",
        "                vals_to_replace = {'a1': '0', 'a2': '1', 'a3': '2', 'a35': '3'}\n",
        "                tags = ['0', '1', '2', '3']\n",
        "                target_names = ['a1', 'a2', 'a3', 'a35']\n",
        "                folds = int(input('\\nCantidad de folios a seperarar el conjunto de datos:'))\n",
        "                test_size = int(input('\\n Porcentaje de division del conjunto de datos trianing/test:'))\n",
        "                X, Y = cc.CrossValidation(features, labels, test_size / 100)\n",
        "                SVM, DT, KNN = cc.classification(self.PATH_IMAGES, X, Y, folds, tags, target_names, vals_to_replace)\n",
        "                print('--------- Training ---------')\n",
        "                for S, D, K in zip(SVM, DT, KNN):\n",
        "\n",
        "                    matrix_confusion_SVM, report_clasification_SVM, report_scores_SVM = S.split()\n",
        "                    matrix_confusion_DT, report_clasification_DT, report_scores_DT = D.split()\n",
        "                    matrix_confusion_KNN, report_clasification_KNN, report_scores_KNN = K.split()\n",
        "                    print('\\n')\n",
        "                    print('-------SVM------')\n",
        "                    for report in report_clasification_SVM:\n",
        "                        print(report)\n",
        "                        for item in report:\n",
        "                            print(report[item])\n",
        "                    print('--------MEAN SVM--------')\n",
        "                    print(np.mean(report_scores_SVM))\n",
        "                    print('-------DT------')\n",
        "                    for report in report_clasification_DT:\n",
        "                        print(report)\n",
        "                        for item in report:\n",
        "                            print(report[item])\n",
        "                    print('--------MEAN DT--------')\n",
        "                    print(np.mean(report_scores_DT))\n",
        "\n",
        "                    print('-------KNN------')\n",
        "                    for report in report_clasification_KNN:\n",
        "                        print(report)\n",
        "                        for item in report:\n",
        "                            print(report[item])\n",
        "                    print('--------MEAN KNN--------')\n",
        "                    print(np.mean(report_scores_KNN))\n",
        "                    print('--------- TEST ---------')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    tesis: MainClass = MainClass()\n",
        "    # tesis.main_run()\n",
        "    tesis.main_alldataset()\n",
        "    # tesis.savebin()\n",
        "    print('Se ha finalizado la ejecución del experimento')\n",
        "    sys.exit(0)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "U4Aw3PBQTFU3",
        "9DAskc84OgB8"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNc4MBVDy97WiqnoXwF4coj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}